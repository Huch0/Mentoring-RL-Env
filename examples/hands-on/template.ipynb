{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gymnasium, SB3 실습\n",
    "\n",
    "목표:\n",
    "- Gymnasium 환경 생성 및 설정\n",
    "- SB3 agent 생성 및 학습\n",
    "- agent 성능 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 환경 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "CartPole-v0 || CartPole-v1 || MountainCar-v0 || MountainCarContinuous-v0 || Pendulum-v1 || \n",
      "Acrobot-v1 || phys2d/CartPole-v0 || phys2d/CartPole-v1 || phys2d/Pendulum-v0 || LunarLander-v2 || \n",
      "LunarLanderContinuous-v2 || BipedalWalker-v3 || BipedalWalkerHardcore-v3 || CarRacing-v2 || Blackjack-v1 || \n",
      "FrozenLake-v1 || FrozenLake8x8-v1 || CliffWalking-v0 || Taxi-v3 || tabular/Blackjack-v0 || \n",
      "tabular/CliffWalking-v0 || Reacher-v2 || Reacher-v4 || Pusher-v2 || Pusher-v4 || \n",
      "InvertedPendulum-v2 || InvertedPendulum-v4 || InvertedDoublePendulum-v2 || InvertedDoublePendulum-v4 || HalfCheetah-v2 || \n",
      "HalfCheetah-v3 || HalfCheetah-v4 || Hopper-v2 || Hopper-v3 || Hopper-v4 || \n",
      "Swimmer-v2 || Swimmer-v3 || Swimmer-v4 || Walker2d-v2 || Walker2d-v3 || \n",
      "Walker2d-v4 || Ant-v2 || Ant-v3 || Ant-v4 || Humanoid-v2 || \n",
      "Humanoid-v3 || Humanoid-v4 || HumanoidStandup-v2 || HumanoidStandup-v4 || GymV21Environment-v0 || \n",
      "GymV26Environment-v0 || "
     ]
    }
   ],
   "source": [
    "envs = list(gym.envs.registry.keys())\n",
    "print(len(envs))\n",
    "\n",
    "for i in range(len(envs)):\n",
    "    print(envs[i], end=' || ')\n",
    "    if i % 5 == 4:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode = \"human\")\n",
    "# 왜 위에 리스트대로 적으면 안되고 이렇게 적으면 되는거지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 환경 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "pygame is not installed, run `pip install gymnasium[classic-control]`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:223\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfxdraw\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygame'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m observation, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m      4\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()  \u001b[38;5;66;03m# 환경 시각화\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:75\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:61\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:57\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_reset_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:186\u001b[0m, in \u001b[0;36menv_reset_passive_checker\u001b[1;34m(env, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdeprecation(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Checks the result of env.reset with kwargs\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m result \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    189\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:209\u001b[0m, in \u001b[0;36mCartPoleEnv.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_beyond_terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), {}\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:226\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfxdraw\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygame is not installed, run `pip install gymnasium[classic-control]`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     pygame\u001b[38;5;241m.\u001b[39minit()\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: pygame is not installed, run `pip install gymnasium[classic-control]`"
     ]
    }
   ],
   "source": [
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(100):\n",
    "    env.render()  \n",
    "    action = env.action_space.sample()  \n",
    "    observation, reward, done, truncated, info = env.step(action)  \n",
    "    \n",
    "    if done or truncated:\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Agent로 환경 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 생성 및 학습\n",
    "\n",
    "- EvalCallback을 사용하여 학습 과정 log\n",
    "- tensorboard로 학습 과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 학습된 모델 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    action, _states = model.predict(observation)  \n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    if done or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 더 탐구해보기\n",
    "\n",
    "- 어떤 모델과 환경이 호환되지 않는 이유가 무엇일까요?\n",
    "- 학습된 모델의 성능을 높이기 위해 어떤 방법을 사용할 수 있을까요?\n",
    "- 여러 환경과 모델을 사용하여 학습을 진행하고, 성능을 비교해보세요.\n",
    "- 다양한 Wrappers, Callbacks를 활용하여 원하는 동작을 구현해보세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
