{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AppleGameEnv import AppleGameEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.logger import configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AppleGameEnv(m=36, n=36, max_steps=1000)\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0, 'steps': 1, 'reward': 0}\n",
      "{'score': 0, 'steps': 2, 'reward': 0}\n",
      "{'score': 0, 'steps': 3, 'reward': 0}\n",
      "{'score': 0, 'steps': 4, 'reward': 0}\n",
      "{'score': 0, 'steps': 5, 'reward': 0}\n",
      "{'score': 0, 'steps': 6, 'reward': 0}\n",
      "{'score': 0, 'steps': 7, 'reward': 0}\n",
      "{'score': 0, 'steps': 8, 'reward': 0}\n",
      "{'score': 0, 'steps': 9, 'reward': 0}\n",
      "{'score': 0, 'steps': 10, 'reward': 0}\n",
      "{'score': 0, 'steps': 11, 'reward': 0}\n",
      "{'score': 0, 'steps': 12, 'reward': 0}\n",
      "{'score': 0, 'steps': 13, 'reward': 0}\n",
      "{'score': 0, 'steps': 14, 'reward': 0}\n",
      "{'score': 0, 'steps': 15, 'reward': 0}\n",
      "{'score': 0, 'steps': 16, 'reward': 0}\n",
      "{'score': 0, 'steps': 17, 'reward': 0}\n",
      "{'score': 0, 'steps': 18, 'reward': 0}\n",
      "{'score': 0, 'steps': 19, 'reward': 0}\n",
      "{'score': 0, 'steps': 20, 'reward': 0}\n",
      "{'score': 0, 'steps': 21, 'reward': 0}\n",
      "{'score': 0, 'steps': 22, 'reward': 0}\n",
      "{'score': 0, 'steps': 23, 'reward': 0}\n",
      "{'score': 0, 'steps': 24, 'reward': 0}\n",
      "{'score': 0, 'steps': 25, 'reward': 0}\n",
      "{'score': 0, 'steps': 26, 'reward': 0}\n",
      "{'score': 0, 'steps': 27, 'reward': 0}\n",
      "{'score': 0, 'steps': 28, 'reward': 0}\n",
      "{'score': 0, 'steps': 29, 'reward': 0}\n",
      "{'score': 0, 'steps': 30, 'reward': 0}\n",
      "{'score': 0, 'steps': 31, 'reward': 0}\n",
      "{'score': 0, 'steps': 32, 'reward': 0}\n",
      "{'score': 0, 'steps': 33, 'reward': 0}\n",
      "{'score': 0, 'steps': 34, 'reward': 0}\n",
      "{'score': 0, 'steps': 35, 'reward': 0}\n",
      "{'score': 0, 'steps': 36, 'reward': 0}\n",
      "{'score': 0, 'steps': 37, 'reward': 0}\n",
      "{'score': 0, 'steps': 38, 'reward': 0}\n",
      "{'score': 0, 'steps': 39, 'reward': 0}\n",
      "{'score': 0, 'steps': 40, 'reward': 0}\n",
      "{'score': 0, 'steps': 41, 'reward': 0}\n",
      "{'score': 0, 'steps': 42, 'reward': 0}\n",
      "{'score': 0, 'steps': 43, 'reward': 0}\n",
      "{'score': 0, 'steps': 44, 'reward': 0}\n",
      "{'score': 0, 'steps': 45, 'reward': 0}\n",
      "{'score': 0, 'steps': 46, 'reward': 0}\n",
      "{'score': 0, 'steps': 47, 'reward': 0}\n",
      "{'score': 0, 'steps': 48, 'reward': 0}\n",
      "{'score': 0, 'steps': 49, 'reward': 0}\n",
      "{'score': 0, 'steps': 50, 'reward': 0}\n",
      "{'score': 0, 'steps': 51, 'reward': 0}\n",
      "{'score': 0, 'steps': 52, 'reward': 0}\n",
      "{'score': 0, 'steps': 53, 'reward': 0}\n",
      "{'score': 0, 'steps': 54, 'reward': 0}\n",
      "{'score': 0, 'steps': 55, 'reward': 0}\n",
      "{'score': 0, 'steps': 56, 'reward': 0}\n",
      "{'score': 0, 'steps': 57, 'reward': 0}\n",
      "{'score': 0, 'steps': 58, 'reward': 0}\n",
      "{'score': 0, 'steps': 59, 'reward': 0}\n",
      "{'score': 0, 'steps': 60, 'reward': 0}\n",
      "{'score': 0, 'steps': 61, 'reward': 0}\n",
      "{'score': 0, 'steps': 62, 'reward': 0}\n",
      "{'score': 0, 'steps': 63, 'reward': 0}\n",
      "{'score': 0, 'steps': 64, 'reward': 0}\n",
      "{'score': 0, 'steps': 65, 'reward': 0}\n",
      "{'score': 0, 'steps': 66, 'reward': 0}\n",
      "{'score': 0, 'steps': 67, 'reward': 0}\n",
      "{'score': 0, 'steps': 68, 'reward': 0}\n",
      "{'score': 0, 'steps': 69, 'reward': 0}\n",
      "{'score': 0, 'steps': 70, 'reward': 0}\n",
      "{'score': 0, 'steps': 71, 'reward': 0}\n",
      "{'score': 0, 'steps': 72, 'reward': 0}\n",
      "{'score': 0, 'steps': 73, 'reward': 0}\n",
      "{'score': 0, 'steps': 74, 'reward': 0}\n",
      "{'score': 0, 'steps': 75, 'reward': 0}\n",
      "{'score': 0, 'steps': 76, 'reward': 0}\n",
      "{'score': 0, 'steps': 77, 'reward': 0}\n",
      "{'score': 0, 'steps': 78, 'reward': 0}\n",
      "{'score': 0, 'steps': 79, 'reward': 0}\n",
      "{'score': 0, 'steps': 80, 'reward': 0}\n",
      "{'score': 0, 'steps': 81, 'reward': 0}\n",
      "{'score': 0, 'steps': 82, 'reward': 0}\n",
      "{'score': 0, 'steps': 83, 'reward': 0}\n",
      "{'score': 0, 'steps': 84, 'reward': 0}\n",
      "{'score': 0, 'steps': 85, 'reward': 0}\n",
      "{'score': 0, 'steps': 86, 'reward': 0}\n",
      "{'score': 0, 'steps': 87, 'reward': 0}\n",
      "{'score': 0, 'steps': 88, 'reward': 0}\n",
      "{'score': 0, 'steps': 89, 'reward': 0}\n",
      "{'score': 0, 'steps': 90, 'reward': 0}\n",
      "{'score': 0, 'steps': 91, 'reward': 0}\n",
      "{'score': 0, 'steps': 92, 'reward': 0}\n",
      "{'score': 0, 'steps': 93, 'reward': 0}\n",
      "{'score': 0, 'steps': 94, 'reward': 0}\n",
      "{'score': 0, 'steps': 95, 'reward': 0}\n",
      "{'score': 0, 'steps': 96, 'reward': 0}\n",
      "{'score': 0, 'steps': 97, 'reward': 0}\n",
      "{'score': 0, 'steps': 98, 'reward': 0}\n",
      "{'score': 0, 'steps': 99, 'reward': 0}\n",
      "{'score': 0, 'steps': 100, 'reward': 0}\n",
      "{'score': 0, 'steps': 101, 'reward': 0}\n",
      "{'score': 0, 'steps': 102, 'reward': 0}\n",
      "{'score': 0, 'steps': 103, 'reward': 0}\n",
      "{'score': 0, 'steps': 104, 'reward': 0}\n",
      "{'score': 0, 'steps': 105, 'reward': 0}\n",
      "{'score': 0, 'steps': 106, 'reward': 0}\n",
      "{'score': 0, 'steps': 107, 'reward': 0}\n",
      "{'score': 0, 'steps': 108, 'reward': 0}\n",
      "{'score': 0, 'steps': 109, 'reward': 0}\n",
      "{'score': 0, 'steps': 110, 'reward': 0}\n",
      "{'score': 0, 'steps': 111, 'reward': 0}\n",
      "{'score': 0, 'steps': 112, 'reward': 0}\n",
      "{'score': 0, 'steps': 113, 'reward': 0}\n",
      "{'score': 0, 'steps': 114, 'reward': 0}\n",
      "{'score': 0, 'steps': 115, 'reward': 0}\n",
      "{'score': 0, 'steps': 116, 'reward': 0}\n",
      "{'score': 0, 'steps': 117, 'reward': 0}\n",
      "{'score': 0, 'steps': 118, 'reward': 0}\n",
      "{'score': 0, 'steps': 119, 'reward': 0}\n",
      "{'score': 0, 'steps': 120, 'reward': 0}\n",
      "{'score': 0, 'steps': 121, 'reward': 0}\n",
      "{'score': 0, 'steps': 122, 'reward': 0}\n",
      "{'score': 0, 'steps': 123, 'reward': 0}\n",
      "{'score': 0, 'steps': 124, 'reward': 0}\n",
      "{'score': 0, 'steps': 125, 'reward': 0}\n",
      "{'score': 0, 'steps': 126, 'reward': 0}\n",
      "{'score': 0, 'steps': 127, 'reward': 0}\n",
      "{'score': 0, 'steps': 128, 'reward': 0}\n",
      "{'score': 0, 'steps': 129, 'reward': 0}\n",
      "{'score': 0, 'steps': 130, 'reward': 0}\n",
      "{'score': 0, 'steps': 131, 'reward': 0}\n",
      "{'score': 0, 'steps': 132, 'reward': 0}\n",
      "{'score': 0, 'steps': 133, 'reward': 0}\n",
      "{'score': 0, 'steps': 134, 'reward': 0}\n",
      "{'score': 0, 'steps': 135, 'reward': 0}\n",
      "{'score': 0, 'steps': 136, 'reward': 0}\n",
      "{'score': 0, 'steps': 137, 'reward': 0}\n",
      "{'score': 0, 'steps': 138, 'reward': 0}\n",
      "{'score': 0, 'steps': 139, 'reward': 0}\n",
      "{'score': 0, 'steps': 140, 'reward': 0}\n",
      "{'score': 0, 'steps': 141, 'reward': 0}\n",
      "{'score': 0, 'steps': 142, 'reward': 0}\n",
      "{'score': 0, 'steps': 143, 'reward': 0}\n",
      "{'score': 0, 'steps': 144, 'reward': 0}\n",
      "{'score': 0, 'steps': 145, 'reward': 0}\n",
      "{'score': 0, 'steps': 146, 'reward': 0}\n",
      "{'score': 0, 'steps': 147, 'reward': 0}\n",
      "{'score': 0, 'steps': 148, 'reward': 0}\n",
      "{'score': 0, 'steps': 149, 'reward': 0}\n",
      "{'score': 0, 'steps': 150, 'reward': 0}\n",
      "{'score': 0, 'steps': 151, 'reward': 0}\n",
      "{'score': 0, 'steps': 152, 'reward': 0}\n",
      "{'score': 0, 'steps': 153, 'reward': 0}\n",
      "{'score': 0, 'steps': 154, 'reward': 0}\n",
      "{'score': 0, 'steps': 155, 'reward': 0}\n",
      "{'score': 0, 'steps': 156, 'reward': 0}\n",
      "{'score': 0, 'steps': 157, 'reward': 0}\n",
      "{'score': 0, 'steps': 158, 'reward': 0}\n",
      "{'score': 0, 'steps': 159, 'reward': 0}\n",
      "{'score': 0, 'steps': 160, 'reward': 0}\n",
      "{'score': 0, 'steps': 161, 'reward': 0}\n",
      "{'score': 0, 'steps': 162, 'reward': 0}\n",
      "{'score': 0, 'steps': 163, 'reward': 0}\n",
      "{'score': 0, 'steps': 164, 'reward': 0}\n",
      "{'score': 0, 'steps': 165, 'reward': 0}\n",
      "{'score': 0, 'steps': 166, 'reward': 0}\n",
      "{'score': 0, 'steps': 167, 'reward': 0}\n",
      "{'score': 0, 'steps': 168, 'reward': 0}\n",
      "{'score': 0, 'steps': 169, 'reward': 0}\n",
      "{'score': 0, 'steps': 170, 'reward': 0}\n",
      "{'score': 0, 'steps': 171, 'reward': 0}\n",
      "{'score': 0, 'steps': 172, 'reward': 0}\n",
      "{'score': 0, 'steps': 173, 'reward': 0}\n",
      "{'score': 0, 'steps': 174, 'reward': 0}\n",
      "{'score': 0, 'steps': 175, 'reward': 0}\n",
      "{'score': 0, 'steps': 176, 'reward': 0}\n",
      "{'score': 0, 'steps': 177, 'reward': 0}\n",
      "{'score': 0, 'steps': 178, 'reward': 0}\n",
      "{'score': 0, 'steps': 179, 'reward': 0}\n",
      "{'score': 0, 'steps': 180, 'reward': 0}\n",
      "{'score': 0, 'steps': 181, 'reward': 0}\n",
      "{'score': 0, 'steps': 182, 'reward': 0}\n",
      "{'score': 0, 'steps': 183, 'reward': 0}\n",
      "{'score': 0, 'steps': 184, 'reward': 0}\n",
      "{'score': 0, 'steps': 185, 'reward': 0}\n",
      "{'score': 0, 'steps': 186, 'reward': 0}\n",
      "{'score': 0, 'steps': 187, 'reward': 0}\n",
      "{'score': 0, 'steps': 188, 'reward': 0}\n",
      "{'score': 0, 'steps': 189, 'reward': 0}\n",
      "{'score': 0, 'steps': 190, 'reward': 0}\n",
      "{'score': 0, 'steps': 191, 'reward': 0}\n",
      "{'score': 0, 'steps': 192, 'reward': 0}\n",
      "{'score': 0, 'steps': 193, 'reward': 0}\n",
      "{'score': 0, 'steps': 194, 'reward': 0}\n",
      "{'score': 0, 'steps': 195, 'reward': 0}\n",
      "{'score': 0, 'steps': 196, 'reward': 0}\n",
      "{'score': 0, 'steps': 197, 'reward': 0}\n",
      "{'score': 0, 'steps': 198, 'reward': 0}\n",
      "{'score': 0, 'steps': 199, 'reward': 0}\n",
      "{'score': 0, 'steps': 200, 'reward': 0}\n",
      "{'score': 0, 'steps': 201, 'reward': 0}\n",
      "{'score': 0, 'steps': 202, 'reward': 0}\n",
      "{'score': 0, 'steps': 203, 'reward': 0}\n",
      "{'score': 0, 'steps': 204, 'reward': 0}\n",
      "{'score': 0, 'steps': 205, 'reward': 0}\n",
      "{'score': 0, 'steps': 206, 'reward': 0}\n",
      "{'score': 0, 'steps': 207, 'reward': 0}\n",
      "{'score': 0, 'steps': 208, 'reward': 0}\n",
      "{'score': 0, 'steps': 209, 'reward': 0}\n",
      "{'score': 0, 'steps': 210, 'reward': 0}\n",
      "{'score': 0, 'steps': 211, 'reward': 0}\n",
      "{'score': 0, 'steps': 212, 'reward': 0}\n",
      "{'score': 0, 'steps': 213, 'reward': 0}\n",
      "{'score': 0, 'steps': 214, 'reward': 0}\n",
      "{'score': 0, 'steps': 215, 'reward': 0}\n",
      "{'score': 0, 'steps': 216, 'reward': 0}\n",
      "{'score': 0, 'steps': 217, 'reward': 0}\n",
      "{'score': 0, 'steps': 218, 'reward': 0}\n",
      "{'score': 0, 'steps': 219, 'reward': 0}\n",
      "{'score': 0, 'steps': 220, 'reward': 0}\n",
      "{'score': 0, 'steps': 221, 'reward': 0}\n",
      "{'score': 0, 'steps': 222, 'reward': 0}\n",
      "{'score': 0, 'steps': 223, 'reward': 0}\n",
      "{'score': 0, 'steps': 224, 'reward': 0}\n",
      "{'score': 0, 'steps': 225, 'reward': 0}\n",
      "{'score': 0, 'steps': 226, 'reward': 0}\n",
      "{'score': 0, 'steps': 227, 'reward': 0}\n",
      "{'score': 0, 'steps': 228, 'reward': 0}\n",
      "{'score': 0, 'steps': 229, 'reward': 0}\n",
      "{'score': 0, 'steps': 230, 'reward': 0}\n",
      "{'score': 0, 'steps': 231, 'reward': 0}\n",
      "{'score': 0, 'steps': 232, 'reward': 0}\n",
      "{'score': 0, 'steps': 233, 'reward': 0}\n",
      "{'score': 0, 'steps': 234, 'reward': 0}\n",
      "{'score': 0, 'steps': 235, 'reward': 0}\n",
      "{'score': 0, 'steps': 236, 'reward': 0}\n",
      "{'score': 0, 'steps': 237, 'reward': 0}\n",
      "{'score': 0, 'steps': 238, 'reward': 0}\n",
      "{'score': 0, 'steps': 239, 'reward': 0}\n",
      "{'score': 0, 'steps': 240, 'reward': 0}\n",
      "{'score': 0, 'steps': 241, 'reward': 0}\n",
      "{'score': 0, 'steps': 242, 'reward': 0}\n",
      "{'score': 0, 'steps': 243, 'reward': 0}\n",
      "{'score': 0, 'steps': 244, 'reward': 0}\n",
      "{'score': 0, 'steps': 245, 'reward': 0}\n",
      "{'score': 0, 'steps': 246, 'reward': 0}\n",
      "{'score': 0, 'steps': 247, 'reward': 0}\n",
      "{'score': 0, 'steps': 248, 'reward': 0}\n",
      "{'score': 0, 'steps': 249, 'reward': 0}\n",
      "{'score': 0, 'steps': 250, 'reward': 0}\n",
      "{'score': 0, 'steps': 251, 'reward': 0}\n",
      "{'score': 0, 'steps': 252, 'reward': 0}\n",
      "{'score': 0, 'steps': 253, 'reward': 0}\n",
      "{'score': 0, 'steps': 254, 'reward': 0}\n",
      "{'score': 0, 'steps': 255, 'reward': 0}\n",
      "{'score': 0, 'steps': 256, 'reward': 0}\n",
      "{'score': 0, 'steps': 257, 'reward': 0}\n",
      "{'score': 0, 'steps': 258, 'reward': 0}\n",
      "{'score': 0, 'steps': 259, 'reward': 0}\n",
      "{'score': 0, 'steps': 260, 'reward': 0}\n",
      "{'score': 0, 'steps': 261, 'reward': 0}\n",
      "{'score': 0, 'steps': 262, 'reward': 0}\n",
      "{'score': 0, 'steps': 263, 'reward': 0}\n",
      "{'score': 0, 'steps': 264, 'reward': 0}\n",
      "{'score': 0, 'steps': 265, 'reward': 0}\n",
      "{'score': 0, 'steps': 266, 'reward': 0}\n",
      "{'score': 0, 'steps': 267, 'reward': 0}\n",
      "{'score': 0, 'steps': 268, 'reward': 0}\n",
      "{'score': 0, 'steps': 269, 'reward': 0}\n",
      "{'score': 0, 'steps': 270, 'reward': 0}\n",
      "{'score': 0, 'steps': 271, 'reward': 0}\n",
      "{'score': 0, 'steps': 272, 'reward': 0}\n",
      "{'score': 0, 'steps': 273, 'reward': 0}\n",
      "{'score': 0, 'steps': 274, 'reward': 0}\n",
      "{'score': 0, 'steps': 275, 'reward': 0}\n",
      "{'score': 0, 'steps': 276, 'reward': 0}\n",
      "{'score': 0, 'steps': 277, 'reward': 0}\n",
      "{'score': 0, 'steps': 278, 'reward': 0}\n",
      "{'score': 0, 'steps': 279, 'reward': 0}\n",
      "{'score': 0, 'steps': 280, 'reward': 0}\n",
      "{'score': 0, 'steps': 281, 'reward': 0}\n",
      "{'score': 0, 'steps': 282, 'reward': 0}\n",
      "{'score': 0, 'steps': 283, 'reward': 0}\n",
      "{'score': 0, 'steps': 284, 'reward': 0}\n",
      "{'score': 0, 'steps': 285, 'reward': 0}\n",
      "{'score': 0, 'steps': 286, 'reward': 0}\n",
      "{'score': 0, 'steps': 287, 'reward': 0}\n",
      "{'score': 0, 'steps': 288, 'reward': 0}\n",
      "{'score': 0, 'steps': 289, 'reward': 0}\n",
      "{'score': 0, 'steps': 290, 'reward': 0}\n",
      "{'score': 0, 'steps': 291, 'reward': 0}\n",
      "{'score': 0, 'steps': 292, 'reward': 0}\n",
      "{'score': 0, 'steps': 293, 'reward': 0}\n",
      "{'score': 0, 'steps': 294, 'reward': 0}\n",
      "{'score': 0, 'steps': 295, 'reward': 0}\n",
      "{'score': 0, 'steps': 296, 'reward': 0}\n",
      "{'score': 0, 'steps': 297, 'reward': 0}\n",
      "{'score': 0, 'steps': 298, 'reward': 0}\n",
      "{'score': 0, 'steps': 299, 'reward': 0}\n",
      "{'score': 0, 'steps': 300, 'reward': 0}\n",
      "{'score': 0, 'steps': 301, 'reward': 0}\n",
      "{'score': 0, 'steps': 302, 'reward': 0}\n",
      "{'score': 0, 'steps': 303, 'reward': 0}\n",
      "{'score': 0, 'steps': 304, 'reward': 0}\n",
      "{'score': 0, 'steps': 305, 'reward': 0}\n",
      "{'score': 0, 'steps': 306, 'reward': 0}\n",
      "{'score': 0, 'steps': 307, 'reward': 0}\n",
      "{'score': 0, 'steps': 308, 'reward': 0}\n",
      "{'score': 0, 'steps': 309, 'reward': 0}\n",
      "{'score': 0, 'steps': 310, 'reward': 0}\n",
      "{'score': 0, 'steps': 311, 'reward': 0}\n",
      "{'score': 0, 'steps': 312, 'reward': 0}\n",
      "{'score': 0, 'steps': 313, 'reward': 0}\n",
      "{'score': 0, 'steps': 314, 'reward': 0}\n",
      "{'score': 0, 'steps': 315, 'reward': 0}\n",
      "{'score': 0, 'steps': 316, 'reward': 0}\n",
      "{'score': 0, 'steps': 317, 'reward': 0}\n",
      "{'score': 0, 'steps': 318, 'reward': 0}\n",
      "{'score': 0, 'steps': 319, 'reward': 0}\n",
      "{'score': 0, 'steps': 320, 'reward': 0}\n",
      "{'score': 0, 'steps': 321, 'reward': 0}\n",
      "{'score': 0, 'steps': 322, 'reward': 0}\n",
      "{'score': 0, 'steps': 323, 'reward': 0}\n",
      "{'score': 0, 'steps': 324, 'reward': 0}\n",
      "{'score': 0, 'steps': 325, 'reward': 0}\n",
      "{'score': 0, 'steps': 326, 'reward': 0}\n",
      "{'score': 0, 'steps': 327, 'reward': 0}\n",
      "{'score': 0, 'steps': 328, 'reward': 0}\n",
      "{'score': 0, 'steps': 329, 'reward': 0}\n",
      "{'score': 0, 'steps': 330, 'reward': 0}\n",
      "{'score': 0, 'steps': 331, 'reward': 0}\n",
      "{'score': 0, 'steps': 332, 'reward': 0}\n",
      "{'score': 0, 'steps': 333, 'reward': 0}\n",
      "{'score': 0, 'steps': 334, 'reward': 0}\n",
      "{'score': 0, 'steps': 335, 'reward': 0}\n",
      "{'score': 0, 'steps': 336, 'reward': 0}\n",
      "{'score': 0, 'steps': 337, 'reward': 0}\n",
      "{'score': 0, 'steps': 338, 'reward': 0}\n",
      "{'score': 0, 'steps': 339, 'reward': 0}\n",
      "{'score': 0, 'steps': 340, 'reward': 0}\n",
      "{'score': 0, 'steps': 341, 'reward': 0}\n",
      "{'score': 0, 'steps': 342, 'reward': 0}\n",
      "{'score': 0, 'steps': 343, 'reward': 0}\n",
      "{'score': 0, 'steps': 344, 'reward': 0}\n",
      "{'score': 0, 'steps': 345, 'reward': 0}\n",
      "{'score': 0, 'steps': 346, 'reward': 0}\n",
      "{'score': 0, 'steps': 347, 'reward': 0}\n",
      "{'score': 0, 'steps': 348, 'reward': 0}\n",
      "{'score': 0, 'steps': 349, 'reward': 0}\n",
      "{'score': 0, 'steps': 350, 'reward': 0}\n",
      "{'score': 0, 'steps': 351, 'reward': 0}\n",
      "{'score': 0, 'steps': 352, 'reward': 0}\n",
      "{'score': 0, 'steps': 353, 'reward': 0}\n",
      "{'score': 0, 'steps': 354, 'reward': 0}\n",
      "{'score': 0, 'steps': 355, 'reward': 0}\n",
      "{'score': 0, 'steps': 356, 'reward': 0}\n",
      "{'score': 0, 'steps': 357, 'reward': 0}\n",
      "{'score': 0, 'steps': 358, 'reward': 0}\n",
      "{'score': 0, 'steps': 359, 'reward': 0}\n",
      "{'score': 0, 'steps': 360, 'reward': 0}\n",
      "{'score': 0, 'steps': 361, 'reward': 0}\n",
      "{'score': 0, 'steps': 362, 'reward': 0}\n",
      "{'score': 0, 'steps': 363, 'reward': 0}\n",
      "{'score': 0, 'steps': 364, 'reward': 0}\n",
      "{'score': 0, 'steps': 365, 'reward': 0}\n",
      "{'score': 0, 'steps': 366, 'reward': 0}\n",
      "{'score': 0, 'steps': 367, 'reward': 0}\n",
      "{'score': 0, 'steps': 368, 'reward': 0}\n",
      "{'score': 0, 'steps': 369, 'reward': 0}\n",
      "{'score': 0, 'steps': 370, 'reward': 0}\n",
      "{'score': 0, 'steps': 371, 'reward': 0}\n",
      "{'score': 0, 'steps': 372, 'reward': 0}\n",
      "{'score': 0, 'steps': 373, 'reward': 0}\n",
      "{'score': 0, 'steps': 374, 'reward': 0}\n",
      "{'score': 0, 'steps': 375, 'reward': 0}\n",
      "{'score': 0, 'steps': 376, 'reward': 0}\n",
      "{'score': 0, 'steps': 377, 'reward': 0}\n",
      "{'score': 0, 'steps': 378, 'reward': 0}\n",
      "{'score': 0, 'steps': 379, 'reward': 0}\n",
      "{'score': 0, 'steps': 380, 'reward': 0}\n",
      "{'score': 0, 'steps': 381, 'reward': 0}\n",
      "{'score': 0, 'steps': 382, 'reward': 0}\n",
      "{'score': 0, 'steps': 383, 'reward': 0}\n",
      "{'score': 0, 'steps': 384, 'reward': 0}\n",
      "{'score': 0, 'steps': 385, 'reward': 0}\n",
      "{'score': 0, 'steps': 386, 'reward': 0}\n",
      "{'score': 0, 'steps': 387, 'reward': 0}\n",
      "{'score': 0, 'steps': 388, 'reward': 0}\n",
      "{'score': 0, 'steps': 389, 'reward': 0}\n",
      "{'score': 0, 'steps': 390, 'reward': 0}\n",
      "{'score': 0, 'steps': 391, 'reward': 0}\n",
      "{'score': 0, 'steps': 392, 'reward': 0}\n",
      "{'score': 0, 'steps': 393, 'reward': 0}\n",
      "{'score': 0, 'steps': 394, 'reward': 0}\n",
      "{'score': 0, 'steps': 395, 'reward': 0}\n",
      "{'score': 0, 'steps': 396, 'reward': 0}\n",
      "{'score': 0, 'steps': 397, 'reward': 0}\n",
      "{'score': 0, 'steps': 398, 'reward': 0}\n",
      "{'score': 0, 'steps': 399, 'reward': 0}\n",
      "{'score': 0, 'steps': 400, 'reward': 0}\n",
      "{'score': 0, 'steps': 401, 'reward': 0}\n",
      "{'score': 0, 'steps': 402, 'reward': 0}\n",
      "{'score': 0, 'steps': 403, 'reward': 0}\n",
      "{'score': 0, 'steps': 404, 'reward': 0}\n",
      "{'score': 0, 'steps': 405, 'reward': 0}\n",
      "{'score': 0, 'steps': 406, 'reward': 0}\n",
      "{'score': 0, 'steps': 407, 'reward': 0}\n",
      "{'score': 0, 'steps': 408, 'reward': 0}\n",
      "{'score': 0, 'steps': 409, 'reward': 0}\n",
      "{'score': 0, 'steps': 410, 'reward': 0}\n",
      "{'score': 0, 'steps': 411, 'reward': 0}\n",
      "{'score': 0, 'steps': 412, 'reward': 0}\n",
      "{'score': 0, 'steps': 413, 'reward': 0}\n",
      "{'score': 0, 'steps': 414, 'reward': 0}\n",
      "{'score': 0, 'steps': 415, 'reward': 0}\n",
      "{'score': 0, 'steps': 416, 'reward': 0}\n",
      "{'score': 0, 'steps': 417, 'reward': 0}\n",
      "{'score': 0, 'steps': 418, 'reward': 0}\n",
      "{'score': 0, 'steps': 419, 'reward': 0}\n",
      "{'score': 0, 'steps': 420, 'reward': 0}\n",
      "{'score': 0, 'steps': 421, 'reward': 0}\n",
      "{'score': 0, 'steps': 422, 'reward': 0}\n",
      "{'score': 0, 'steps': 423, 'reward': 0}\n",
      "{'score': 0, 'steps': 424, 'reward': 0}\n",
      "{'score': 0, 'steps': 425, 'reward': 0}\n",
      "{'score': 0, 'steps': 426, 'reward': 0}\n",
      "{'score': 0, 'steps': 427, 'reward': 0}\n",
      "{'score': 0, 'steps': 428, 'reward': 0}\n",
      "{'score': 0, 'steps': 429, 'reward': 0}\n",
      "{'score': 0, 'steps': 430, 'reward': 0}\n",
      "{'score': 0, 'steps': 431, 'reward': 0}\n",
      "{'score': 0, 'steps': 432, 'reward': 0}\n",
      "{'score': 0, 'steps': 433, 'reward': 0}\n",
      "{'score': 0, 'steps': 434, 'reward': 0}\n",
      "{'score': 0, 'steps': 435, 'reward': 0}\n",
      "{'score': 0, 'steps': 436, 'reward': 0}\n",
      "{'score': 0, 'steps': 437, 'reward': 0}\n",
      "{'score': 0, 'steps': 438, 'reward': 0}\n",
      "{'score': 0, 'steps': 439, 'reward': 0}\n",
      "{'score': 0, 'steps': 440, 'reward': 0}\n",
      "{'score': 0, 'steps': 441, 'reward': 0}\n",
      "{'score': 0, 'steps': 442, 'reward': 0}\n",
      "{'score': 0, 'steps': 443, 'reward': 0}\n",
      "{'score': 0, 'steps': 444, 'reward': 0}\n",
      "{'score': 0, 'steps': 445, 'reward': 0}\n",
      "{'score': 0, 'steps': 446, 'reward': 0}\n",
      "{'score': 0, 'steps': 447, 'reward': 0}\n",
      "{'score': 0, 'steps': 448, 'reward': 0}\n",
      "{'score': 0, 'steps': 449, 'reward': 0}\n",
      "{'score': 0, 'steps': 450, 'reward': 0}\n",
      "{'score': 0, 'steps': 451, 'reward': 0}\n",
      "{'score': 0, 'steps': 452, 'reward': 0}\n",
      "{'score': 0, 'steps': 453, 'reward': 0}\n",
      "{'score': 0, 'steps': 454, 'reward': 0}\n",
      "{'score': 0, 'steps': 455, 'reward': 0}\n",
      "{'score': 0, 'steps': 456, 'reward': 0}\n",
      "{'score': 0, 'steps': 457, 'reward': 0}\n",
      "{'score': 0, 'steps': 458, 'reward': 0}\n",
      "{'score': 0, 'steps': 459, 'reward': 0}\n",
      "{'score': 0, 'steps': 460, 'reward': 0}\n",
      "{'score': 0, 'steps': 461, 'reward': 0}\n",
      "{'score': 0, 'steps': 462, 'reward': 0}\n",
      "{'score': 0, 'steps': 463, 'reward': 0}\n",
      "{'score': 0, 'steps': 464, 'reward': 0}\n",
      "{'score': 0, 'steps': 465, 'reward': 0}\n",
      "{'score': 0, 'steps': 466, 'reward': 0}\n",
      "{'score': 0, 'steps': 467, 'reward': 0}\n",
      "{'score': 0, 'steps': 468, 'reward': 0}\n",
      "{'score': 0, 'steps': 469, 'reward': 0}\n",
      "{'score': 0, 'steps': 470, 'reward': 0}\n",
      "{'score': 0, 'steps': 471, 'reward': 0}\n",
      "{'score': 0, 'steps': 472, 'reward': 0}\n",
      "{'score': 0, 'steps': 473, 'reward': 0}\n",
      "{'score': 0, 'steps': 474, 'reward': 0}\n",
      "{'score': 0, 'steps': 475, 'reward': 0}\n",
      "{'score': 0, 'steps': 476, 'reward': 0}\n",
      "{'score': 0, 'steps': 477, 'reward': 0}\n",
      "{'score': 0, 'steps': 478, 'reward': 0}\n",
      "{'score': 0, 'steps': 479, 'reward': 0}\n",
      "{'score': 0, 'steps': 480, 'reward': 0}\n",
      "{'score': 0, 'steps': 481, 'reward': 0}\n",
      "{'score': 0, 'steps': 482, 'reward': 0}\n",
      "{'score': 0, 'steps': 483, 'reward': 0}\n",
      "{'score': 0, 'steps': 484, 'reward': 0}\n",
      "{'score': 0, 'steps': 485, 'reward': 0}\n",
      "{'score': 0, 'steps': 486, 'reward': 0}\n",
      "{'score': 0, 'steps': 487, 'reward': 0}\n",
      "{'score': 0, 'steps': 488, 'reward': 0}\n",
      "{'score': 0, 'steps': 489, 'reward': 0}\n",
      "{'score': 0, 'steps': 490, 'reward': 0}\n",
      "{'score': 0, 'steps': 491, 'reward': 0}\n",
      "{'score': 0, 'steps': 492, 'reward': 0}\n",
      "{'score': 0, 'steps': 493, 'reward': 0}\n",
      "{'score': 0, 'steps': 494, 'reward': 0}\n",
      "{'score': 0, 'steps': 495, 'reward': 0}\n",
      "{'score': 0, 'steps': 496, 'reward': 0}\n",
      "{'score': 0, 'steps': 497, 'reward': 0}\n",
      "{'score': 0, 'steps': 498, 'reward': 0}\n",
      "{'score': 0, 'steps': 499, 'reward': 0}\n",
      "{'score': 0, 'steps': 500, 'reward': 0}\n",
      "{'score': 0, 'steps': 501, 'reward': 0}\n",
      "{'score': 0, 'steps': 502, 'reward': 0}\n",
      "{'score': 0, 'steps': 503, 'reward': 0}\n",
      "{'score': 0, 'steps': 504, 'reward': 0}\n",
      "{'score': 0, 'steps': 505, 'reward': 0}\n",
      "{'score': 0, 'steps': 506, 'reward': 0}\n",
      "{'score': 0, 'steps': 507, 'reward': 0}\n",
      "{'score': 0, 'steps': 508, 'reward': 0}\n",
      "{'score': 0, 'steps': 509, 'reward': 0}\n",
      "{'score': 0, 'steps': 510, 'reward': 0}\n",
      "{'score': 0, 'steps': 511, 'reward': 0}\n",
      "{'score': 0, 'steps': 512, 'reward': 0}\n",
      "{'score': 0, 'steps': 513, 'reward': 0}\n",
      "{'score': 0, 'steps': 514, 'reward': 0}\n",
      "{'score': 0, 'steps': 515, 'reward': 0}\n",
      "{'score': 0, 'steps': 516, 'reward': 0}\n",
      "{'score': 0, 'steps': 517, 'reward': 0}\n",
      "{'score': 0, 'steps': 518, 'reward': 0}\n",
      "{'score': 0, 'steps': 519, 'reward': 0}\n",
      "{'score': 0, 'steps': 520, 'reward': 0}\n",
      "{'score': 0, 'steps': 521, 'reward': 0}\n",
      "{'score': 0, 'steps': 522, 'reward': 0}\n",
      "{'score': 0, 'steps': 523, 'reward': 0}\n",
      "{'score': 0, 'steps': 524, 'reward': 0}\n",
      "{'score': 0, 'steps': 525, 'reward': 0}\n",
      "{'score': 0, 'steps': 526, 'reward': 0}\n",
      "{'score': 0, 'steps': 527, 'reward': 0}\n",
      "{'score': 0, 'steps': 528, 'reward': 0}\n",
      "{'score': 0, 'steps': 529, 'reward': 0}\n",
      "{'score': 0, 'steps': 530, 'reward': 0}\n",
      "{'score': 0, 'steps': 531, 'reward': 0}\n",
      "{'score': 0, 'steps': 532, 'reward': 0}\n",
      "{'score': 0, 'steps': 533, 'reward': 0}\n",
      "{'score': 0, 'steps': 534, 'reward': 0}\n",
      "{'score': 0, 'steps': 535, 'reward': 0}\n",
      "{'score': 0, 'steps': 536, 'reward': 0}\n",
      "{'score': 0, 'steps': 537, 'reward': 0}\n",
      "{'score': 0, 'steps': 538, 'reward': 0}\n",
      "{'score': 0, 'steps': 539, 'reward': 0}\n",
      "{'score': 0, 'steps': 540, 'reward': 0}\n",
      "{'score': 0, 'steps': 541, 'reward': 0}\n",
      "{'score': 0, 'steps': 542, 'reward': 0}\n",
      "{'score': 0, 'steps': 543, 'reward': 0}\n",
      "{'score': 0, 'steps': 544, 'reward': 0}\n",
      "{'score': 0, 'steps': 545, 'reward': 0}\n",
      "{'score': 0, 'steps': 546, 'reward': 0}\n",
      "{'score': 0, 'steps': 547, 'reward': 0}\n",
      "{'score': 0, 'steps': 548, 'reward': 0}\n",
      "{'score': 0, 'steps': 549, 'reward': 0}\n",
      "{'score': 0, 'steps': 550, 'reward': 0}\n",
      "{'score': 0, 'steps': 551, 'reward': 0}\n",
      "{'score': 0, 'steps': 552, 'reward': 0}\n",
      "{'score': 0, 'steps': 553, 'reward': 0}\n",
      "{'score': 0, 'steps': 554, 'reward': 0}\n",
      "{'score': 0, 'steps': 555, 'reward': 0}\n",
      "{'score': 0, 'steps': 556, 'reward': 0}\n",
      "{'score': 0, 'steps': 557, 'reward': 0}\n",
      "{'score': 0, 'steps': 558, 'reward': 0}\n",
      "{'score': 0, 'steps': 559, 'reward': 0}\n",
      "{'score': 0, 'steps': 560, 'reward': 0}\n",
      "{'score': 0, 'steps': 561, 'reward': 0}\n",
      "{'score': 0, 'steps': 562, 'reward': 0}\n",
      "{'score': 0, 'steps': 563, 'reward': 0}\n",
      "{'score': 0, 'steps': 564, 'reward': 0}\n",
      "{'score': 0, 'steps': 565, 'reward': 0}\n",
      "{'score': 0, 'steps': 566, 'reward': 0}\n",
      "{'score': 0, 'steps': 567, 'reward': 0}\n",
      "{'score': 0, 'steps': 568, 'reward': 0}\n",
      "{'score': 0, 'steps': 569, 'reward': 0}\n",
      "{'score': 0, 'steps': 570, 'reward': 0}\n",
      "{'score': 0, 'steps': 571, 'reward': 0}\n",
      "{'score': 0, 'steps': 572, 'reward': 0}\n",
      "{'score': 0, 'steps': 573, 'reward': 0}\n",
      "{'score': 0, 'steps': 574, 'reward': 0}\n",
      "{'score': 0, 'steps': 575, 'reward': 0}\n",
      "{'score': 0, 'steps': 576, 'reward': 0}\n",
      "{'score': 0, 'steps': 577, 'reward': 0}\n",
      "{'score': 0, 'steps': 578, 'reward': 0}\n",
      "{'score': 0, 'steps': 579, 'reward': 0}\n",
      "{'score': 0, 'steps': 580, 'reward': 0}\n",
      "{'score': 0, 'steps': 581, 'reward': 0}\n",
      "{'score': 0, 'steps': 582, 'reward': 0}\n",
      "{'score': 0, 'steps': 583, 'reward': 0}\n",
      "{'score': 0, 'steps': 584, 'reward': 0}\n",
      "{'score': 0, 'steps': 585, 'reward': 0}\n",
      "{'score': 0, 'steps': 586, 'reward': 0}\n",
      "{'score': 0, 'steps': 587, 'reward': 0}\n",
      "{'score': 0, 'steps': 588, 'reward': 0}\n",
      "{'score': 0, 'steps': 589, 'reward': 0}\n",
      "{'score': 0, 'steps': 590, 'reward': 0}\n",
      "{'score': 0, 'steps': 591, 'reward': 0}\n",
      "{'score': 0, 'steps': 592, 'reward': 0}\n",
      "{'score': 0, 'steps': 593, 'reward': 0}\n",
      "{'score': 0, 'steps': 594, 'reward': 0}\n",
      "{'score': 0, 'steps': 595, 'reward': 0}\n",
      "{'score': 0, 'steps': 596, 'reward': 0}\n",
      "{'score': 0, 'steps': 597, 'reward': 0}\n",
      "{'score': 0, 'steps': 598, 'reward': 0}\n",
      "{'score': 0, 'steps': 599, 'reward': 0}\n",
      "{'score': 0, 'steps': 600, 'reward': 0}\n",
      "{'score': 0, 'steps': 601, 'reward': 0}\n",
      "{'score': 0, 'steps': 602, 'reward': 0}\n",
      "{'score': 0, 'steps': 603, 'reward': 0}\n",
      "{'score': 0, 'steps': 604, 'reward': 0}\n",
      "{'score': 0, 'steps': 605, 'reward': 0}\n",
      "{'score': 0, 'steps': 606, 'reward': 0}\n",
      "{'score': 0, 'steps': 607, 'reward': 0}\n",
      "{'score': 0, 'steps': 608, 'reward': 0}\n",
      "{'score': 0, 'steps': 609, 'reward': 0}\n",
      "{'score': 0, 'steps': 610, 'reward': 0}\n",
      "{'score': 0, 'steps': 611, 'reward': 0}\n",
      "{'score': 0, 'steps': 612, 'reward': 0}\n",
      "{'score': 0, 'steps': 613, 'reward': 0}\n",
      "{'score': 0, 'steps': 614, 'reward': 0}\n",
      "{'score': 0, 'steps': 615, 'reward': 0}\n",
      "{'score': 0, 'steps': 616, 'reward': 0}\n",
      "{'score': 0, 'steps': 617, 'reward': 0}\n",
      "{'score': 0, 'steps': 618, 'reward': 0}\n",
      "{'score': 0, 'steps': 619, 'reward': 0}\n",
      "{'score': 0, 'steps': 620, 'reward': 0}\n",
      "{'score': 0, 'steps': 621, 'reward': 0}\n",
      "{'score': 0, 'steps': 622, 'reward': 0}\n",
      "{'score': 0, 'steps': 623, 'reward': 0}\n",
      "{'score': 0, 'steps': 624, 'reward': 0}\n",
      "{'score': 0, 'steps': 625, 'reward': 0}\n",
      "{'score': 0, 'steps': 626, 'reward': 0}\n",
      "{'score': 0, 'steps': 627, 'reward': 0}\n",
      "{'score': 0, 'steps': 628, 'reward': 0}\n",
      "{'score': 0, 'steps': 629, 'reward': 0}\n",
      "{'score': 0, 'steps': 630, 'reward': 0}\n",
      "{'score': 0, 'steps': 631, 'reward': 0}\n",
      "{'score': 0, 'steps': 632, 'reward': 0}\n",
      "{'score': 0, 'steps': 633, 'reward': 0}\n",
      "{'score': 0, 'steps': 634, 'reward': 0}\n",
      "{'score': 0, 'steps': 635, 'reward': 0}\n",
      "{'score': 0, 'steps': 636, 'reward': 0}\n",
      "{'score': 0, 'steps': 637, 'reward': 0}\n",
      "{'score': 0, 'steps': 638, 'reward': 0}\n",
      "{'score': 0, 'steps': 639, 'reward': 0}\n",
      "{'score': 0, 'steps': 640, 'reward': 0}\n",
      "{'score': 0, 'steps': 641, 'reward': 0}\n",
      "{'score': 0, 'steps': 642, 'reward': 0}\n",
      "{'score': 0, 'steps': 643, 'reward': 0}\n",
      "{'score': 0, 'steps': 644, 'reward': 0}\n",
      "{'score': 0, 'steps': 645, 'reward': 0}\n",
      "{'score': 0, 'steps': 646, 'reward': 0}\n",
      "{'score': 0, 'steps': 647, 'reward': 0}\n",
      "{'score': 0, 'steps': 648, 'reward': 0}\n",
      "{'score': 0, 'steps': 649, 'reward': 0}\n",
      "{'score': 0, 'steps': 650, 'reward': 0}\n",
      "{'score': 0, 'steps': 651, 'reward': 0}\n",
      "{'score': 0, 'steps': 652, 'reward': 0}\n",
      "{'score': 0, 'steps': 653, 'reward': 0}\n",
      "{'score': 0, 'steps': 654, 'reward': 0}\n",
      "{'score': 0, 'steps': 655, 'reward': 0}\n",
      "{'score': 0, 'steps': 656, 'reward': 0}\n",
      "{'score': 0, 'steps': 657, 'reward': 0}\n",
      "{'score': 0, 'steps': 658, 'reward': 0}\n",
      "{'score': 0, 'steps': 659, 'reward': 0}\n",
      "{'score': 0, 'steps': 660, 'reward': 0}\n",
      "{'score': 0, 'steps': 661, 'reward': 0}\n",
      "{'score': 0, 'steps': 662, 'reward': 0}\n",
      "{'score': 0, 'steps': 663, 'reward': 0}\n",
      "{'score': 0, 'steps': 664, 'reward': 0}\n",
      "{'score': 0, 'steps': 665, 'reward': 0}\n",
      "{'score': 0, 'steps': 666, 'reward': 0}\n",
      "{'score': 0, 'steps': 667, 'reward': 0}\n",
      "{'score': 0, 'steps': 668, 'reward': 0}\n",
      "{'score': 0, 'steps': 669, 'reward': 0}\n",
      "{'score': 0, 'steps': 670, 'reward': 0}\n",
      "{'score': 0, 'steps': 671, 'reward': 0}\n",
      "{'score': 0, 'steps': 672, 'reward': 0}\n",
      "{'score': 0, 'steps': 673, 'reward': 0}\n",
      "{'score': 0, 'steps': 674, 'reward': 0}\n",
      "{'score': 0, 'steps': 675, 'reward': 0}\n",
      "{'score': 0, 'steps': 676, 'reward': 0}\n",
      "{'score': 0, 'steps': 677, 'reward': 0}\n",
      "{'score': 0, 'steps': 678, 'reward': 0}\n",
      "{'score': 0, 'steps': 679, 'reward': 0}\n",
      "{'score': 3, 'steps': 680, 'reward': 3}\n",
      "{'score': 3, 'steps': 681, 'reward': 0}\n",
      "{'score': 3, 'steps': 682, 'reward': 0}\n",
      "{'score': 3, 'steps': 683, 'reward': 0}\n",
      "{'score': 3, 'steps': 684, 'reward': 0}\n",
      "{'score': 3, 'steps': 685, 'reward': 0}\n",
      "{'score': 3, 'steps': 686, 'reward': 0}\n",
      "{'score': 3, 'steps': 687, 'reward': 0}\n",
      "{'score': 3, 'steps': 688, 'reward': 0}\n",
      "{'score': 3, 'steps': 689, 'reward': 0}\n",
      "{'score': 3, 'steps': 690, 'reward': 0}\n",
      "{'score': 3, 'steps': 691, 'reward': 0}\n",
      "{'score': 3, 'steps': 692, 'reward': 0}\n",
      "{'score': 3, 'steps': 693, 'reward': 0}\n",
      "{'score': 3, 'steps': 694, 'reward': 0}\n",
      "{'score': 3, 'steps': 695, 'reward': 0}\n",
      "{'score': 3, 'steps': 696, 'reward': 0}\n",
      "{'score': 3, 'steps': 697, 'reward': 0}\n",
      "{'score': 3, 'steps': 698, 'reward': 0}\n",
      "{'score': 3, 'steps': 699, 'reward': 0}\n",
      "{'score': 3, 'steps': 700, 'reward': 0}\n",
      "{'score': 3, 'steps': 701, 'reward': 0}\n",
      "{'score': 3, 'steps': 702, 'reward': 0}\n",
      "{'score': 3, 'steps': 703, 'reward': 0}\n",
      "{'score': 3, 'steps': 704, 'reward': 0}\n",
      "{'score': 3, 'steps': 705, 'reward': 0}\n",
      "{'score': 3, 'steps': 706, 'reward': 0}\n",
      "{'score': 3, 'steps': 707, 'reward': 0}\n",
      "{'score': 3, 'steps': 708, 'reward': 0}\n",
      "{'score': 3, 'steps': 709, 'reward': 0}\n",
      "{'score': 3, 'steps': 710, 'reward': 0}\n",
      "{'score': 3, 'steps': 711, 'reward': 0}\n",
      "{'score': 3, 'steps': 712, 'reward': 0}\n",
      "{'score': 3, 'steps': 713, 'reward': 0}\n",
      "{'score': 3, 'steps': 714, 'reward': 0}\n",
      "{'score': 3, 'steps': 715, 'reward': 0}\n",
      "{'score': 3, 'steps': 716, 'reward': 0}\n",
      "{'score': 3, 'steps': 717, 'reward': 0}\n",
      "{'score': 3, 'steps': 718, 'reward': 0}\n",
      "{'score': 3, 'steps': 719, 'reward': 0}\n",
      "{'score': 3, 'steps': 720, 'reward': 0}\n",
      "{'score': 3, 'steps': 721, 'reward': 0}\n",
      "{'score': 3, 'steps': 722, 'reward': 0}\n",
      "{'score': 3, 'steps': 723, 'reward': 0}\n",
      "{'score': 3, 'steps': 724, 'reward': 0}\n",
      "{'score': 3, 'steps': 725, 'reward': 0}\n",
      "{'score': 3, 'steps': 726, 'reward': 0}\n",
      "{'score': 3, 'steps': 727, 'reward': 0}\n",
      "{'score': 3, 'steps': 728, 'reward': 0}\n",
      "{'score': 3, 'steps': 729, 'reward': 0}\n",
      "{'score': 3, 'steps': 730, 'reward': 0}\n",
      "{'score': 3, 'steps': 731, 'reward': 0}\n",
      "{'score': 3, 'steps': 732, 'reward': 0}\n",
      "{'score': 3, 'steps': 733, 'reward': 0}\n",
      "{'score': 3, 'steps': 734, 'reward': 0}\n",
      "{'score': 3, 'steps': 735, 'reward': 0}\n",
      "{'score': 3, 'steps': 736, 'reward': 0}\n",
      "{'score': 3, 'steps': 737, 'reward': 0}\n",
      "{'score': 3, 'steps': 738, 'reward': 0}\n",
      "{'score': 3, 'steps': 739, 'reward': 0}\n",
      "{'score': 3, 'steps': 740, 'reward': 0}\n",
      "{'score': 3, 'steps': 741, 'reward': 0}\n",
      "{'score': 3, 'steps': 742, 'reward': 0}\n",
      "{'score': 3, 'steps': 743, 'reward': 0}\n",
      "{'score': 3, 'steps': 744, 'reward': 0}\n",
      "{'score': 3, 'steps': 745, 'reward': 0}\n",
      "{'score': 3, 'steps': 746, 'reward': 0}\n",
      "{'score': 3, 'steps': 747, 'reward': 0}\n",
      "{'score': 3, 'steps': 748, 'reward': 0}\n",
      "{'score': 3, 'steps': 749, 'reward': 0}\n",
      "{'score': 3, 'steps': 750, 'reward': 0}\n",
      "{'score': 3, 'steps': 751, 'reward': 0}\n",
      "{'score': 3, 'steps': 752, 'reward': 0}\n",
      "{'score': 3, 'steps': 753, 'reward': 0}\n",
      "{'score': 3, 'steps': 754, 'reward': 0}\n",
      "{'score': 3, 'steps': 755, 'reward': 0}\n",
      "{'score': 3, 'steps': 756, 'reward': 0}\n",
      "{'score': 3, 'steps': 757, 'reward': 0}\n",
      "{'score': 3, 'steps': 758, 'reward': 0}\n",
      "{'score': 3, 'steps': 759, 'reward': 0}\n",
      "{'score': 3, 'steps': 760, 'reward': 0}\n",
      "{'score': 3, 'steps': 761, 'reward': 0}\n",
      "{'score': 3, 'steps': 762, 'reward': 0}\n",
      "{'score': 3, 'steps': 763, 'reward': 0}\n",
      "{'score': 3, 'steps': 764, 'reward': 0}\n",
      "{'score': 3, 'steps': 765, 'reward': 0}\n",
      "{'score': 3, 'steps': 766, 'reward': 0}\n",
      "{'score': 3, 'steps': 767, 'reward': 0}\n",
      "{'score': 3, 'steps': 768, 'reward': 0}\n",
      "{'score': 3, 'steps': 769, 'reward': 0}\n",
      "{'score': 3, 'steps': 770, 'reward': 0}\n",
      "{'score': 3, 'steps': 771, 'reward': 0}\n",
      "{'score': 3, 'steps': 772, 'reward': 0}\n",
      "{'score': 3, 'steps': 773, 'reward': 0}\n",
      "{'score': 3, 'steps': 774, 'reward': 0}\n",
      "{'score': 3, 'steps': 775, 'reward': 0}\n",
      "{'score': 3, 'steps': 776, 'reward': 0}\n",
      "{'score': 3, 'steps': 777, 'reward': 0}\n",
      "{'score': 3, 'steps': 778, 'reward': 0}\n",
      "{'score': 3, 'steps': 779, 'reward': 0}\n",
      "{'score': 3, 'steps': 780, 'reward': 0}\n",
      "{'score': 3, 'steps': 781, 'reward': 0}\n",
      "{'score': 3, 'steps': 782, 'reward': 0}\n",
      "{'score': 3, 'steps': 783, 'reward': 0}\n",
      "{'score': 3, 'steps': 784, 'reward': 0}\n",
      "{'score': 3, 'steps': 785, 'reward': 0}\n",
      "{'score': 3, 'steps': 786, 'reward': 0}\n",
      "{'score': 3, 'steps': 787, 'reward': 0}\n",
      "{'score': 3, 'steps': 788, 'reward': 0}\n",
      "{'score': 3, 'steps': 789, 'reward': 0}\n",
      "{'score': 3, 'steps': 790, 'reward': 0}\n",
      "{'score': 3, 'steps': 791, 'reward': 0}\n",
      "{'score': 3, 'steps': 792, 'reward': 0}\n",
      "{'score': 3, 'steps': 793, 'reward': 0}\n",
      "{'score': 3, 'steps': 794, 'reward': 0}\n",
      "{'score': 3, 'steps': 795, 'reward': 0}\n",
      "{'score': 3, 'steps': 796, 'reward': 0}\n",
      "{'score': 3, 'steps': 797, 'reward': 0}\n",
      "{'score': 3, 'steps': 798, 'reward': 0}\n",
      "{'score': 3, 'steps': 799, 'reward': 0}\n",
      "{'score': 3, 'steps': 800, 'reward': 0}\n",
      "{'score': 3, 'steps': 801, 'reward': 0}\n",
      "{'score': 3, 'steps': 802, 'reward': 0}\n",
      "{'score': 3, 'steps': 803, 'reward': 0}\n",
      "{'score': 3, 'steps': 804, 'reward': 0}\n",
      "{'score': 3, 'steps': 805, 'reward': 0}\n",
      "{'score': 3, 'steps': 806, 'reward': 0}\n",
      "{'score': 3, 'steps': 807, 'reward': 0}\n",
      "{'score': 3, 'steps': 808, 'reward': 0}\n",
      "{'score': 3, 'steps': 809, 'reward': 0}\n",
      "{'score': 3, 'steps': 810, 'reward': 0}\n",
      "{'score': 3, 'steps': 811, 'reward': 0}\n",
      "{'score': 3, 'steps': 812, 'reward': 0}\n",
      "{'score': 3, 'steps': 813, 'reward': 0}\n",
      "{'score': 3, 'steps': 814, 'reward': 0}\n",
      "{'score': 3, 'steps': 815, 'reward': 0}\n",
      "{'score': 3, 'steps': 816, 'reward': 0}\n",
      "{'score': 3, 'steps': 817, 'reward': 0}\n",
      "{'score': 3, 'steps': 818, 'reward': 0}\n",
      "{'score': 3, 'steps': 819, 'reward': 0}\n",
      "{'score': 3, 'steps': 820, 'reward': 0}\n",
      "{'score': 3, 'steps': 821, 'reward': 0}\n",
      "{'score': 3, 'steps': 822, 'reward': 0}\n",
      "{'score': 3, 'steps': 823, 'reward': 0}\n",
      "{'score': 3, 'steps': 824, 'reward': 0}\n",
      "{'score': 3, 'steps': 825, 'reward': 0}\n",
      "{'score': 3, 'steps': 826, 'reward': 0}\n",
      "{'score': 3, 'steps': 827, 'reward': 0}\n",
      "{'score': 3, 'steps': 828, 'reward': 0}\n",
      "{'score': 3, 'steps': 829, 'reward': 0}\n",
      "{'score': 3, 'steps': 830, 'reward': 0}\n",
      "{'score': 6, 'steps': 831, 'reward': 3}\n",
      "{'score': 6, 'steps': 832, 'reward': 0}\n",
      "{'score': 6, 'steps': 833, 'reward': 0}\n",
      "{'score': 6, 'steps': 834, 'reward': 0}\n",
      "{'score': 6, 'steps': 835, 'reward': 0}\n",
      "{'score': 6, 'steps': 836, 'reward': 0}\n",
      "{'score': 6, 'steps': 837, 'reward': 0}\n",
      "{'score': 6, 'steps': 838, 'reward': 0}\n",
      "{'score': 6, 'steps': 839, 'reward': 0}\n",
      "{'score': 6, 'steps': 840, 'reward': 0}\n",
      "{'score': 6, 'steps': 841, 'reward': 0}\n",
      "{'score': 6, 'steps': 842, 'reward': 0}\n",
      "{'score': 6, 'steps': 843, 'reward': 0}\n",
      "{'score': 6, 'steps': 844, 'reward': 0}\n",
      "{'score': 6, 'steps': 845, 'reward': 0}\n",
      "{'score': 6, 'steps': 846, 'reward': 0}\n",
      "{'score': 6, 'steps': 847, 'reward': 0}\n",
      "{'score': 6, 'steps': 848, 'reward': 0}\n",
      "{'score': 6, 'steps': 849, 'reward': 0}\n",
      "{'score': 6, 'steps': 850, 'reward': 0}\n",
      "{'score': 6, 'steps': 851, 'reward': 0}\n",
      "{'score': 6, 'steps': 852, 'reward': 0}\n",
      "{'score': 6, 'steps': 853, 'reward': 0}\n",
      "{'score': 6, 'steps': 854, 'reward': 0}\n",
      "{'score': 6, 'steps': 855, 'reward': 0}\n",
      "{'score': 6, 'steps': 856, 'reward': 0}\n",
      "{'score': 6, 'steps': 857, 'reward': 0}\n",
      "{'score': 6, 'steps': 858, 'reward': 0}\n",
      "{'score': 6, 'steps': 859, 'reward': 0}\n",
      "{'score': 6, 'steps': 860, 'reward': 0}\n",
      "{'score': 6, 'steps': 861, 'reward': 0}\n",
      "{'score': 6, 'steps': 862, 'reward': 0}\n",
      "{'score': 6, 'steps': 863, 'reward': 0}\n",
      "{'score': 6, 'steps': 864, 'reward': 0}\n",
      "{'score': 6, 'steps': 865, 'reward': 0}\n",
      "{'score': 6, 'steps': 866, 'reward': 0}\n",
      "{'score': 6, 'steps': 867, 'reward': 0}\n",
      "{'score': 6, 'steps': 868, 'reward': 0}\n",
      "{'score': 6, 'steps': 869, 'reward': 0}\n",
      "{'score': 6, 'steps': 870, 'reward': 0}\n",
      "{'score': 6, 'steps': 871, 'reward': 0}\n",
      "{'score': 6, 'steps': 872, 'reward': 0}\n",
      "{'score': 6, 'steps': 873, 'reward': 0}\n",
      "{'score': 6, 'steps': 874, 'reward': 0}\n",
      "{'score': 6, 'steps': 875, 'reward': 0}\n",
      "{'score': 6, 'steps': 876, 'reward': 0}\n",
      "{'score': 6, 'steps': 877, 'reward': 0}\n",
      "{'score': 6, 'steps': 878, 'reward': 0}\n",
      "{'score': 6, 'steps': 879, 'reward': 0}\n",
      "{'score': 6, 'steps': 880, 'reward': 0}\n",
      "{'score': 6, 'steps': 881, 'reward': 0}\n",
      "{'score': 6, 'steps': 882, 'reward': 0}\n",
      "{'score': 6, 'steps': 883, 'reward': 0}\n",
      "{'score': 6, 'steps': 884, 'reward': 0}\n",
      "{'score': 6, 'steps': 885, 'reward': 0}\n",
      "{'score': 6, 'steps': 886, 'reward': 0}\n",
      "{'score': 6, 'steps': 887, 'reward': 0}\n",
      "{'score': 6, 'steps': 888, 'reward': 0}\n",
      "{'score': 6, 'steps': 889, 'reward': 0}\n",
      "{'score': 6, 'steps': 890, 'reward': 0}\n",
      "{'score': 6, 'steps': 891, 'reward': 0}\n",
      "{'score': 6, 'steps': 892, 'reward': 0}\n",
      "{'score': 6, 'steps': 893, 'reward': 0}\n",
      "{'score': 6, 'steps': 894, 'reward': 0}\n",
      "{'score': 6, 'steps': 895, 'reward': 0}\n",
      "{'score': 6, 'steps': 896, 'reward': 0}\n",
      "{'score': 6, 'steps': 897, 'reward': 0}\n",
      "{'score': 6, 'steps': 898, 'reward': 0}\n",
      "{'score': 6, 'steps': 899, 'reward': 0}\n",
      "{'score': 6, 'steps': 900, 'reward': 0}\n",
      "{'score': 6, 'steps': 901, 'reward': 0}\n",
      "{'score': 6, 'steps': 902, 'reward': 0}\n",
      "{'score': 6, 'steps': 903, 'reward': 0}\n",
      "{'score': 6, 'steps': 904, 'reward': 0}\n",
      "{'score': 6, 'steps': 905, 'reward': 0}\n",
      "{'score': 6, 'steps': 906, 'reward': 0}\n",
      "{'score': 6, 'steps': 907, 'reward': 0}\n",
      "{'score': 6, 'steps': 908, 'reward': 0}\n",
      "{'score': 6, 'steps': 909, 'reward': 0}\n",
      "{'score': 6, 'steps': 910, 'reward': 0}\n",
      "{'score': 6, 'steps': 911, 'reward': 0}\n",
      "{'score': 6, 'steps': 912, 'reward': 0}\n",
      "{'score': 6, 'steps': 913, 'reward': 0}\n",
      "{'score': 6, 'steps': 914, 'reward': 0}\n",
      "{'score': 6, 'steps': 915, 'reward': 0}\n",
      "{'score': 6, 'steps': 916, 'reward': 0}\n",
      "{'score': 6, 'steps': 917, 'reward': 0}\n",
      "{'score': 6, 'steps': 918, 'reward': 0}\n",
      "{'score': 6, 'steps': 919, 'reward': 0}\n",
      "{'score': 6, 'steps': 920, 'reward': 0}\n",
      "{'score': 6, 'steps': 921, 'reward': 0}\n",
      "{'score': 6, 'steps': 922, 'reward': 0}\n",
      "{'score': 6, 'steps': 923, 'reward': 0}\n",
      "{'score': 6, 'steps': 924, 'reward': 0}\n",
      "{'score': 6, 'steps': 925, 'reward': 0}\n",
      "{'score': 6, 'steps': 926, 'reward': 0}\n",
      "{'score': 6, 'steps': 927, 'reward': 0}\n",
      "{'score': 6, 'steps': 928, 'reward': 0}\n",
      "{'score': 6, 'steps': 929, 'reward': 0}\n",
      "{'score': 6, 'steps': 930, 'reward': 0}\n",
      "{'score': 6, 'steps': 931, 'reward': 0}\n",
      "{'score': 6, 'steps': 932, 'reward': 0}\n",
      "{'score': 6, 'steps': 933, 'reward': 0}\n",
      "{'score': 6, 'steps': 934, 'reward': 0}\n",
      "{'score': 6, 'steps': 935, 'reward': 0}\n",
      "{'score': 6, 'steps': 936, 'reward': 0}\n",
      "{'score': 6, 'steps': 937, 'reward': 0}\n",
      "{'score': 6, 'steps': 938, 'reward': 0}\n",
      "{'score': 6, 'steps': 939, 'reward': 0}\n",
      "{'score': 6, 'steps': 940, 'reward': 0}\n",
      "{'score': 6, 'steps': 941, 'reward': 0}\n",
      "{'score': 6, 'steps': 942, 'reward': 0}\n",
      "{'score': 6, 'steps': 943, 'reward': 0}\n",
      "{'score': 6, 'steps': 944, 'reward': 0}\n",
      "{'score': 6, 'steps': 945, 'reward': 0}\n",
      "{'score': 6, 'steps': 946, 'reward': 0}\n",
      "{'score': 6, 'steps': 947, 'reward': 0}\n",
      "{'score': 6, 'steps': 948, 'reward': 0}\n",
      "{'score': 6, 'steps': 949, 'reward': 0}\n",
      "{'score': 6, 'steps': 950, 'reward': 0}\n",
      "{'score': 6, 'steps': 951, 'reward': 0}\n",
      "{'score': 6, 'steps': 952, 'reward': 0}\n",
      "{'score': 6, 'steps': 953, 'reward': 0}\n",
      "{'score': 6, 'steps': 954, 'reward': 0}\n",
      "{'score': 6, 'steps': 955, 'reward': 0}\n",
      "{'score': 6, 'steps': 956, 'reward': 0}\n",
      "{'score': 6, 'steps': 957, 'reward': 0}\n",
      "{'score': 6, 'steps': 958, 'reward': 0}\n",
      "{'score': 6, 'steps': 959, 'reward': 0}\n",
      "{'score': 6, 'steps': 960, 'reward': 0}\n",
      "{'score': 6, 'steps': 961, 'reward': 0}\n",
      "{'score': 6, 'steps': 962, 'reward': 0}\n",
      "{'score': 6, 'steps': 963, 'reward': 0}\n",
      "{'score': 6, 'steps': 964, 'reward': 0}\n",
      "{'score': 6, 'steps': 965, 'reward': 0}\n",
      "{'score': 6, 'steps': 966, 'reward': 0}\n",
      "{'score': 6, 'steps': 967, 'reward': 0}\n",
      "{'score': 6, 'steps': 968, 'reward': 0}\n",
      "{'score': 6, 'steps': 969, 'reward': 0}\n",
      "{'score': 6, 'steps': 970, 'reward': 0}\n",
      "{'score': 6, 'steps': 971, 'reward': 0}\n",
      "{'score': 6, 'steps': 972, 'reward': 0}\n",
      "{'score': 6, 'steps': 973, 'reward': 0}\n",
      "{'score': 6, 'steps': 974, 'reward': 0}\n",
      "{'score': 6, 'steps': 975, 'reward': 0}\n",
      "{'score': 6, 'steps': 976, 'reward': 0}\n",
      "{'score': 6, 'steps': 977, 'reward': 0}\n",
      "{'score': 6, 'steps': 978, 'reward': 0}\n",
      "{'score': 6, 'steps': 979, 'reward': 0}\n",
      "{'score': 6, 'steps': 980, 'reward': 0}\n",
      "{'score': 6, 'steps': 981, 'reward': 0}\n",
      "{'score': 6, 'steps': 982, 'reward': 0}\n",
      "{'score': 6, 'steps': 983, 'reward': 0}\n",
      "{'score': 6, 'steps': 984, 'reward': 0}\n",
      "{'score': 6, 'steps': 985, 'reward': 0}\n",
      "{'score': 6, 'steps': 986, 'reward': 0}\n",
      "{'score': 6, 'steps': 987, 'reward': 0}\n",
      "{'score': 6, 'steps': 988, 'reward': 0}\n",
      "{'score': 6, 'steps': 989, 'reward': 0}\n",
      "{'score': 6, 'steps': 990, 'reward': 0}\n",
      "{'score': 6, 'steps': 991, 'reward': 0}\n",
      "{'score': 6, 'steps': 992, 'reward': 0}\n",
      "{'score': 6, 'steps': 993, 'reward': 0}\n",
      "{'score': 6, 'steps': 994, 'reward': 0}\n",
      "{'score': 6, 'steps': 995, 'reward': 0}\n",
      "{'score': 6, 'steps': 996, 'reward': 0}\n",
      "{'score': 6, 'steps': 997, 'reward': 0}\n",
      "{'score': 6, 'steps': 998, 'reward': 0}\n",
      "{'score': 6, 'steps': 999, 'reward': 0}\n",
      "{'score': 6, 'steps': 1000, 'reward': 0}\n",
      "      0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35\n",
      "   ------------------------------------------------------------------------------------------------------------\n",
      " 0 |  5  8  6  7  7  8  1  2  9  4  4  3  3  4  7  8  6  9  5  5  4  2  6  2  6  3  7  7  3  5  8  6  1  8  7  5\n",
      " 1 |  9  5  9  3  7  6  3  2  3  9  7  8  8  9  6  8  9  9  2  2  5  6  7  4  3  7  3  9  9  7  7  5  8  6  4  9\n",
      " 2 |  6  1  4  6  4  3  7  6  6  9  6  8  6  8  8  4  1  3  7  4  1  9  8  6  2  9  4  3  4  7  4  6  4  3  1  8\n",
      " 3 |  4  8  8  2  9  1  2  4  2  5  3  0  0  0  6  2  1  3  5  3  8  6  3  5  9  8  8  1  4  4  4  5  7  3  7  8\n",
      " 4 |  5  7  5  9  8  3  4  5  2  1  9  3  1  9  5  5  8  3  6  6  8  2  7  7  3  9  9  5  3  2  2  1  3  2  5  2\n",
      " 5 |  1  8  7  4  6  9  2  9  4  2  2  2  1  8  2  6  8  3  8  9  6  9  4  2  7  5  8  8  1  2  6  3  1  2  2  1\n",
      " 6 |  8  1  1  4  6  7  7  4  9  2  7  5  1  9  1  9  3  5  2  7  7  4  6  5  5  8  3  9  6  5  8  4  3  4  5  4\n",
      " 7 |  5  3  8  5  5  5  5  9  8  8  1  5  5  1  8  5  7  6  4  3  8  3  9  8  7  2  6  2  6  8  6  9  1  3  5  2\n",
      " 8 |  2  6  4  6  7  2  8  9  4  3  4  7  8  4  1  6  5  6  3  4  1  2  9  2  8  3  3  4  7  5  6  5  3  8  9  1\n",
      " 9 |  4  2  9  4  2  1  3  7  8  7  3  4  1  2  4  8  8  8  6  4  1  1  6  1  7  9  8  4  2  3  7  9  3  7  4  6\n",
      "10 |  5  8  9  7  3  1  5  1  3  9  8  2  7  2  4  4  2  9  1  4  8  2  8  3  6  2  8  1  1  4  2  5  8  2  1  1\n",
      "11 |  4  3  3  6  4  6  9  1  2  2  4  5  7  6  7  7  1  9  8  2  9  4  6  3  9  3  4  8  4  2  2  1  5  6  1  9\n",
      "12 |  2  8  7  5  6  8  1  5  7  7  6  4  4  2  6  5  8  6  7  6  7  4  6  6  9  5  6  6  9  6  5  4  2  9  6  6\n",
      "13 |  3  6  3  4  3  2  4  6  1  9  5  3  6  8  2  7  1  8  9  9  6  1  2  4  4  3  7  6  9  1  8  6  3  6  3  3\n",
      "14 |  9  5  1  4  5  1  4  5  8  4  9  7  3  1  3  5  9  4  4  3  2  4  9  4  5  7  5  6  1  7  2  6  4  9  2  1\n",
      "15 |  7  3  9  5  4  1  6  9  2  5  6  8  1  2  1  6  6  7  4  8  1  9  7  7  1  6  5  1  9  6  2  5  4  7  5  2\n",
      "16 |  5  9  8  7  6  1  4  2  5  6  1  9  5  7  6  9  6  2  5  1  8  3  2  8  8  9  7  3  9  5  3  3  7  9  3  4\n",
      "17 |  9  3  1  7  3  1  6  7  1  6  8  9  2  3  4  8  2  5  4  7  4  7  8  9  9  8  9  1  9  1  7  9  0  3  4  1\n",
      "18 |  2  3  5  9  4  5  6  4  5  9  9  7  7  9  7  8  5  4  2  7  7  6  5  4  6  3  3  6  8  3  5  3  0  9  9  9\n",
      "19 |  7  4  5  9  2  5  9  7  7  7  1  9  5  6  6  5  8  3  7  7  8  3  9  3  4  7  1  3  4  6  5  7  0  3  6  4\n",
      "20 |  8  4  2  8  5  5  5  6  2  7  1  2  4  6  4  4  9  8  4  2  9  5  2  9  2  3  8  4  5  3  9  9  3  8  4  4\n",
      "21 |  8  2  8  2  5  6  2  2  3  8  1  2  4  8  6  8  5  3  2  6  1  2  4  3  4  7  3  8  3  6  9  5  4  2  9  6\n",
      "22 |  8  7  9  9  3  4  3  4  5  9  5  1  8  6  6  3  5  7  6  1  4  4  5  6  8  9  9  5  2  2  1  7  6  7  9  1\n",
      "23 |  5  5  9  9  2  9  7  9  2  9  9  1  6  4  2  1  9  6  6  9  1  6  4  5  8  9  3  5  7  1  1  7  9  4  2  5\n",
      "24 |  8  2  9  4  3  2  8  5  8  5  8  1  2  7  2  9  7  3  1  2  6  3  1  2  6  5  7  2  9  6  3  3  9  6  9  6\n",
      "25 |  6  8  4  3  2  3  2  6  4  4  4  3  6  2  9  9  8  6  9  8  2  2  8  6  6  7  2  6  2  3  7  2  8  4  2  3\n",
      "26 |  2  4  3  4  6  9  5  1  4  5  2  2  4  2  9  2  7  5  8  6  6  8  2  1  3  6  1  6  5  8  6  2  8  6  2  1\n",
      "27 |  7  7  7  8  1  9  1  7  8  7  5  1  5  9  9  4  5  1  1  4  3  6  9  5  6  3  5  2  4  5  2  4  6  9  8  9\n",
      "28 |  1  3  9  4  3  6  4  7  4  8  5  6  8  5  5  2  1  1  4  1  4  9  7  9  3  7  8  7  7  8  5  6  3  2  7  6\n",
      "29 |  9  5  5  8  4  8  5  5  1  1  3  8  5  4  2  7  3  1  4  2  7  2  3  2  6  1  5  7  3  6  5  9  5  7  7  5\n",
      "30 |  9  4  5  2  7  7  4  3  6  8  3  9  8  9  9  3  6  7  2  6  1  2  7  9  3  8  3  8  6  8  7  5  5  5  6  8\n",
      "31 |  1  2  7  3  6  3  5  3  3  7  5  8  2  4  7  2  5  8  9  5  4  5  6  4  3  2  7  4  1  3  4  7  8  6  3  6\n",
      "32 |  3  5  4  5  6  6  2  2  6  8  8  9  6  1  1  4  8  3  4  4  8  9  2  2  5  8  7  8  6  8  6  6  1  4  9  1\n",
      "33 |  1  1  6  7  7  2  7  4  1  6  2  4  4  5  7  1  2  8  4  1  5  5  7  8  7  3  6  8  3  9  7  2  6  9  8  9\n",
      "34 |  8  4  1  7  9  9  9  5  7  7  9  2  1  8  4  9  8  3  4  9  5  7  2  8  6  3  1  5  2  6  2  7  3  8  7  7\n",
      "35 |  1  2  6  5  9  1  3  1  7  4  8  6  9  2  1  5  5  8  5  9  4  5  2  6  2  8  4  6  7  2  7  7  1  4  5  5\n",
      "남은 스텝:  0\n",
      "점수:  6\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "env.reset(seed=seed)\n",
    "env.action_space.seed(seed)\n",
    "\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    print(info)\n",
    "    done = terminated or truncated\n",
    "\n",
    "env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "train_env = AppleGameEnv(m=36, n=36, max_steps=1000)\n",
    "\n",
    "model = PPO(\"CnnPolicy\", train_env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ../tmp/logs/1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 5.5      |\n",
      "| time/              |          |\n",
      "|    fps             | 4995     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 2.75          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 898           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00856844    |\n",
      "|    clip_fraction        | 0.0468        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.68         |\n",
      "|    explained_variance   | -0.0004749298 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0206        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00302      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.159         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008673143 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.72743005  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0133      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 9.39e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064226408 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.012824535  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00974      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 0.052        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chiyeong/Documents/projects/Mentoring-RL-Env/.venv/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004568476 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.016076446 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0183     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 0.0165      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.08         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046160715 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.61        |\n",
      "|    explained_variance   | 0.0036671162 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0231      |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 0.0368       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.79          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 509           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008670973   |\n",
      "|    clip_fraction        | 0.0479        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.58         |\n",
      "|    explained_variance   | -0.0013247728 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.004         |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    std                  | 0.97          |\n",
      "|    value_loss           | 0.0328        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.81         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059346957 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.55        |\n",
      "|    explained_variance   | 0.015996218  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000982    |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    std                  | 0.968        |\n",
      "|    value_loss           | 0.03         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 506        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00588894 |\n",
      "|    clip_fraction        | 0.0576     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.54      |\n",
      "|    explained_variance   | 0.8086447  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0135    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.00449   |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 0.000525   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004158807 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.008821189 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0491      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 0.0648      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.65     |\n",
      "| time/              |          |\n",
      "|    fps             | 490      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 491         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009104876 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.7755108   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    std                  | 0.957       |\n",
      "|    value_loss           | 0.000164    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.38         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 490          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070431186 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.49        |\n",
      "|    explained_variance   | 0.5760317    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0237       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 0.000119     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009752125 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | -0.0196172  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00109     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.000288   |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 6.84e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 486         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711591 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.4380089   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 3.94e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008125162  |\n",
      "|    clip_fraction        | 0.0749       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.56        |\n",
      "|    explained_variance   | -0.009254932 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.51e-06     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 3.46e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 479      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 481          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004009638  |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.55        |\n",
      "|    explained_variance   | 0.0057626963 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00302      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 0.0153       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.18         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 481          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046326434 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.51        |\n",
      "|    explained_variance   | 0.0010101795 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0138       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 0.0522       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 480          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036778322 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.47        |\n",
      "|    explained_variance   | 0.015018582  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00375      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    std                  | 0.947        |\n",
      "|    value_loss           | 0.0163       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.24         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 479          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036154399 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.44        |\n",
      "|    explained_variance   | 0.03545791   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0393       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 0.032        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062413965 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.41        |\n",
      "|    explained_variance   | 0.017562628  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0154       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    std                  | 0.933        |\n",
      "|    value_loss           | 0.0328       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 474      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.42        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006450909 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.030634701 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.076       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 0.0991      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.36         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006403588  |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.38        |\n",
      "|    explained_variance   | -0.006643057 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0129      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    std                  | 0.926        |\n",
      "|    value_loss           | 0.0522       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.3          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077149225 |\n",
      "|    clip_fraction        | 0.0567       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.37        |\n",
      "|    explained_variance   | 0.38111466   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00611     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    std                  | 0.927        |\n",
      "|    value_loss           | 0.000158     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006012151 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.31591588  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0165      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 9.6e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1e+03         |\n",
      "|    mean_reward          | 0             |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 50000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0070013944  |\n",
      "|    clip_fraction        | 0.0431        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.36         |\n",
      "|    explained_variance   | -0.0021336079 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0913        |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.00328      |\n",
      "|    std                  | 0.921         |\n",
      "|    value_loss           | 0.0684        |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.39     |\n",
      "| time/              |          |\n",
      "|    fps             | 474      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 107      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 473          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050054295 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.34        |\n",
      "|    explained_variance   | 0.01864165   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000201     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 0.0371       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.36         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 472          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.003252344  |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.34        |\n",
      "|    explained_variance   | -0.018195152 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.049        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    std                  | 0.922        |\n",
      "|    value_loss           | 0.0654       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009065148 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.7974292   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.000125    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 471          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006355229  |\n",
      "|    clip_fraction        | 0.073        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.37        |\n",
      "|    explained_variance   | -0.021464229 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00957      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 0.0166       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059727104 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.36        |\n",
      "|    explained_variance   | 0.009521961  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0324       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    std                  | 0.922        |\n",
      "|    value_loss           | 0.0152       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.3      |\n",
      "| time/              |          |\n",
      "|    fps             | 468      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006591619 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.62364703  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0165     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 7.54e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 469         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006130104 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.20872408  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00226    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 6.54e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 470        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00835075 |\n",
      "|    clip_fraction        | 0.0812     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.35      |\n",
      "|    explained_variance   | 0.6349405  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00113   |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00671   |\n",
      "|    std                  | 0.926      |\n",
      "|    value_loss           | 5.46e-05   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.23          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 471           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 147           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.004471831   |\n",
      "|    clip_fraction        | 0.0229        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.37         |\n",
      "|    explained_variance   | -0.0055943727 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.106         |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -4.95e-05     |\n",
      "|    std                  | 0.926         |\n",
      "|    value_loss           | 0.0819        |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005731877 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.2201181   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 0.932       |\n",
      "|    value_loss           | 8.89e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 469      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 152      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006013912 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.008790076 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.015       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.000846   |\n",
      "|    std                  | 0.93        |\n",
      "|    value_loss           | 0.037       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.23         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 470          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067471126 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.35        |\n",
      "|    explained_variance   | -0.04056728  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0296       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    std                  | 0.917        |\n",
      "|    value_loss           | 0.029        |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1e+03          |\n",
      "|    ep_rew_mean          | 1.29           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 471            |\n",
      "|    iterations           | 38             |\n",
      "|    time_elapsed         | 165            |\n",
      "|    total_timesteps      | 77824          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.007220512    |\n",
      "|    clip_fraction        | 0.0717         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -5.3           |\n",
      "|    explained_variance   | -0.00020635128 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.0376         |\n",
      "|    n_updates            | 370            |\n",
      "|    policy_gradient_loss | -0.0055        |\n",
      "|    std                  | 0.906          |\n",
      "|    value_loss           | 0.0975         |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009911928 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.26       |\n",
      "|    explained_variance   | 0.060002565 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00477     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045065866 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.23        |\n",
      "|    explained_variance   | 0.047495484  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0221       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    std                  | 0.895        |\n",
      "|    value_loss           | 0.0128       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 469      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.3          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069341143 |\n",
      "|    clip_fraction        | 0.0917       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.23        |\n",
      "|    explained_variance   | 0.5523483    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0132       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    std                  | 0.895        |\n",
      "|    value_loss           | 0.00026      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005626778 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.2        |\n",
      "|    explained_variance   | -0.01102066 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0768      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 0.0521      |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1e+03          |\n",
      "|    ep_rew_mean          | 1.45           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 470            |\n",
      "|    iterations           | 43             |\n",
      "|    time_elapsed         | 187            |\n",
      "|    total_timesteps      | 88064          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.006186636    |\n",
      "|    clip_fraction        | 0.0574         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -5.13          |\n",
      "|    explained_variance   | -0.00053429604 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.02           |\n",
      "|    n_updates            | 420            |\n",
      "|    policy_gradient_loss | -0.00477       |\n",
      "|    std                  | 0.869          |\n",
      "|    value_loss           | 0.0839         |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1e+03         |\n",
      "|    mean_reward          | 0             |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 90000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0045744847  |\n",
      "|    clip_fraction        | 0.0308        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.09         |\n",
      "|    explained_variance   | 0.00027352571 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.132         |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.00281      |\n",
      "|    std                  | 0.86          |\n",
      "|    value_loss           | 0.13          |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.44     |\n",
      "| time/              |          |\n",
      "|    fps             | 468      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 192      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.41         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062966323 |\n",
      "|    clip_fraction        | 0.059        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.06        |\n",
      "|    explained_variance   | -0.009590387 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0134       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 0.859        |\n",
      "|    value_loss           | 0.0168       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005849177 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.08       |\n",
      "|    explained_variance   | 0.06401539  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00514    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    std                  | 0.869       |\n",
      "|    value_loss           | 0.000296    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 470        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01841349 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.13      |\n",
      "|    explained_variance   | 0.18635356 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00747    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00743   |\n",
      "|    std                  | 0.878      |\n",
      "|    value_loss           | 0.000182   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.43        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008826371 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.31482863  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0226     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 0.872       |\n",
      "|    value_loss           | 0.000126    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010295954  |\n",
      "|    clip_fraction        | 0.0943       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.1         |\n",
      "|    explained_variance   | 0.0015473962 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.199        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    std                  | 0.863        |\n",
      "|    value_loss           | 0.137        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.42     |\n",
      "| time/              |          |\n",
      "|    fps             | 469      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 213      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 469         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003983204 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.08       |\n",
      "|    explained_variance   | 0.039627075 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0158      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    std                  | 0.862       |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.38          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 470           |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 222           |\n",
      "|    total_timesteps      | 104448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0105516575  |\n",
      "|    clip_fraction        | 0.101         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.05         |\n",
      "|    explained_variance   | -0.0069903135 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0834        |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | -0.00417      |\n",
      "|    std                  | 0.853         |\n",
      "|    value_loss           | 0.067         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.35         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 470          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079515185 |\n",
      "|    clip_fraction        | 0.0932       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | -0.021287799 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0188      |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 0.0162       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 471        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 230        |\n",
      "|    total_timesteps      | 108544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00816772 |\n",
      "|    clip_fraction        | 0.0679     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.98      |\n",
      "|    explained_variance   | 0.2230478  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00867    |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.00391   |\n",
      "|    std                  | 0.843      |\n",
      "|    value_loss           | 0.000263   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=0.60 +/- 1.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1e+03         |\n",
      "|    mean_reward          | 0.6           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 110000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008362995   |\n",
      "|    clip_fraction        | 0.0831        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5            |\n",
      "|    explained_variance   | -0.0018359423 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00694      |\n",
      "|    n_updates            | 530           |\n",
      "|    policy_gradient_loss | -0.00376      |\n",
      "|    std                  | 0.849         |\n",
      "|    value_loss           | 0.0166        |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.36     |\n",
      "| time/              |          |\n",
      "|    fps             | 469      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.36         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008886369  |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | -0.001885891 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0544       |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    std                  | 0.851        |\n",
      "|    value_loss           | 0.048        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010165595 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | -0.02050519 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0112      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    std                  | 0.846       |\n",
      "|    value_loss           | 0.0182      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.38         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 470          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032752603 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | -0.005644202 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0435       |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 0.841        |\n",
      "|    value_loss           | 0.065        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007617717 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.34391457  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00409    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 0.000204    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1e+03         |\n",
      "|    mean_reward          | 0             |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 120000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0073019043  |\n",
      "|    clip_fraction        | 0.0569        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.02         |\n",
      "|    explained_variance   | -0.0033626556 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00868       |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -0.00301      |\n",
      "|    std                  | 0.852         |\n",
      "|    value_loss           | 0.0166        |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.44     |\n",
      "| time/              |          |\n",
      "|    fps             | 468      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 257      |\n",
      "|    total_timesteps | 120832   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.47          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 468           |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 262           |\n",
      "|    total_timesteps      | 122880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006107069   |\n",
      "|    clip_fraction        | 0.0675        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.99         |\n",
      "|    explained_variance   | -0.0044339895 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0604        |\n",
      "|    n_updates            | 590           |\n",
      "|    policy_gradient_loss | -0.00384      |\n",
      "|    std                  | 0.84          |\n",
      "|    value_loss           | 0.0867        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.49         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 468          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087060705 |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.93        |\n",
      "|    explained_variance   | 0.016505957  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00463      |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    std                  | 0.826        |\n",
      "|    value_loss           | 0.0534       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.53        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005284326 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.009141743 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00112     |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    std                  | 0.827       |\n",
      "|    value_loss           | 0.0167      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.53        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003976017 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.03674239  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    std                  | 0.827       |\n",
      "|    value_loss           | 0.0126      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 130000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068981834 |\n",
      "|    clip_fraction        | 0.0738       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | -0.009800196 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0166       |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 0.0169       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.56     |\n",
      "| time/              |          |\n",
      "|    fps             | 465      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 281      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.53         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 286          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065662516 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.0011860132 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0145       |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.827        |\n",
      "|    value_loss           | 0.0539       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 290          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050749606 |\n",
      "|    clip_fraction        | 0.0356       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.24201548   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0113      |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 0.000246     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006295098 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | -0.01499331 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0445      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.81        |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.55        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004041002 |\n",
      "|    clip_fraction        | 0.0288      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.07078898  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    std                  | 0.807       |\n",
      "|    value_loss           | 0.0543      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006732242 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.61779356  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00471     |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    std                  | 0.809       |\n",
      "|    value_loss           | 0.000255    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.56     |\n",
      "| time/              |          |\n",
      "|    fps             | 463      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 305      |\n",
      "|    total_timesteps | 141312   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.53          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 462           |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 309           |\n",
      "|    total_timesteps      | 143360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0061758333  |\n",
      "|    clip_fraction        | 0.0458        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.79         |\n",
      "|    explained_variance   | -0.0082633495 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0903        |\n",
      "|    n_updates            | 690           |\n",
      "|    policy_gradient_loss | -0.00352      |\n",
      "|    std                  | 0.801         |\n",
      "|    value_loss           | 0.136         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.53        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 463         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005898246 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | -0.02468896 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00979    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.796       |\n",
      "|    value_loss           | 0.0164      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.55         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065078177 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75        |\n",
      "|    explained_variance   | -0.015186548 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0267      |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.797        |\n",
      "|    value_loss           | 0.0159       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.51         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 323          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066043017 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.77        |\n",
      "|    explained_variance   | 0.704157     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00202     |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    std                  | 0.802        |\n",
      "|    value_loss           | 0.000197     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.003554766  |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.76        |\n",
      "|    explained_variance   | 0.0066678524 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00279      |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    std                  | 0.794        |\n",
      "|    value_loss           | 0.0371       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.48     |\n",
      "| time/              |          |\n",
      "|    fps             | 460      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 328      |\n",
      "|    total_timesteps | 151552   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 460         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005958385 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.42876428  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00173     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.791       |\n",
      "|    value_loss           | 9.78e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.51         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 337          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006226871  |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | -0.016909242 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0561       |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    std                  | 0.785        |\n",
      "|    value_loss           | 0.0655       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.49         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 341          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047130543 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.69        |\n",
      "|    explained_variance   | 0.19014895   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00744     |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    std                  | 0.783        |\n",
      "|    value_loss           | 0.016        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.51          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 461           |\n",
      "|    iterations           | 78            |\n",
      "|    time_elapsed         | 345           |\n",
      "|    total_timesteps      | 159744        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008452981   |\n",
      "|    clip_fraction        | 0.0664        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.65         |\n",
      "|    explained_variance   | -0.0121177435 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000545     |\n",
      "|    n_updates            | 770           |\n",
      "|    policy_gradient_loss | -0.00516      |\n",
      "|    std                  | 0.774         |\n",
      "|    value_loss           | 0.0311        |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042952094 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.6765436    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00434      |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    std                  | 0.78         |\n",
      "|    value_loss           | 0.000281     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.51     |\n",
      "| time/              |          |\n",
      "|    fps             | 461      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 350      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.51         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 355          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076036174 |\n",
      "|    clip_fraction        | 0.054        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.5563071    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00649     |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00765     |\n",
      "|    std                  | 0.792        |\n",
      "|    value_loss           | 0.000115     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 461         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008043457 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.4296208   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00575    |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    std                  | 0.789       |\n",
      "|    value_loss           | 6.52e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.63        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004183712 |\n",
      "|    clip_fraction        | 0.0288      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.71       |\n",
      "|    explained_variance   | 0.017411947 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0814      |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    std                  | 0.788       |\n",
      "|    value_loss           | 0.0922      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004042779 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.016666532 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.777       |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 1e+03          |\n",
      "|    mean_reward          | 0              |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 170000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00892802     |\n",
      "|    clip_fraction        | 0.041          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -4.62          |\n",
      "|    explained_variance   | -0.00053572655 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.0668         |\n",
      "|    n_updates            | 830            |\n",
      "|    policy_gradient_loss | -0.00355       |\n",
      "|    std                  | 0.769          |\n",
      "|    value_loss           | 0.0834         |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.67     |\n",
      "| time/              |          |\n",
      "|    fps             | 461      |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 372      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.75         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 376          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011699123  |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.61        |\n",
      "|    explained_variance   | -0.016180992 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0051       |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    std                  | 0.772        |\n",
      "|    value_loss           | 0.0167       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006621737 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.015568197 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0435      |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    std                  | 0.77        |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.74        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006989779 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.058609605 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0042      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 0.768       |\n",
      "|    value_loss           | 0.0371      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 180000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071260724 |\n",
      "|    clip_fraction        | 0.0805       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.57        |\n",
      "|    explained_variance   | 0.013649881  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0114       |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    std                  | 0.757        |\n",
      "|    value_loss           | 0.102        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.79     |\n",
      "| time/              |          |\n",
      "|    fps             | 461      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 390      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.83         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 394          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005975025  |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.5         |\n",
      "|    explained_variance   | -0.008901477 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00776     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    std                  | 0.742        |\n",
      "|    value_loss           | 0.0532       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008988224 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.002979815 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    std                  | 0.74        |\n",
      "|    value_loss           | 0.0316      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.74         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 402          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055784252 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.42        |\n",
      "|    explained_variance   | 0.07632136   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0404       |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    std                  | 0.729        |\n",
      "|    value_loss           | 0.0166       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.7          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 406          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068941023 |\n",
      "|    clip_fraction        | 0.0654       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.38        |\n",
      "|    explained_variance   | -0.005867243 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0537       |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.73         |\n",
      "|    value_loss           | 0.0721       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 190000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00687219   |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.38        |\n",
      "|    explained_variance   | -0.030248404 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0159       |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 0.728        |\n",
      "|    value_loss           | 0.0322       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.68     |\n",
      "| time/              |          |\n",
      "|    fps             | 462      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 412      |\n",
      "|    total_timesteps | 190464   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006082532 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.38       |\n",
      "|    explained_variance   | 0.58028066  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    std                  | 0.73        |\n",
      "|    value_loss           | 0.000204    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 420          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064365882 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.38        |\n",
      "|    explained_variance   | 0.008149564  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.038        |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    std                  | 0.728        |\n",
      "|    value_loss           | 0.0529       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 424          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076360893 |\n",
      "|    clip_fraction        | 0.0909       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.36        |\n",
      "|    explained_variance   | 0.47946262   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0117      |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00779     |\n",
      "|    std                  | 0.725        |\n",
      "|    value_loss           | 0.000191     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.65        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 463         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008727292 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.37       |\n",
      "|    explained_variance   | 0.5030495   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00604    |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    std                  | 0.729       |\n",
      "|    value_loss           | 0.000102    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038378797 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.37        |\n",
      "|    explained_variance   | -0.026917815 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0196       |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.726        |\n",
      "|    value_loss           | 0.0164       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.63     |\n",
      "| time/              |          |\n",
      "|    fps             | 462      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 433      |\n",
      "|    total_timesteps | 200704   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 438          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075298874 |\n",
      "|    clip_fraction        | 0.0696       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.35        |\n",
      "|    explained_variance   | 0.002490759  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00468     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 0.72         |\n",
      "|    value_loss           | 0.0162       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.65         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 442          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058981446 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.31        |\n",
      "|    explained_variance   | 0.011131048  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0407       |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    std                  | 0.712        |\n",
      "|    value_loss           | 0.0434       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.67         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 446          |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061122403 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.27        |\n",
      "|    explained_variance   | -0.006980419 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0013       |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    std                  | 0.706        |\n",
      "|    value_loss           | 0.0316       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.65        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 463         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005849041 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.03738171  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 0.0165      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 210000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065068514 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.22        |\n",
      "|    explained_variance   | 0.8016213    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00976     |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    std                  | 0.703        |\n",
      "|    value_loss           | 0.000143     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.68     |\n",
      "| time/              |          |\n",
      "|    fps             | 463      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 455      |\n",
      "|    total_timesteps | 210944   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.69          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 463           |\n",
      "|    iterations           | 104           |\n",
      "|    time_elapsed         | 459           |\n",
      "|    total_timesteps      | 212992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00753233    |\n",
      "|    clip_fraction        | 0.055         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.18         |\n",
      "|    explained_variance   | -0.0022848845 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0493        |\n",
      "|    n_updates            | 1030          |\n",
      "|    policy_gradient_loss | -0.00309      |\n",
      "|    std                  | 0.689         |\n",
      "|    value_loss           | 0.151         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.67         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 463          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008942053  |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.14        |\n",
      "|    explained_variance   | -0.010058641 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0103       |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    std                  | 0.687        |\n",
      "|    value_loss           | 0.0146       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 463         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006259333 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.024833262 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00645     |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.000436   |\n",
      "|    std                  | 0.683       |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.68         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 472          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008706632  |\n",
      "|    clip_fraction        | 0.0908       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.08        |\n",
      "|    explained_variance   | -0.026257277 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0104      |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    std                  | 0.675        |\n",
      "|    value_loss           | 0.0165       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008210748 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.018243909 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00778     |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    std                  | 0.671       |\n",
      "|    value_loss           | 0.0371      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.64     |\n",
      "| time/              |          |\n",
      "|    fps             | 463      |\n",
      "|    iterations      | 108      |\n",
      "|    time_elapsed    | 477      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.64          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 463           |\n",
      "|    iterations           | 109           |\n",
      "|    time_elapsed         | 481           |\n",
      "|    total_timesteps      | 223232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0065226364  |\n",
      "|    clip_fraction        | 0.0491        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.01         |\n",
      "|    explained_variance   | -0.0077120066 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0107       |\n",
      "|    n_updates            | 1080          |\n",
      "|    policy_gradient_loss | -0.00246      |\n",
      "|    std                  | 0.661         |\n",
      "|    value_loss           | 0.0311        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 463         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006122415 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.09375906  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0656      |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    std                  | 0.661       |\n",
      "|    value_loss           | 0.0371      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 490          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062334444 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.96        |\n",
      "|    explained_variance   | 0.016624868  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0759       |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    std                  | 0.656        |\n",
      "|    value_loss           | 0.196        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.78         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 464          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 494          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047757095 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.029444218  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0181      |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.000647    |\n",
      "|    std                  | 0.652        |\n",
      "|    value_loss           | 0.0166       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1e+03         |\n",
      "|    mean_reward          | 0             |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 230000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0059214816  |\n",
      "|    clip_fraction        | 0.0407        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.92         |\n",
      "|    explained_variance   | -0.0084193945 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.039         |\n",
      "|    n_updates            | 1120          |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    std                  | 0.65          |\n",
      "|    value_loss           | 0.068         |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.73     |\n",
      "| time/              |          |\n",
      "|    fps             | 463      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 499      |\n",
      "|    total_timesteps | 231424   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 463         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008125452 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.60160136  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00607    |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.000817   |\n",
      "|    std                  | 0.65        |\n",
      "|    value_loss           | 0.000273    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 1.79          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 462           |\n",
      "|    iterations           | 115           |\n",
      "|    time_elapsed         | 508           |\n",
      "|    total_timesteps      | 235520        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008098144   |\n",
      "|    clip_fraction        | 0.104         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.91         |\n",
      "|    explained_variance   | -5.507469e-05 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0291        |\n",
      "|    n_updates            | 1140          |\n",
      "|    policy_gradient_loss | -0.00488      |\n",
      "|    std                  | 0.649         |\n",
      "|    value_loss           | 0.0883        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 513         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008419687 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.52798927  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0283     |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    std                  | 0.65        |\n",
      "|    value_loss           | 0.000403    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.81         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 517          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062102326 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.89        |\n",
      "|    explained_variance   | 0.010704815  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0052      |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    std                  | 0.643        |\n",
      "|    value_loss           | 0.0614       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058604227 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.85        |\n",
      "|    explained_variance   | -0.011488557 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.03         |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000573    |\n",
      "|    std                  | 0.634        |\n",
      "|    value_loss           | 0.0373       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 461      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 523      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.8          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 527          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073144664 |\n",
      "|    clip_fraction        | 0.0633       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.8         |\n",
      "|    explained_variance   | 0.01350528   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.118        |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    std                  | 0.628        |\n",
      "|    value_loss           | 0.102        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.86        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 461         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007888262 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.112018704 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    std                  | 0.623       |\n",
      "|    value_loss           | 0.0158      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 461         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006073119 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | -0.0151546  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    std                  | 0.622       |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.93         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004911519  |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.0055586696 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0155       |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    std                  | 0.619        |\n",
      "|    value_loss           | 0.1          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006213831 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | -0.01981461 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0333      |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 0.61        |\n",
      "|    value_loss           | 0.0625      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.99     |\n",
      "| time/              |          |\n",
      "|    fps             | 460      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 546      |\n",
      "|    total_timesteps | 251904   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.03         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 460          |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 551          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008714771  |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | -0.013310194 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00136     |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    std                  | 0.602        |\n",
      "|    value_loss           | 0.0168       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 460         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 555         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006670087 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.009502351 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    std                  | 0.596       |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 460         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 560         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005419515 |\n",
      "|    clip_fraction        | 0.034       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | -0.3901714  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.017      |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    std                  | 0.6         |\n",
      "|    value_loss           | 0.000714    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 260000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070260894 |\n",
      "|    clip_fraction        | 0.0931       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.54        |\n",
      "|    explained_variance   | -0.003788352 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0134       |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    std                  | 0.59         |\n",
      "|    value_loss           | 0.178        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 459      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 565      |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.11         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 570          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076510543 |\n",
      "|    clip_fraction        | 0.0875       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.00931263   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0235       |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    std                  | 0.586        |\n",
      "|    value_loss           | 0.0169       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 460         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 574         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009532277 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.5225254   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    std                  | 0.59        |\n",
      "|    value_loss           | 0.000266    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 578         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011323431 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.55382305  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.017      |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    std                  | 0.589       |\n",
      "|    value_loss           | 0.000251    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002958241 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.092602074 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0123     |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.000118   |\n",
      "|    std                  | 0.59        |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 270000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084364675 |\n",
      "|    clip_fraction        | 0.0978       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.015364945  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0195       |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.582        |\n",
      "|    value_loss           | 0.0534       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.97     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 589      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 1.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 594          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055605164 |\n",
      "|    clip_fraction        | 0.0373       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.42        |\n",
      "|    explained_variance   | 0.016696274  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0228       |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    std                  | 0.571        |\n",
      "|    value_loss           | 0.0802       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012586069 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.020523548 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000293   |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    std                  | 0.563       |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.04         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 602          |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077086445 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.3         |\n",
      "|    explained_variance   | 0.014134705  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.011       |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    std                  | 0.556        |\n",
      "|    value_loss           | 0.0518       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010003561 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.008188069 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    std                  | 0.56        |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005683502 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.038434207 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0746      |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    std                  | 0.557       |\n",
      "|    value_loss           | 0.0362      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.99     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 612      |\n",
      "|    total_timesteps | 280576   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00445598  |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.014121413 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0063     |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    std                  | 0.553       |\n",
      "|    value_loss           | 0.0331      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.03         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 620          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057524517 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.23        |\n",
      "|    explained_variance   | 0.021351337  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00424     |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | 0.000264     |\n",
      "|    std                  | 0.547        |\n",
      "|    value_loss           | 0.0534       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.07         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 624          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048322976 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.2         |\n",
      "|    explained_variance   | -0.04026282  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0152       |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.000975    |\n",
      "|    std                  | 0.545        |\n",
      "|    value_loss           | 0.0525       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 2.09          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 459           |\n",
      "|    iterations           | 141           |\n",
      "|    time_elapsed         | 628           |\n",
      "|    total_timesteps      | 288768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008684217   |\n",
      "|    clip_fraction        | 0.0439        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.15         |\n",
      "|    explained_variance   | -0.0035669804 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00885       |\n",
      "|    n_updates            | 1400          |\n",
      "|    policy_gradient_loss | -0.00358      |\n",
      "|    std                  | 0.535         |\n",
      "|    value_loss           | 0.114         |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 290000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010561109 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.0212636   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0166      |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 0.531       |\n",
      "|    value_loss           | 0.0694      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 634      |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007863694 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.08       |\n",
      "|    explained_variance   | 0.009513497 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0544      |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 0.529       |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.3          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 642          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058108135 |\n",
      "|    clip_fraction        | 0.0663       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.05        |\n",
      "|    explained_variance   | 0.00682956   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0544       |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    std                  | 0.522        |\n",
      "|    value_loss           | 0.0662       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.3          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 646          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076639145 |\n",
      "|    clip_fraction        | 0.0799       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.06        |\n",
      "|    explained_variance   | 0.23775339   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0112      |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    std                  | 0.529        |\n",
      "|    value_loss           | 0.000971     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 650         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005434075 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | 0.15101826  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00505     |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    std                  | 0.53        |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062404587 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.07        |\n",
      "|    explained_variance   | -0.009171605 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0324      |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    std                  | 0.524        |\n",
      "|    value_loss           | 0.0377       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 459      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 655      |\n",
      "|    total_timesteps | 301056   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 660         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007974001 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.10214883  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0042     |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.000307   |\n",
      "|    std                  | 0.522       |\n",
      "|    value_loss           | 0.0169      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.37         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 149          |\n",
      "|    time_elapsed         | 664          |\n",
      "|    total_timesteps      | 305152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077940207 |\n",
      "|    clip_fraction        | 0.0746       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3           |\n",
      "|    explained_variance   | 0.0058953166 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0528       |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    std                  | 0.515        |\n",
      "|    value_loss           | 0.115        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 2.35          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 459           |\n",
      "|    iterations           | 150           |\n",
      "|    time_elapsed         | 668           |\n",
      "|    total_timesteps      | 307200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011349915   |\n",
      "|    clip_fraction        | 0.0978        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.93         |\n",
      "|    explained_variance   | 0.00034493208 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0249       |\n",
      "|    n_updates            | 1490          |\n",
      "|    policy_gradient_loss | -0.00373      |\n",
      "|    std                  | 0.504         |\n",
      "|    value_loss           | 0.033         |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 2.42       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 459        |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 672        |\n",
      "|    total_timesteps      | 309248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00746812 |\n",
      "|    clip_fraction        | 0.0861     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.89      |\n",
      "|    explained_variance   | 0.70431054 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00117    |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | -0.00258   |\n",
      "|    std                  | 0.504      |\n",
      "|    value_loss           | 0.000333   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005203278 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.006695509 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0442      |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    std                  | 0.503       |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.33     |\n",
      "| time/              |          |\n",
      "|    fps             | 459      |\n",
      "|    iterations      | 152      |\n",
      "|    time_elapsed    | 677      |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006585564 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.71087873  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0176     |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.503       |\n",
      "|    value_loss           | 0.000665    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.39         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 154          |\n",
      "|    time_elapsed         | 686          |\n",
      "|    total_timesteps      | 315392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065174485 |\n",
      "|    clip_fraction        | 0.0681       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | 0.26838458   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00192     |\n",
      "|    n_updates            | 1530         |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    std                  | 0.507        |\n",
      "|    value_loss           | 0.000217     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1e+03         |\n",
      "|    ep_rew_mean          | 2.39          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 459           |\n",
      "|    iterations           | 155           |\n",
      "|    time_elapsed         | 690           |\n",
      "|    total_timesteps      | 317440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009021494   |\n",
      "|    clip_fraction        | 0.0901        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.89         |\n",
      "|    explained_variance   | -0.0012669563 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.173         |\n",
      "|    n_updates            | 1540          |\n",
      "|    policy_gradient_loss | -0.00494      |\n",
      "|    std                  | 0.502         |\n",
      "|    value_loss           | 0.13          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012385201 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.6986451   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00195    |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    std                  | 0.507       |\n",
      "|    value_loss           | 0.000414    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008145825  |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | -0.013490081 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0243       |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    std                  | 0.499        |\n",
      "|    value_loss           | 0.0372       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.4      |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 701      |\n",
      "|    total_timesteps | 321536   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 705         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007022855 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.013470173 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    std                  | 0.491       |\n",
      "|    value_loss           | 0.0529      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.41         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 709          |\n",
      "|    total_timesteps      | 325632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059946235 |\n",
      "|    clip_fraction        | 0.0875       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.027613997  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00941     |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.000923    |\n",
      "|    std                  | 0.485        |\n",
      "|    value_loss           | 0.0163       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.41         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 713          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075648525 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0.037822902  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0394       |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    std                  | 0.481        |\n",
      "|    value_loss           | 0.139        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 718         |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009142321 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0.09607637  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    std                  | 0.477       |\n",
      "|    value_loss           | 0.0169      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806725 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.010197401 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00159    |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.466       |\n",
      "|    value_loss           | 0.0527      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.45     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 162      |\n",
      "|    time_elapsed    | 723      |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.45        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 727         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008778259 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.06050378  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0614      |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    std                  | 0.455       |\n",
      "|    value_loss           | 0.072       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 164          |\n",
      "|    time_elapsed         | 731          |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071156956 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.11314237   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00947      |\n",
      "|    n_updates            | 1630         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    std                  | 0.445        |\n",
      "|    value_loss           | 0.0528       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 736         |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008614711 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.37       |\n",
      "|    explained_variance   | 0.05405301  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 0.0374      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008977858 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.13256037  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    std                  | 0.435       |\n",
      "|    value_loss           | 0.0169      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 340000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046645678 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.32        |\n",
      "|    explained_variance   | 0.7223635    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00351      |\n",
      "|    n_updates            | 1660         |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    std                  | 0.439        |\n",
      "|    value_loss           | 0.000178     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.49     |\n",
      "| time/              |          |\n",
      "|    fps             | 457      |\n",
      "|    iterations      | 167      |\n",
      "|    time_elapsed    | 747      |\n",
      "|    total_timesteps | 342016   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.48         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 168          |\n",
      "|    time_elapsed         | 751          |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065013273 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.014762461  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0773       |\n",
      "|    n_updates            | 1670         |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    std                  | 0.433        |\n",
      "|    value_loss           | 0.251        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 755          |\n",
      "|    total_timesteps      | 346112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063515026 |\n",
      "|    clip_fraction        | 0.0571       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | -0.020629406 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.015       |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.426        |\n",
      "|    value_loss           | 0.0175       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 759         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011590146 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 0.67707485  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00507     |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    std                  | 0.424       |\n",
      "|    value_loss           | 0.000458    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006480992 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.0867278   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | 2.82e-05    |\n",
      "|    std                  | 0.421       |\n",
      "|    value_loss           | 0.0336      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.31     |\n",
      "| time/              |          |\n",
      "|    fps             | 457      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 764      |\n",
      "|    total_timesteps | 350208   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 769         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010677522 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.89516664  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00549    |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.422       |\n",
      "|    value_loss           | 0.000354    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 773         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006272589 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.81358194  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0176      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    std                  | 0.423       |\n",
      "|    value_loss           | 0.000463    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011112091 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | -0.06524575 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    std                  | 0.418       |\n",
      "|    value_loss           | 0.0166      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.26         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 781          |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100823045 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.11        |\n",
      "|    explained_variance   | 0.003166914  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0118      |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    std                  | 0.411        |\n",
      "|    value_loss           | 0.0531       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 360000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004262806  |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | -0.021447778 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0962       |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | -0.000451    |\n",
      "|    std                  | 0.404        |\n",
      "|    value_loss           | 0.108        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.35     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 786      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 790         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007072839 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.03779137  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00528     |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 0.401       |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 795          |\n",
      "|    total_timesteps      | 364544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044516353 |\n",
      "|    clip_fraction        | 0.0697       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.051947534  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0155       |\n",
      "|    n_updates            | 1770         |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    std                  | 0.396        |\n",
      "|    value_loss           | 0.0379       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 799          |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056248475 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.04165101   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0266       |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.389        |\n",
      "|    value_loss           | 0.0803       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 803         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008968151 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.101323724 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00188     |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    std                  | 0.385       |\n",
      "|    value_loss           | 0.0812      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 370000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056880405 |\n",
      "|    clip_fraction        | 0.0509       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.13039964   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00149      |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.381        |\n",
      "|    value_loss           | 0.0809       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.56     |\n",
      "| time/              |          |\n",
      "|    fps             | 457      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 809      |\n",
      "|    total_timesteps | 370688   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 814          |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009295614  |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.0036142468 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.103        |\n",
      "|    n_updates            | 1810         |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    std                  | 0.373        |\n",
      "|    value_loss           | 0.0685       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.72        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 819         |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005369992 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.11138499  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    std                  | 0.368       |\n",
      "|    value_loss           | 0.0332      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.62         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 823          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075778826 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | -0.008205771 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0949       |\n",
      "|    n_updates            | 1830         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 0.195        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009706965 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.5325788   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000176    |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    std                  | 0.368       |\n",
      "|    value_loss           | 0.000695    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 380000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009016432  |\n",
      "|    clip_fraction        | 0.0774       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | -0.010629535 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0244       |\n",
      "|    n_updates            | 1850         |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 0.146        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77     |\n",
      "| time/              |          |\n",
      "|    fps             | 457      |\n",
      "|    iterations      | 186      |\n",
      "|    time_elapsed    | 833      |\n",
      "|    total_timesteps | 380928   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 837         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006517593 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.00277555 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 841          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007578435  |\n",
      "|    clip_fraction        | 0.0692       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | -0.036649346 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.105        |\n",
      "|    n_updates            | 1870         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    std                  | 0.355        |\n",
      "|    value_loss           | 0.197        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 845         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010649113 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.09115994  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    std                  | 0.347       |\n",
      "|    value_loss           | 0.0679      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006375079 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.058911085 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0194      |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.347       |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1e+03         |\n",
      "|    mean_reward          | 0             |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 390000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00583802    |\n",
      "|    clip_fraction        | 0.0539        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -0.0035932064 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0216        |\n",
      "|    n_updates            | 1900          |\n",
      "|    policy_gradient_loss | -0.00109      |\n",
      "|    std                  | 0.347         |\n",
      "|    value_loss           | 0.179         |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82     |\n",
      "| time/              |          |\n",
      "|    fps             | 457      |\n",
      "|    iterations      | 191      |\n",
      "|    time_elapsed    | 855      |\n",
      "|    total_timesteps | 391168   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 2.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 859          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006228856  |\n",
      "|    clip_fraction        | 0.0761       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -0.021504283 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0285       |\n",
      "|    n_updates            | 1910         |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.344        |\n",
      "|    value_loss           | 0.0177       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.99        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 863         |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010554785 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.023820579 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    std                  | 0.34        |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 3.02         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 867          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00842689   |\n",
      "|    clip_fraction        | 0.0796       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -0.006845951 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0307       |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    std                  | 0.337        |\n",
      "|    value_loss           | 0.0831       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.99        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 871         |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006580245 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.058271706 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0646      |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 0.332       |\n",
      "|    value_loss           | 0.0537      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008646264 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.15474558  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    std                  | 0.329       |\n",
      "|    value_loss           | 0.0618      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 3.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 457      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 876      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 3.1          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 457          |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 880          |\n",
      "|    total_timesteps      | 403456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068506277 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | -0.010075569 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0903       |\n",
      "|    n_updates            | 1960         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    std                  | 0.323        |\n",
      "|    value_loss           | 0.0807       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 3.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 885         |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00731887  |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.015795112 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0205      |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    std                  | 0.32        |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 3.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 889         |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005464244 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.009975076 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    std                  | 0.316       |\n",
      "|    value_loss           | 0.072       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 3.26         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 893          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053941915 |\n",
      "|    clip_fraction        | 0.0674       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -0.008581877 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00653      |\n",
      "|    n_updates            | 1990         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    std                  | 0.311        |\n",
      "|    value_loss           | 0.0666       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 410000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062440066 |\n",
      "|    clip_fraction        | 0.0738       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.965       |\n",
      "|    explained_variance   | -0.019401908 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.138        |\n",
      "|    n_updates            | 2000         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    std                  | 0.308        |\n",
      "|    value_loss           | 0.165        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 3.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 201      |\n",
      "|    time_elapsed    | 898      |\n",
      "|    total_timesteps | 411648   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 3.47         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 902          |\n",
      "|    total_timesteps      | 413696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072757974 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.921       |\n",
      "|    explained_variance   | 0.057265878  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.123        |\n",
      "|    n_updates            | 2010         |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    std                  | 0.305        |\n",
      "|    value_loss           | 0.168        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 3.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 906          |\n",
      "|    total_timesteps      | 415744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027042185 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.875       |\n",
      "|    explained_variance   | 0.057854176  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0267       |\n",
      "|    n_updates            | 2020         |\n",
      "|    policy_gradient_loss | -0.000995    |\n",
      "|    std                  | 0.301        |\n",
      "|    value_loss           | 0.0852       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 3.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 910         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007561818 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.847      |\n",
      "|    explained_variance   | 0.14640605  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 3.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 915         |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012629151 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.801      |\n",
      "|    explained_variance   | 0.101409495 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0244      |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    std                  | 0.295       |\n",
      "|    value_loss           | 0.0454      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 420000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01116192  |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.763      |\n",
      "|    explained_variance   | 0.025670052 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00719    |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    std                  | 0.295       |\n",
      "|    value_loss           | 0.0528      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 3.6      |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 206      |\n",
      "|    time_elapsed    | 920      |\n",
      "|    total_timesteps | 421888   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 3.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 924          |\n",
      "|    total_timesteps      | 423936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058213044 |\n",
      "|    clip_fraction        | 0.0801       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.756       |\n",
      "|    explained_variance   | 0.076343834  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0105       |\n",
      "|    n_updates            | 2060         |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    std                  | 0.294        |\n",
      "|    value_loss           | 0.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 3.78         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 928          |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008061206  |\n",
      "|    clip_fraction        | 0.0885       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.723       |\n",
      "|    explained_variance   | -0.033892393 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.127        |\n",
      "|    n_updates            | 2070         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 0.29         |\n",
      "|    value_loss           | 0.189        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 3.89        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 932         |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009239577 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | -0.01229167 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    std                  | 0.286       |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010877745 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0.077867866 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0139      |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    std                  | 0.28        |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 3.97     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 210      |\n",
      "|    time_elapsed    | 937      |\n",
      "|    total_timesteps | 430080   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.08         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 941          |\n",
      "|    total_timesteps      | 432128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006556359  |\n",
      "|    clip_fraction        | 0.0673       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | -0.105297804 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.197        |\n",
      "|    n_updates            | 2100         |\n",
      "|    policy_gradient_loss | -0.000419    |\n",
      "|    std                  | 0.279        |\n",
      "|    value_loss           | 0.203        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 946         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009305407 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.486      |\n",
      "|    explained_variance   | 0.044907987 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.205       |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    std                  | 0.272       |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 950         |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007971543 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.411      |\n",
      "|    explained_variance   | 0.09317756  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.28         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 954          |\n",
      "|    total_timesteps      | 438272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073953383 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.356       |\n",
      "|    explained_variance   | 0.0445022    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00052     |\n",
      "|    n_updates            | 2130         |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 0.265        |\n",
      "|    value_loss           | 0.168        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 440000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056198216 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.324       |\n",
      "|    explained_variance   | 0.17843759   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0183       |\n",
      "|    n_updates            | 2140         |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    std                  | 0.264        |\n",
      "|    value_loss           | 0.0555       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 4.36     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 959      |\n",
      "|    total_timesteps | 440320   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 963         |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006832256 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.11578065  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0681      |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 0.0874      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.29         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 968          |\n",
      "|    total_timesteps      | 444416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006034648  |\n",
      "|    clip_fraction        | 0.069        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.234       |\n",
      "|    explained_variance   | -0.034811974 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0681       |\n",
      "|    n_updates            | 2160         |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.258        |\n",
      "|    value_loss           | 0.15         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 972         |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010576012 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.193      |\n",
      "|    explained_variance   | 0.18856502  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00105    |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 0.0488      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.37         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 976          |\n",
      "|    total_timesteps      | 448512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084446855 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.172       |\n",
      "|    explained_variance   | 0.059536397  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00316      |\n",
      "|    n_updates            | 2180         |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 0.0384       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 450000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008496505 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.155      |\n",
      "|    explained_variance   | 0.016510129 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0625      |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 4.43     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 981      |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.49         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 985          |\n",
      "|    total_timesteps      | 452608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058756815 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.115       |\n",
      "|    explained_variance   | 0.3734163    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00955     |\n",
      "|    n_updates            | 2200         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    std                  | 0.25         |\n",
      "|    value_loss           | 0.0648       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 989         |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003588532 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0743     |\n",
      "|    explained_variance   | 0.41053593  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0534      |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.00068    |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 0.0856      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.71         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 994          |\n",
      "|    total_timesteps      | 456704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073599145 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0129      |\n",
      "|    explained_variance   | 0.08960056   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0405       |\n",
      "|    n_updates            | 2220         |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    std                  | 0.243        |\n",
      "|    value_loss           | 0.144        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 4.7        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 459        |\n",
      "|    iterations           | 224        |\n",
      "|    time_elapsed         | 998        |\n",
      "|    total_timesteps      | 458752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00662766 |\n",
      "|    clip_fraction        | 0.0759     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.0285     |\n",
      "|    explained_variance   | 0.22914988 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.112      |\n",
      "|    n_updates            | 2230       |\n",
      "|    policy_gradient_loss | -0.00187   |\n",
      "|    std                  | 0.242      |\n",
      "|    value_loss           | 0.148      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 460000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072657047 |\n",
      "|    clip_fraction        | 0.0792       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.051        |\n",
      "|    explained_variance   | 0.04335296   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 2240         |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 0.117        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 4.71     |\n",
      "| time/              |          |\n",
      "|    fps             | 459      |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 1003     |\n",
      "|    total_timesteps | 460800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.89         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 1007         |\n",
      "|    total_timesteps      | 462848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073132627 |\n",
      "|    clip_fraction        | 0.0668       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.0783       |\n",
      "|    explained_variance   | 0.084038675  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0691       |\n",
      "|    n_updates            | 2250         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    std                  | 0.239        |\n",
      "|    value_loss           | 0.124        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 4.89         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 1012         |\n",
      "|    total_timesteps      | 464896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007933449  |\n",
      "|    clip_fraction        | 0.0671       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.117        |\n",
      "|    explained_variance   | -0.014445782 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0111       |\n",
      "|    n_updates            | 2260         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 0.188        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 1016        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006273754 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.153       |\n",
      "|    explained_variance   | 0.14528424  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 0.0799      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 1020        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006666106 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.187       |\n",
      "|    explained_variance   | 0.117351174 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0978      |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 470000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248677 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.23        |\n",
      "|    explained_variance   | -0.11934757 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.000411   |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 5.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 230      |\n",
      "|    time_elapsed    | 1026     |\n",
      "|    total_timesteps | 471040   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 5.12         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 231          |\n",
      "|    time_elapsed         | 1031         |\n",
      "|    total_timesteps      | 473088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065597594 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.276        |\n",
      "|    explained_variance   | 0.05072862   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0315       |\n",
      "|    n_updates            | 2300         |\n",
      "|    policy_gradient_loss | -0.000772    |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 0.0843       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 1035        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009896939 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.306       |\n",
      "|    explained_variance   | 0.47265363  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 0.0847      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 1040        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007197504 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.345       |\n",
      "|    explained_variance   | 0.036245763 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.31        |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 5.28         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 1044         |\n",
      "|    total_timesteps      | 479232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008579194  |\n",
      "|    clip_fraction        | 0.0654       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.411        |\n",
      "|    explained_variance   | -0.062278748 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0304       |\n",
      "|    n_updates            | 2330         |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 0.136        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052354345 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.452        |\n",
      "|    explained_variance   | 0.27533072   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0802       |\n",
      "|    n_updates            | 2340         |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    std                  | 0.218        |\n",
      "|    value_loss           | 0.116        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 5.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 235      |\n",
      "|    time_elapsed    | 1049     |\n",
      "|    total_timesteps | 481280   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 1053        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007166693 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.48        |\n",
      "|    explained_variance   | 0.006849885 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 1058        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008303186 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.51        |\n",
      "|    explained_variance   | 0.48239505  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.025       |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 0.0494      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 1062        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006878383 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.535       |\n",
      "|    explained_variance   | 0.21464306  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0424      |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 0.214       |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 5.43         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 1066         |\n",
      "|    total_timesteps      | 489472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054523135 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.558        |\n",
      "|    explained_variance   | 0.36522764   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.11         |\n",
      "|    n_updates            | 2380         |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 0.144        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 490000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004908513 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.589       |\n",
      "|    explained_variance   | 0.024522007 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0716      |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | 0.000171    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 5.52     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 240      |\n",
      "|    time_elapsed    | 1071     |\n",
      "|    total_timesteps | 491520   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 5.51         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 1075         |\n",
      "|    total_timesteps      | 493568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063906293 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.625        |\n",
      "|    explained_variance   | 0.15228623   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0822       |\n",
      "|    n_updates            | 2400         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 0.173        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 5.58         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 242          |\n",
      "|    time_elapsed         | 1079         |\n",
      "|    total_timesteps      | 495616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048072916 |\n",
      "|    clip_fraction        | 0.0612       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.643        |\n",
      "|    explained_variance   | 0.07660687   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.113        |\n",
      "|    n_updates            | 2410         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 0.187        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 5.67         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 459          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 1084         |\n",
      "|    total_timesteps      | 497664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043445365 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.679        |\n",
      "|    explained_variance   | 0.5066589    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00817     |\n",
      "|    n_updates            | 2420         |\n",
      "|    policy_gradient_loss | -0.000889    |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 0.129        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 5.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 1088        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008185935 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.734       |\n",
      "|    explained_variance   | -0.12422764 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.203       |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006385253 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.795       |\n",
      "|    explained_variance   | 0.078978    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0324      |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 6.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 245      |\n",
      "|    time_elapsed    | 1094     |\n",
      "|    total_timesteps | 501760   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 6.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 458        |\n",
      "|    iterations           | 246        |\n",
      "|    time_elapsed         | 1098       |\n",
      "|    total_timesteps      | 503808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00784921 |\n",
      "|    clip_fraction        | 0.0827     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.853      |\n",
      "|    explained_variance   | 0.19746524 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.2        |\n",
      "|    n_updates            | 2450       |\n",
      "|    policy_gradient_loss | -0.00343   |\n",
      "|    std                  | 0.197      |\n",
      "|    value_loss           | 0.375      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 6.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 1103        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006670421 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.902       |\n",
      "|    explained_variance   | 0.39378047  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 6.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 1108        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006922682 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.935       |\n",
      "|    explained_variance   | 0.035347342 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.00054    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 6.66       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 458        |\n",
      "|    iterations           | 249        |\n",
      "|    time_elapsed         | 1112       |\n",
      "|    total_timesteps      | 509952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00597928 |\n",
      "|    clip_fraction        | 0.0554     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.962      |\n",
      "|    explained_variance   | 0.23781139 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0555     |\n",
      "|    n_updates            | 2480       |\n",
      "|    policy_gradient_loss | -7.94e-05  |\n",
      "|    std                  | 0.192      |\n",
      "|    value_loss           | 0.237      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006242058 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.01        |\n",
      "|    explained_variance   | 0.11469293  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0987      |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    std                  | 0.19        |\n",
      "|    value_loss           | 0.239       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 6.9      |\n",
      "| time/              |          |\n",
      "|    fps             | 457      |\n",
      "|    iterations      | 250      |\n",
      "|    time_elapsed    | 1118     |\n",
      "|    total_timesteps | 512000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 7.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 1122        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005460443 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.08089149  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0913      |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.000717   |\n",
      "|    std                  | 0.188       |\n",
      "|    value_loss           | 0.37        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 7.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 1126         |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00977851   |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.07         |\n",
      "|    explained_variance   | 0.0136678815 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.339        |\n",
      "|    n_updates            | 2510         |\n",
      "|    policy_gradient_loss | 0.000105     |\n",
      "|    std                  | 0.188        |\n",
      "|    value_loss           | 0.559        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 7.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 1130        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009524346 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.06        |\n",
      "|    explained_variance   | 0.21477413  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0545      |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    std                  | 0.188       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009248838 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.08        |\n",
      "|    explained_variance   | 0.25465882  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0298      |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    std                  | 0.187       |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 7.38     |\n",
      "| time/              |          |\n",
      "|    fps             | 457      |\n",
      "|    iterations      | 254      |\n",
      "|    time_elapsed    | 1136     |\n",
      "|    total_timesteps | 520192   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 7.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 1140        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008770412 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.11        |\n",
      "|    explained_variance   | 0.5734427   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 7.62         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 256          |\n",
      "|    time_elapsed         | 1144         |\n",
      "|    total_timesteps      | 524288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062617166 |\n",
      "|    clip_fraction        | 0.0892       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.14         |\n",
      "|    explained_variance   | 0.34387767   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.226        |\n",
      "|    n_updates            | 2550         |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.184        |\n",
      "|    value_loss           | 0.412        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 7.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007076711 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.11130041  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0613      |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    std                  | 0.183       |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 8.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 1152        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009051891 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.18        |\n",
      "|    explained_variance   | 0.40186614  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0656      |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    std                  | 0.182       |\n",
      "|    value_loss           | 0.293       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009015521 |\n",
      "|    clip_fraction        | 0.0889      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.24914634  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0698      |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.000187   |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 0.361       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 8.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 259      |\n",
      "|    time_elapsed    | 1157     |\n",
      "|    total_timesteps | 530432   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 8.36       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 458        |\n",
      "|    iterations           | 260        |\n",
      "|    time_elapsed         | 1161       |\n",
      "|    total_timesteps      | 532480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01084728 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.27       |\n",
      "|    explained_variance   | 0.2157839  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0978     |\n",
      "|    n_updates            | 2590       |\n",
      "|    policy_gradient_loss | 0.00134    |\n",
      "|    std                  | 0.177      |\n",
      "|    value_loss           | 0.393      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 8.73        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 1165        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007866554 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.3         |\n",
      "|    explained_variance   | 0.4699613   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0786      |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.177       |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 8.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 1170        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010200131 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.33        |\n",
      "|    explained_variance   | 0.3197295   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.281       |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    std                  | 0.175       |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 9.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 1174        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010759511 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.38        |\n",
      "|    explained_variance   | 0.22692615  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.231       |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.173       |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 540000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011891376 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.42        |\n",
      "|    explained_variance   | 0.44211358  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 0.429       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 9.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 264      |\n",
      "|    time_elapsed    | 1179     |\n",
      "|    total_timesteps | 540672   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 9.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 1183        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010204348 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.41        |\n",
      "|    explained_variance   | 0.8268758   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    std                  | 0.173       |\n",
      "|    value_loss           | 0.0385      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 9.63        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 1187        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009881522 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.41        |\n",
      "|    explained_variance   | 0.5381819   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 0.347       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 9.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 1192        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013655668 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.44        |\n",
      "|    explained_variance   | 0.3973434   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 9.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 1196        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008670131 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.48        |\n",
      "|    explained_variance   | 0.5858186   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0808      |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    std                  | 0.169       |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008586997 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.51        |\n",
      "|    explained_variance   | 0.272453    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0125      |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 10.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 269      |\n",
      "|    time_elapsed    | 1201     |\n",
      "|    total_timesteps | 550912   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 10.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 1205        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008279944 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.56        |\n",
      "|    explained_variance   | 0.084034026 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0328      |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 10.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 271          |\n",
      "|    time_elapsed         | 1210         |\n",
      "|    total_timesteps      | 555008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072628967 |\n",
      "|    clip_fraction        | 0.0958       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.62         |\n",
      "|    explained_variance   | 0.7774673    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 2700         |\n",
      "|    policy_gradient_loss | 0.002        |\n",
      "|    std                  | 0.164        |\n",
      "|    value_loss           | 0.221        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 1214         |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067802155 |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.31480688   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.108        |\n",
      "|    n_updates            | 2710         |\n",
      "|    policy_gradient_loss | 0.00033      |\n",
      "|    std                  | 0.163        |\n",
      "|    value_loss           | 0.216        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 10.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 458        |\n",
      "|    iterations           | 273        |\n",
      "|    time_elapsed         | 1219       |\n",
      "|    total_timesteps      | 559104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0065125  |\n",
      "|    clip_fraction        | 0.0819     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.63       |\n",
      "|    explained_variance   | 0.10836369 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0796     |\n",
      "|    n_updates            | 2720       |\n",
      "|    policy_gradient_loss | -0.00163   |\n",
      "|    std                  | 0.164      |\n",
      "|    value_loss           | 0.118      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009134943 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.5686826   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.188       |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 0.294       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 10.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 274      |\n",
      "|    time_elapsed    | 1224     |\n",
      "|    total_timesteps | 561152   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 10.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 1228        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007407592 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.3657449   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 11          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007243807 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.67        |\n",
      "|    explained_variance   | 0.35543215  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 11.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 1237        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006611435 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.68        |\n",
      "|    explained_variance   | 0.4182334   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | 0.000688    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 11.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 1241        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009629756 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.7         |\n",
      "|    explained_variance   | 0.10004133  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0908      |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.000619   |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 570000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015283687 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.75        |\n",
      "|    explained_variance   | 0.35179466  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0853      |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 0.364       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 11.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 279      |\n",
      "|    time_elapsed    | 1246     |\n",
      "|    total_timesteps | 571392   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 11.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 458        |\n",
      "|    iterations           | 280        |\n",
      "|    time_elapsed         | 1250       |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00968532 |\n",
      "|    clip_fraction        | 0.0969     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.81       |\n",
      "|    explained_variance   | 0.21453959 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.195      |\n",
      "|    n_updates            | 2790       |\n",
      "|    policy_gradient_loss | -0.000971  |\n",
      "|    std                  | 0.156      |\n",
      "|    value_loss           | 0.396      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 11.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 1254        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008962151 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.1470896   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.344       |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 11.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 458        |\n",
      "|    iterations           | 282        |\n",
      "|    time_elapsed         | 1259       |\n",
      "|    total_timesteps      | 577536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01158057 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.89       |\n",
      "|    explained_variance   | 0.42605275 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.165      |\n",
      "|    n_updates            | 2810       |\n",
      "|    policy_gradient_loss | -0.00381   |\n",
      "|    std                  | 0.153      |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 1263        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009515889 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.91        |\n",
      "|    explained_variance   | 0.3040902   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0734      |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013797788 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.6184051   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.000999   |\n",
      "|    std                  | 0.15        |\n",
      "|    value_loss           | 0.326       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 12.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 284      |\n",
      "|    time_elapsed    | 1268     |\n",
      "|    total_timesteps | 581632   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 12.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 458          |\n",
      "|    iterations           | 285          |\n",
      "|    time_elapsed         | 1272         |\n",
      "|    total_timesteps      | 583680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077725854 |\n",
      "|    clip_fraction        | 0.0985       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2            |\n",
      "|    explained_variance   | 0.7461562    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000867    |\n",
      "|    n_updates            | 2840         |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    std                  | 0.149        |\n",
      "|    value_loss           | 0.0673       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 12.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 458        |\n",
      "|    iterations           | 286        |\n",
      "|    time_elapsed         | 1276       |\n",
      "|    total_timesteps      | 585728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00953717 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.49031144 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0268     |\n",
      "|    n_updates            | 2850       |\n",
      "|    policy_gradient_loss | -0.000554  |\n",
      "|    std                  | 0.148      |\n",
      "|    value_loss           | 0.232      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 1280        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008712016 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.23946822  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0721      |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.147       |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 12.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 459        |\n",
      "|    iterations           | 288        |\n",
      "|    time_elapsed         | 1284       |\n",
      "|    total_timesteps      | 589824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01036315 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.07       |\n",
      "|    explained_variance   | 0.54369044 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.154      |\n",
      "|    n_updates            | 2870       |\n",
      "|    policy_gradient_loss | -0.00195   |\n",
      "|    std                  | 0.146      |\n",
      "|    value_loss           | 0.359      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 590000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009014135 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.12        |\n",
      "|    explained_variance   | 0.79296726  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0742      |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 12.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 458      |\n",
      "|    iterations      | 289      |\n",
      "|    time_elapsed    | 1289     |\n",
      "|    total_timesteps | 591872   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 1294        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014644581 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.16        |\n",
      "|    explained_variance   | 0.1179468   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | 0.00515     |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 0.387       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014692326 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.6191149   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.000129   |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 459        |\n",
      "|    iterations           | 292        |\n",
      "|    time_elapsed         | 1302       |\n",
      "|    total_timesteps      | 598016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01022168 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.22       |\n",
      "|    explained_variance   | 0.46314353 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0396     |\n",
      "|    n_updates            | 2910       |\n",
      "|    policy_gradient_loss | -0.00276   |\n",
      "|    std                  | 0.141      |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009714354 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.45628297  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | 0.000582    |\n",
      "|    std                  | 0.14        |\n",
      "|    value_loss           | 0.32        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 459      |\n",
      "|    iterations      | 293      |\n",
      "|    time_elapsed    | 1307     |\n",
      "|    total_timesteps | 600064   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 1311        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023202326 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.28        |\n",
      "|    explained_variance   | 0.19268948  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.486       |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | 0.0032      |\n",
      "|    std                  | 0.14        |\n",
      "|    value_loss           | 0.698       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 459        |\n",
      "|    iterations           | 295        |\n",
      "|    time_elapsed         | 1315       |\n",
      "|    total_timesteps      | 604160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00826242 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.3        |\n",
      "|    explained_variance   | 0.6341394  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0957     |\n",
      "|    n_updates            | 2940       |\n",
      "|    policy_gradient_loss | 0.00122    |\n",
      "|    std                  | 0.139      |\n",
      "|    value_loss           | 0.261      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 1320        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009172556 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.33        |\n",
      "|    explained_variance   | 0.4126097   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0895      |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.00038    |\n",
      "|    std                  | 0.138       |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 1325        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009863304 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.35        |\n",
      "|    explained_variance   | 0.4278739   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000308    |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.000247   |\n",
      "|    std                  | 0.137       |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010401994 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.37        |\n",
      "|    explained_variance   | 0.6741507   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | 0.000992    |\n",
      "|    std                  | 0.136       |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 411      |\n",
      "|    iterations      | 298      |\n",
      "|    time_elapsed    | 1483     |\n",
      "|    total_timesteps | 610304   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 1487        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008415924 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.41        |\n",
      "|    explained_variance   | 0.7137972   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0643      |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | 0.00146     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 13.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 411          |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 1492         |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067198104 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.42         |\n",
      "|    explained_variance   | 0.66915643   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0436       |\n",
      "|    n_updates            | 2990         |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    std                  | 0.135        |\n",
      "|    value_loss           | 0.193        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 1496        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012518139 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.44        |\n",
      "|    explained_variance   | 0.632444    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0423      |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.000697   |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 411         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 1501        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009757921 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.46        |\n",
      "|    explained_variance   | 0.80586     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0632      |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | 0.00249     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0.4          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 620000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076499674 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.46         |\n",
      "|    explained_variance   | 0.65757656   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0845       |\n",
      "|    n_updates            | 3020         |\n",
      "|    policy_gradient_loss | -0.000187    |\n",
      "|    std                  | 0.133        |\n",
      "|    value_loss           | 0.266        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 411      |\n",
      "|    iterations      | 303      |\n",
      "|    time_elapsed    | 1506     |\n",
      "|    total_timesteps | 620544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 412        |\n",
      "|    iterations           | 304        |\n",
      "|    time_elapsed         | 1511       |\n",
      "|    total_timesteps      | 622592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00906275 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.48       |\n",
      "|    explained_variance   | 0.576789   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.151      |\n",
      "|    n_updates            | 3030       |\n",
      "|    policy_gradient_loss | 0.000919   |\n",
      "|    std                  | 0.133      |\n",
      "|    value_loss           | 0.359      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 1515        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013075467 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 0.81781197  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 2418        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008737503 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 0.12639225  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    std                  | 0.133       |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 2422        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009579781 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.53        |\n",
      "|    explained_variance   | 0.6576154   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.000882   |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 630000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011885878 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.81184554  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.000577   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 259      |\n",
      "|    iterations      | 308      |\n",
      "|    time_elapsed    | 2427     |\n",
      "|    total_timesteps | 630784   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 2431        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009026733 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.6         |\n",
      "|    explained_variance   | 0.61821413  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.465       |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | 0.00127     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 2435        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007285676 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.6         |\n",
      "|    explained_variance   | 0.66553664  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 2439        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017046396 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.64        |\n",
      "|    explained_variance   | 0.5351939   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0827      |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 0.364       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 2443        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008354567 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.68        |\n",
      "|    explained_variance   | 0.78440726  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | 0.00221     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=0.60 +/- 1.20\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0.6         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012767357 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.7973032   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0805      |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.000154   |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 0.338       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 261      |\n",
      "|    iterations      | 313      |\n",
      "|    time_elapsed    | 2448     |\n",
      "|    total_timesteps | 641024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 2452        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010717141 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.79803354  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00741     |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | 0.00185     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 0.252       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 14.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 262        |\n",
      "|    iterations           | 315        |\n",
      "|    time_elapsed         | 2456       |\n",
      "|    total_timesteps      | 645120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00682995 |\n",
      "|    clip_fraction        | 0.0801     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.7        |\n",
      "|    explained_variance   | 0.7194431  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0623     |\n",
      "|    n_updates            | 3140       |\n",
      "|    policy_gradient_loss | 0.00121    |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 0.24       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 2460        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010365974 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.79092693  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.000263   |\n",
      "|    std                  | 0.124       |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 2464        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011917941 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.72        |\n",
      "|    explained_variance   | 0.6876404   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    std                  | 0.124       |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 650000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092057185 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.75868994   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.108        |\n",
      "|    n_updates            | 3170         |\n",
      "|    policy_gradient_loss | 0.000985     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 0.189        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 263      |\n",
      "|    iterations      | 318      |\n",
      "|    time_elapsed    | 2469     |\n",
      "|    total_timesteps | 651264   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 2473        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007239108 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.61531925  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0865      |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.000631   |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 2477        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013802055 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.81        |\n",
      "|    explained_variance   | 0.4949475   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.000216   |\n",
      "|    std                  | 0.121       |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 2481        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013441865 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.84        |\n",
      "|    explained_variance   | 0.709461    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    std                  | 0.12        |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 2485        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011372535 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.51101077  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0893      |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | 0.000578    |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 660000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011183994 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.91        |\n",
      "|    explained_variance   | 0.32189006  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | 0.00183     |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 0.37        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 222      |\n",
      "|    iterations      | 323      |\n",
      "|    time_elapsed    | 2974     |\n",
      "|    total_timesteps | 661504   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 2979        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012636831 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.71565866  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0088      |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | 3.95e-05    |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 2983        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017163416 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.96        |\n",
      "|    explained_variance   | 0.7134839   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    std                  | 0.116       |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 2987        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013259077 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.96        |\n",
      "|    explained_variance   | 0.6135459   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.197       |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 2991        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010134313 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.96        |\n",
      "|    explained_variance   | 0.39377606  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0872      |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    std                  | 0.116       |\n",
      "|    value_loss           | 0.334       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 670000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015083005 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.98        |\n",
      "|    explained_variance   | 0.48651248  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | 0.0022      |\n",
      "|    std                  | 0.115       |\n",
      "|    value_loss           | 0.296       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 224      |\n",
      "|    iterations      | 328      |\n",
      "|    time_elapsed    | 2996     |\n",
      "|    total_timesteps | 671744   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 3000        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011488697 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3           |\n",
      "|    explained_variance   | 0.46745896  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0712      |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.000277   |\n",
      "|    std                  | 0.115       |\n",
      "|    value_loss           | 0.267       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 3004        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014733596 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.5817095   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0982      |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    std                  | 0.113       |\n",
      "|    value_loss           | 0.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 3008        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012279829 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.4196741   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | 0.00182     |\n",
      "|    std                  | 0.112       |\n",
      "|    value_loss           | 0.324       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 225         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 3012        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010271404 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.14        |\n",
      "|    explained_variance   | 0.7257591   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | 0.000509    |\n",
      "|    std                  | 0.111       |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 680000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011102889 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.15        |\n",
      "|    explained_variance   | 0.6766119   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | 0.000167    |\n",
      "|    std                  | 0.111       |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 226      |\n",
      "|    iterations      | 333      |\n",
      "|    time_elapsed    | 3017     |\n",
      "|    total_timesteps | 681984   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 14.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 226          |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 3021         |\n",
      "|    total_timesteps      | 684032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128518585 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.15         |\n",
      "|    explained_variance   | 0.7913187    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.321        |\n",
      "|    n_updates            | 3330         |\n",
      "|    policy_gradient_loss | 0.00329      |\n",
      "|    std                  | 0.111        |\n",
      "|    value_loss           | 0.259        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 3025        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009292883 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.18        |\n",
      "|    explained_variance   | 0.8494156   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0283      |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | 0.00101     |\n",
      "|    std                  | 0.11        |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 3029        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011022681 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.77979684  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0652      |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | 0.00095     |\n",
      "|    std                  | 0.109       |\n",
      "|    value_loss           | 0.283       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010827969 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.8477508   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | 0.00041     |\n",
      "|    std                  | 0.109       |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 15       |\n",
      "| time/              |          |\n",
      "|    fps             | 227      |\n",
      "|    iterations      | 337      |\n",
      "|    time_elapsed    | 3034     |\n",
      "|    total_timesteps | 690176   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 3038        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009232853 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.25        |\n",
      "|    explained_variance   | 0.6186267   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | 0.00166     |\n",
      "|    std                  | 0.108       |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 3042        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010554643 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.84941566  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0835      |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    std                  | 0.107       |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 15.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 3047       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01068175 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.66302323 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.19       |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | 0.00148    |\n",
      "|    std                  | 0.106      |\n",
      "|    value_loss           | 0.266      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 3051        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008197287 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.74748397  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0665      |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.000575   |\n",
      "|    std                  | 0.105       |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009865778 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.66976285  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    std                  | 0.104       |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 229      |\n",
      "|    iterations      | 342      |\n",
      "|    time_elapsed    | 3056     |\n",
      "|    total_timesteps | 700416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 3061        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010046662 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.89437866  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    std                  | 0.104       |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 3065        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011093495 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.7483456   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0682      |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    std                  | 0.104       |\n",
      "|    value_loss           | 0.405       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 3069        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010360368 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.44        |\n",
      "|    explained_variance   | 0.8884351   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.047       |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 0.103       |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 3074        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010963995 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.8206753   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0903      |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | 0.00439     |\n",
      "|    std                  | 0.103       |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 710000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011552681 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.48        |\n",
      "|    explained_variance   | 0.9037992   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0985      |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | 0.000159    |\n",
      "|    std                  | 0.102       |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 230      |\n",
      "|    iterations      | 347      |\n",
      "|    time_elapsed    | 3080     |\n",
      "|    total_timesteps | 710656   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 15.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 348        |\n",
      "|    time_elapsed         | 3084       |\n",
      "|    total_timesteps      | 712704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00989671 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.52       |\n",
      "|    explained_variance   | 0.83596134 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.128      |\n",
      "|    n_updates            | 3470       |\n",
      "|    policy_gradient_loss | -0.00112   |\n",
      "|    std                  | 0.101      |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 3089        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007876916 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.56        |\n",
      "|    explained_variance   | 0.7399416   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.197       |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.000657   |\n",
      "|    std                  | 0.1         |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 3094        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010390785 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.56        |\n",
      "|    explained_variance   | 0.83027554  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.097       |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    std                  | 0.101       |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 3098        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012698056 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.56        |\n",
      "|    explained_variance   | 0.67765784  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0832      |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.0997      |\n",
      "|    value_loss           | 0.325       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 720000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010285596 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.8624641   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0346      |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    std                  | 0.0987      |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 232      |\n",
      "|    iterations      | 352      |\n",
      "|    time_elapsed    | 3105     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 3109        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009834821 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.76835424  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0498      |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | 0.000321    |\n",
      "|    std                  | 0.0986      |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 3114        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010889959 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.64        |\n",
      "|    explained_variance   | 0.7630576   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | 0.000298    |\n",
      "|    std                  | 0.098       |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 3119        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009977082 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.66        |\n",
      "|    explained_variance   | 0.77478564  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | 0.000872    |\n",
      "|    std                  | 0.0977      |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 14.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 356        |\n",
      "|    time_elapsed         | 3124       |\n",
      "|    total_timesteps      | 729088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0093158  |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.67       |\n",
      "|    explained_variance   | 0.75982547 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0607     |\n",
      "|    n_updates            | 3550       |\n",
      "|    policy_gradient_loss | 0.000209   |\n",
      "|    std                  | 0.0978     |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 730000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010041265 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.66        |\n",
      "|    explained_variance   | 0.78611344  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0306      |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    std                  | 0.0981      |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 233      |\n",
      "|    iterations      | 357      |\n",
      "|    time_elapsed    | 3131     |\n",
      "|    total_timesteps | 731136   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 14.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 358        |\n",
      "|    time_elapsed         | 3136       |\n",
      "|    total_timesteps      | 733184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01112696 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.66       |\n",
      "|    explained_variance   | 0.78845024 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.155      |\n",
      "|    n_updates            | 3570       |\n",
      "|    policy_gradient_loss | 0.000504   |\n",
      "|    std                  | 0.0978     |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 3141        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008584651 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.67        |\n",
      "|    explained_variance   | 0.83236253  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0446      |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    std                  | 0.0977      |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 3146        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013595648 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.68        |\n",
      "|    explained_variance   | 0.75752246  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | 0.00627     |\n",
      "|    std                  | 0.0972      |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 3151        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011543235 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.72        |\n",
      "|    explained_variance   | 0.8298792   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00547     |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    std                  | 0.096       |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010967983 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.74        |\n",
      "|    explained_variance   | 0.8497576   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | 0.000953    |\n",
      "|    std                  | 0.096       |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 234      |\n",
      "|    iterations      | 362      |\n",
      "|    time_elapsed    | 3158     |\n",
      "|    total_timesteps | 741376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 3163        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010724616 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.75        |\n",
      "|    explained_variance   | 0.83558935  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.0952      |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 3168        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013745931 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.78        |\n",
      "|    explained_variance   | 0.8595799   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.000626   |\n",
      "|    std                  | 0.0946      |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 3174        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013066862 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.8         |\n",
      "|    explained_variance   | 0.8305128   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0525      |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | 0.000718    |\n",
      "|    std                  | 0.0944      |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 3180        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010059241 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.81        |\n",
      "|    explained_variance   | 0.84975773  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0817      |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | 0.000464    |\n",
      "|    std                  | 0.0942      |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008754613 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.81        |\n",
      "|    explained_variance   | 0.6130037   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.267       |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.0939      |\n",
      "|    value_loss           | 0.354       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 235      |\n",
      "|    iterations      | 367      |\n",
      "|    time_elapsed    | 3186     |\n",
      "|    total_timesteps | 751616   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 3192        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016933687 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.83        |\n",
      "|    explained_variance   | 0.7593089   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    std                  | 0.0934      |\n",
      "|    value_loss           | 0.386       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 3197        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012592254 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.85        |\n",
      "|    explained_variance   | 0.83464116  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0263      |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.00091    |\n",
      "|    std                  | 0.0931      |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 3203        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014665669 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.86        |\n",
      "|    explained_variance   | 0.8042393   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | 0.000977    |\n",
      "|    std                  | 0.0928      |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 3208        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014026269 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.89        |\n",
      "|    explained_variance   | 0.8277682   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0622      |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.0921      |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014533816 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.91        |\n",
      "|    explained_variance   | 0.7635311   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0861      |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | 0.00639     |\n",
      "|    std                  | 0.0916      |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 236      |\n",
      "|    iterations      | 372      |\n",
      "|    time_elapsed    | 3215     |\n",
      "|    total_timesteps | 761856   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 13.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 373          |\n",
      "|    time_elapsed         | 3221         |\n",
      "|    total_timesteps      | 763904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122146215 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.93         |\n",
      "|    explained_variance   | 0.8983803    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0178       |\n",
      "|    n_updates            | 3720         |\n",
      "|    policy_gradient_loss | 0.00343      |\n",
      "|    std                  | 0.0917       |\n",
      "|    value_loss           | 0.122        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 3227        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012890076 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.7419834   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    std                  | 0.0906      |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 13.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 375          |\n",
      "|    time_elapsed         | 3232         |\n",
      "|    total_timesteps      | 768000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052332478 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.97         |\n",
      "|    explained_variance   | 0.86591053   |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0289       |\n",
      "|    n_updates            | 3740         |\n",
      "|    policy_gradient_loss | 0.00132      |\n",
      "|    std                  | 0.0908       |\n",
      "|    value_loss           | 0.161        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 770000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012937392 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.96        |\n",
      "|    explained_variance   | 0.86303926  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | 0.00221     |\n",
      "|    std                  | 0.091       |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 237      |\n",
      "|    iterations      | 376      |\n",
      "|    time_elapsed    | 3239     |\n",
      "|    total_timesteps | 770048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 3245        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010831645 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.83467185  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | 0.00172     |\n",
      "|    std                  | 0.0914      |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 3251        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009208392 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.97        |\n",
      "|    explained_variance   | 0.8412614   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.00082    |\n",
      "|    std                  | 0.09        |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 3257        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008966861 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.02        |\n",
      "|    explained_variance   | 0.88751847  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | 0.00568     |\n",
      "|    std                  | 0.0888      |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 3262        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010084803 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.57961494  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    std                  | 0.0889      |\n",
      "|    value_loss           | 0.274       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 780000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01398931 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.07       |\n",
      "|    explained_variance   | 0.88330036 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0655     |\n",
      "|    n_updates            | 3800       |\n",
      "|    policy_gradient_loss | 0.00195    |\n",
      "|    std                  | 0.0876     |\n",
      "|    value_loss           | 0.148      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 238      |\n",
      "|    iterations      | 381      |\n",
      "|    time_elapsed    | 3269     |\n",
      "|    total_timesteps | 780288   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 3275        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009236585 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 0.81853175  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0623      |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | 0.000227    |\n",
      "|    std                  | 0.0869      |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 3281        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017573109 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.14        |\n",
      "|    explained_variance   | 0.6878384   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | 0.00344     |\n",
      "|    std                  | 0.0869      |\n",
      "|    value_loss           | 0.252       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 3287        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008474573 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.14        |\n",
      "|    explained_variance   | 0.87703097  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0999      |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | 0.00396     |\n",
      "|    std                  | 0.0867      |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 385        |\n",
      "|    time_elapsed         | 3293       |\n",
      "|    total_timesteps      | 788480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01319565 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.13       |\n",
      "|    explained_variance   | 0.8386568  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.142      |\n",
      "|    n_updates            | 3840       |\n",
      "|    policy_gradient_loss | 0.00225    |\n",
      "|    std                  | 0.0873     |\n",
      "|    value_loss           | 0.281      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 0.4        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 790000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01493444 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.1        |\n",
      "|    explained_variance   | 0.759191   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0441     |\n",
      "|    n_updates            | 3850       |\n",
      "|    policy_gradient_loss | -0.00127   |\n",
      "|    std                  | 0.0882     |\n",
      "|    value_loss           | 0.254      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 239      |\n",
      "|    iterations      | 386      |\n",
      "|    time_elapsed    | 3300     |\n",
      "|    total_timesteps | 790528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 3306        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019745696 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.09        |\n",
      "|    explained_variance   | 0.6886578   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0463      |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | 0.00272     |\n",
      "|    std                  | 0.0876      |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 3312        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008920178 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.11        |\n",
      "|    explained_variance   | 0.9175663   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0529      |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | 0.00299     |\n",
      "|    std                  | 0.0875      |\n",
      "|    value_loss           | 0.0805      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 3319        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016125362 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.14        |\n",
      "|    explained_variance   | 0.60586345  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.0866      |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 3325        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011064769 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.17        |\n",
      "|    explained_variance   | 0.85000366  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0498      |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    std                  | 0.086       |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025364865 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.17        |\n",
      "|    explained_variance   | 0.61403674  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0427      |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | 0.00379     |\n",
      "|    std                  | 0.0867      |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13       |\n",
      "| time/              |          |\n",
      "|    fps             | 240      |\n",
      "|    iterations      | 391      |\n",
      "|    time_elapsed    | 3332     |\n",
      "|    total_timesteps | 800768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 3338        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010245644 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.16        |\n",
      "|    explained_variance   | 0.85295033  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0519      |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | 0.00273     |\n",
      "|    std                  | 0.0866      |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 3344        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015353186 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.17        |\n",
      "|    explained_variance   | 0.9005734   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0859      |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.000526   |\n",
      "|    std                  | 0.0865      |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 3350        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014179468 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.19        |\n",
      "|    explained_variance   | 0.7593029   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    std                  | 0.0858      |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 3356        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010561792 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.2         |\n",
      "|    explained_variance   | 0.9086693   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | 0.0013      |\n",
      "|    std                  | 0.0861      |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 810000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010701261 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.86391056  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0793      |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | 0.00368     |\n",
      "|    std                  | 0.0853      |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 12.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 241      |\n",
      "|    iterations      | 396      |\n",
      "|    time_elapsed    | 3363     |\n",
      "|    total_timesteps | 811008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 3369        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016954666 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.27        |\n",
      "|    explained_variance   | 0.638004    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0942      |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | 0.00499     |\n",
      "|    std                  | 0.084       |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 3375        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017722242 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.31        |\n",
      "|    explained_variance   | 0.8805062   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    std                  | 0.0838      |\n",
      "|    value_loss           | 0.0642      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 12.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 399        |\n",
      "|    time_elapsed         | 3381       |\n",
      "|    total_timesteps      | 817152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01077052 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.33       |\n",
      "|    explained_variance   | 0.814428   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0412     |\n",
      "|    n_updates            | 3980       |\n",
      "|    policy_gradient_loss | 0.00576    |\n",
      "|    std                  | 0.0833     |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 3387        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019517757 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.34        |\n",
      "|    explained_variance   | 0.8352693   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | 0.00484     |\n",
      "|    std                  | 0.0836      |\n",
      "|    value_loss           | 0.257       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013541149 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.34        |\n",
      "|    explained_variance   | 0.7700879   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | 0.00178     |\n",
      "|    std                  | 0.0829      |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 12.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 241      |\n",
      "|    iterations      | 401      |\n",
      "|    time_elapsed    | 3395     |\n",
      "|    total_timesteps | 821248   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 3400        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011551668 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.38        |\n",
      "|    explained_variance   | 0.86232764  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    std                  | 0.0821      |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 3407        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014723368 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.43        |\n",
      "|    explained_variance   | 0.8075488   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    std                  | 0.0811      |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 3413        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014744082 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.46        |\n",
      "|    explained_variance   | 0.851084    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0722      |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | 0.00196     |\n",
      "|    std                  | 0.0812      |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 3419        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013627842 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.46        |\n",
      "|    explained_variance   | 0.86194754  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0941      |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | 0.000104    |\n",
      "|    std                  | 0.081       |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 830000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013077952 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.48        |\n",
      "|    explained_variance   | 0.87564886  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0857      |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | 0.000208    |\n",
      "|    std                  | 0.0807      |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13       |\n",
      "| time/              |          |\n",
      "|    fps             | 242      |\n",
      "|    iterations      | 406      |\n",
      "|    time_elapsed    | 3426     |\n",
      "|    total_timesteps | 831488   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 3432        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018225275 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.49        |\n",
      "|    explained_variance   | 0.5736264   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0479      |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | 0.00565     |\n",
      "|    std                  | 0.0802      |\n",
      "|    value_loss           | 0.297       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 13.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 243       |\n",
      "|    iterations           | 408       |\n",
      "|    time_elapsed         | 3438      |\n",
      "|    total_timesteps      | 835584    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0228251 |\n",
      "|    clip_fraction        | 0.237     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.53      |\n",
      "|    explained_variance   | 0.7167354 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.184     |\n",
      "|    n_updates            | 4070      |\n",
      "|    policy_gradient_loss | -0.00043  |\n",
      "|    std                  | 0.0795    |\n",
      "|    value_loss           | 0.221     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 3444       |\n",
      "|    total_timesteps      | 837632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01974827 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.57       |\n",
      "|    explained_variance   | 0.7761256  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.1        |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | -0.000172  |\n",
      "|    std                  | 0.0786     |\n",
      "|    value_loss           | 0.263      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 410        |\n",
      "|    time_elapsed         | 3450       |\n",
      "|    total_timesteps      | 839680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01543626 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.61       |\n",
      "|    explained_variance   | 0.7887714  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.122      |\n",
      "|    n_updates            | 4090       |\n",
      "|    policy_gradient_loss | 0.00481    |\n",
      "|    std                  | 0.078      |\n",
      "|    value_loss           | 0.309      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 840000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016020957 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.63        |\n",
      "|    explained_variance   | 0.87543535  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    std                  | 0.0778      |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 243      |\n",
      "|    iterations      | 411      |\n",
      "|    time_elapsed    | 3457     |\n",
      "|    total_timesteps | 841728   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 3463        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012495933 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.66        |\n",
      "|    explained_variance   | 0.8232741   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0849      |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    std                  | 0.0772      |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 3469        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019181022 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.68        |\n",
      "|    explained_variance   | 0.71761394  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0408      |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.000577   |\n",
      "|    std                  | 0.0774      |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 3475        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019776143 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.66        |\n",
      "|    explained_variance   | 0.8803709   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0713      |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    std                  | 0.0779      |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 3481        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013611796 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.66        |\n",
      "|    explained_variance   | 0.8810483   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | 0.000696    |\n",
      "|    std                  | 0.0778      |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 850000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016991455 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.68        |\n",
      "|    explained_variance   | 0.80467916  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0945      |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | 0.00568     |\n",
      "|    std                  | 0.0773      |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 244      |\n",
      "|    iterations      | 416      |\n",
      "|    time_elapsed    | 3489     |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 3495        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019144833 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.71        |\n",
      "|    explained_variance   | 0.5369556   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | 0.00503     |\n",
      "|    std                  | 0.0766      |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 3501        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011241989 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.74        |\n",
      "|    explained_variance   | 0.92319196  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0395      |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | 0.00315     |\n",
      "|    std                  | 0.0765      |\n",
      "|    value_loss           | 0.0818      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 3507        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018432947 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.75        |\n",
      "|    explained_variance   | 0.63672745  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | 0.00421     |\n",
      "|    std                  | 0.0762      |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 860000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018791579 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.76        |\n",
      "|    explained_variance   | 0.84794044  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0638      |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | 0.00296     |\n",
      "|    std                  | 0.0762      |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 244      |\n",
      "|    iterations      | 420      |\n",
      "|    time_elapsed    | 3515     |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 13.7      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 244       |\n",
      "|    iterations           | 421       |\n",
      "|    time_elapsed         | 3521      |\n",
      "|    total_timesteps      | 862208    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0167229 |\n",
      "|    clip_fraction        | 0.21      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.78      |\n",
      "|    explained_variance   | 0.783616  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.106     |\n",
      "|    n_updates            | 4200      |\n",
      "|    policy_gradient_loss | 0.00208   |\n",
      "|    std                  | 0.0753    |\n",
      "|    value_loss           | 0.176     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 3527        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015551757 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.82        |\n",
      "|    explained_variance   | 0.8799164   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | 0.00414     |\n",
      "|    std                  | 0.0746      |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 13.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 245          |\n",
      "|    iterations           | 423          |\n",
      "|    time_elapsed         | 3533         |\n",
      "|    total_timesteps      | 866304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116395615 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.84         |\n",
      "|    explained_variance   | 0.9437927    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0298       |\n",
      "|    n_updates            | 4220         |\n",
      "|    policy_gradient_loss | 0.00285      |\n",
      "|    std                  | 0.0744       |\n",
      "|    value_loss           | 0.138        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 245        |\n",
      "|    iterations           | 424        |\n",
      "|    time_elapsed         | 3539       |\n",
      "|    total_timesteps      | 868352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01840766 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.86       |\n",
      "|    explained_variance   | 0.82391274 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.157      |\n",
      "|    n_updates            | 4230       |\n",
      "|    policy_gradient_loss | 0.0053     |\n",
      "|    std                  | 0.0743     |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 870000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119355405 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.86         |\n",
      "|    explained_variance   | 0.9055212    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.213        |\n",
      "|    n_updates            | 4240         |\n",
      "|    policy_gradient_loss | 0.00348      |\n",
      "|    std                  | 0.0739       |\n",
      "|    value_loss           | 0.273        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 245      |\n",
      "|    iterations      | 425      |\n",
      "|    time_elapsed    | 3546     |\n",
      "|    total_timesteps | 870400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 3553        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011906025 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.89        |\n",
      "|    explained_variance   | 0.9110449   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | 0.00315     |\n",
      "|    std                  | 0.0735      |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 3559        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029497322 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.92        |\n",
      "|    explained_variance   | 0.9159799   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | 0.00308     |\n",
      "|    std                  | 0.0729      |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 245        |\n",
      "|    iterations           | 428        |\n",
      "|    time_elapsed         | 3565       |\n",
      "|    total_timesteps      | 876544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01583135 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.93       |\n",
      "|    explained_variance   | 0.8155962  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.2        |\n",
      "|    n_updates            | 4270       |\n",
      "|    policy_gradient_loss | 0.00598    |\n",
      "|    std                  | 0.073      |\n",
      "|    value_loss           | 0.311      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 3571        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011436837 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.94        |\n",
      "|    explained_variance   | 0.7761013   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.074       |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | 0.0024      |\n",
      "|    std                  | 0.0723      |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 880000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01339106 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.95       |\n",
      "|    explained_variance   | 0.90321505 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.17       |\n",
      "|    n_updates            | 4290       |\n",
      "|    policy_gradient_loss | 0.0029     |\n",
      "|    std                  | 0.0729     |\n",
      "|    value_loss           | 0.0825     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 246      |\n",
      "|    iterations      | 430      |\n",
      "|    time_elapsed    | 3578     |\n",
      "|    total_timesteps | 880640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 3584        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017937012 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.98        |\n",
      "|    explained_variance   | 0.7514138   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0872      |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | 0.00451     |\n",
      "|    std                  | 0.0715      |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 432        |\n",
      "|    time_elapsed         | 3591       |\n",
      "|    total_timesteps      | 884736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01054888 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.04       |\n",
      "|    explained_variance   | 0.8866361  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0403     |\n",
      "|    n_updates            | 4310       |\n",
      "|    policy_gradient_loss | -0.000156  |\n",
      "|    std                  | 0.0709     |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 3597        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019472692 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.05        |\n",
      "|    explained_variance   | 0.64284354  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.0709      |\n",
      "|    value_loss           | 0.334       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 3603        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024883142 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.08        |\n",
      "|    explained_variance   | 0.62578464  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0976      |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    std                  | 0.07        |\n",
      "|    value_loss           | 0.331       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012945576 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.1         |\n",
      "|    explained_variance   | 0.790373    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.255       |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    std                  | 0.0701      |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 246      |\n",
      "|    iterations      | 435      |\n",
      "|    time_elapsed    | 3611     |\n",
      "|    total_timesteps | 890880   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 3617        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015351695 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.11        |\n",
      "|    explained_variance   | 0.7706371   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | 0.00124     |\n",
      "|    std                  | 0.0699      |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 3623        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017899033 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.11        |\n",
      "|    explained_variance   | 0.9127076   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0887      |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | 0.00566     |\n",
      "|    std                  | 0.0702      |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 3629        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024377342 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.12        |\n",
      "|    explained_variance   | 0.89758265  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0721      |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | 0.00502     |\n",
      "|    std                  | 0.0696      |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 3636        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012511166 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.14        |\n",
      "|    explained_variance   | 0.8568328   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | 0.00397     |\n",
      "|    std                  | 0.0696      |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012368491 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.15        |\n",
      "|    explained_variance   | 0.8877702   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0647      |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | 0.00646     |\n",
      "|    std                  | 0.0694      |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 247      |\n",
      "|    iterations      | 440      |\n",
      "|    time_elapsed    | 3643     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 3649        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018483348 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.15        |\n",
      "|    explained_variance   | 0.8445625   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0934      |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | 0.00413     |\n",
      "|    std                  | 0.0697      |\n",
      "|    value_loss           | 0.263       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 14.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 442        |\n",
      "|    time_elapsed         | 3656       |\n",
      "|    total_timesteps      | 905216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01429899 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.13       |\n",
      "|    explained_variance   | 0.8455437  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.228      |\n",
      "|    n_updates            | 4410       |\n",
      "|    policy_gradient_loss | 0.00486    |\n",
      "|    std                  | 0.0701     |\n",
      "|    value_loss           | 0.233      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 3662        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026180122 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.12        |\n",
      "|    explained_variance   | 0.83224225  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | 0.0079      |\n",
      "|    std                  | 0.0703      |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 14.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 444        |\n",
      "|    time_elapsed         | 3668       |\n",
      "|    total_timesteps      | 909312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01219767 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.12       |\n",
      "|    explained_variance   | 0.7676841  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.159      |\n",
      "|    n_updates            | 4430       |\n",
      "|    policy_gradient_loss | 0.00287    |\n",
      "|    std                  | 0.0702     |\n",
      "|    value_loss           | 0.297      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 910000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015545264 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.14        |\n",
      "|    explained_variance   | 0.6967944   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | 0.00526     |\n",
      "|    std                  | 0.07        |\n",
      "|    value_loss           | 0.319       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 15       |\n",
      "| time/              |          |\n",
      "|    fps             | 247      |\n",
      "|    iterations      | 445      |\n",
      "|    time_elapsed    | 3675     |\n",
      "|    total_timesteps | 911360   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 3681        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018363684 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.18        |\n",
      "|    explained_variance   | 0.7847009   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | 0.0058      |\n",
      "|    std                  | 0.0689      |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 3688        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014751511 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.22        |\n",
      "|    explained_variance   | 0.85494435  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | 0.00142     |\n",
      "|    std                  | 0.0682      |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 3694        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010901736 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.24        |\n",
      "|    explained_variance   | 0.9349372   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0935      |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | 0.00347     |\n",
      "|    std                  | 0.0685      |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 3700        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015885212 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.21        |\n",
      "|    explained_variance   | 0.8319978   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.057       |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.0692      |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=0.40 +/- 0.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013962151 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.2         |\n",
      "|    explained_variance   | 0.7609842   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.23        |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.000704   |\n",
      "|    std                  | 0.0689      |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 248      |\n",
      "|    iterations      | 450      |\n",
      "|    time_elapsed    | 3708     |\n",
      "|    total_timesteps | 921600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 3714        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021258883 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.24        |\n",
      "|    explained_variance   | 0.72607476  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.048       |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.000797   |\n",
      "|    std                  | 0.0683      |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 3720        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012983374 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.27        |\n",
      "|    explained_variance   | 0.86394316  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0474      |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.000352   |\n",
      "|    std                  | 0.0678      |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 15.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 453        |\n",
      "|    time_elapsed         | 3726       |\n",
      "|    total_timesteps      | 927744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0124564  |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.3        |\n",
      "|    explained_variance   | 0.93269813 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0738     |\n",
      "|    n_updates            | 4520       |\n",
      "|    policy_gradient_loss | 0.00176    |\n",
      "|    std                  | 0.0674     |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 15.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 3733        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012222402 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.31        |\n",
      "|    explained_variance   | 0.91409373  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0593      |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | 0.00159     |\n",
      "|    std                  | 0.0675      |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 930000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01667858 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.3        |\n",
      "|    explained_variance   | 0.80037326 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.155      |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | 0.00586    |\n",
      "|    std                  | 0.0679     |\n",
      "|    value_loss           | 0.264      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 15       |\n",
      "| time/              |          |\n",
      "|    fps             | 249      |\n",
      "|    iterations      | 455      |\n",
      "|    time_elapsed    | 3741     |\n",
      "|    total_timesteps | 931840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 3747        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011932021 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.29        |\n",
      "|    explained_variance   | 0.8952683   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000916   |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | 0.00491     |\n",
      "|    std                  | 0.068       |\n",
      "|    value_loss           | 0.0916      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 3753        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012427219 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.31        |\n",
      "|    explained_variance   | 0.8772323   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | 0.00236     |\n",
      "|    std                  | 0.0673      |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 3759        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010361886 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.33        |\n",
      "|    explained_variance   | 0.755555    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0187      |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | 0.00293     |\n",
      "|    std                  | 0.0675      |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 940000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016588464 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.32        |\n",
      "|    explained_variance   | 0.5020904   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | 0.00732     |\n",
      "|    std                  | 0.0676      |\n",
      "|    value_loss           | 0.477       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 249      |\n",
      "|    iterations      | 459      |\n",
      "|    time_elapsed    | 3767     |\n",
      "|    total_timesteps | 940032   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 14.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 460        |\n",
      "|    time_elapsed         | 3774       |\n",
      "|    total_timesteps      | 942080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01737882 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.34       |\n",
      "|    explained_variance   | 0.94799227 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.047      |\n",
      "|    n_updates            | 4590       |\n",
      "|    policy_gradient_loss | 0.00404    |\n",
      "|    std                  | 0.0671     |\n",
      "|    value_loss           | 0.0349     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 3780        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011322111 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.37        |\n",
      "|    explained_variance   | 0.91498053  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.076       |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | 0.00322     |\n",
      "|    std                  | 0.0667      |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 3786        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016081132 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.38        |\n",
      "|    explained_variance   | 0.8787776   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0665      |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | 0.000992    |\n",
      "|    std                  | 0.0667      |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 3793        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011904642 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.39        |\n",
      "|    explained_variance   | 0.94449025  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.04        |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    std                  | 0.0666      |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013177957 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.39        |\n",
      "|    explained_variance   | 0.9269139   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | 0.0048      |\n",
      "|    std                  | 0.0666      |\n",
      "|    value_loss           | 0.0948      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 250      |\n",
      "|    iterations      | 464      |\n",
      "|    time_elapsed    | 3800     |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 3806        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009837968 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.4         |\n",
      "|    explained_variance   | 0.9321787   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | 0.00607     |\n",
      "|    std                  | 0.0662      |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 3813        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022552859 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.41        |\n",
      "|    explained_variance   | 0.9080248   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0377      |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | 0.00582     |\n",
      "|    std                  | 0.0663      |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 14.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 250       |\n",
      "|    iterations           | 467       |\n",
      "|    time_elapsed         | 3819      |\n",
      "|    total_timesteps      | 956416    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0132779 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 5.39      |\n",
      "|    explained_variance   | 0.829257  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.165     |\n",
      "|    n_updates            | 4660      |\n",
      "|    policy_gradient_loss | 0.00203   |\n",
      "|    std                  | 0.0668    |\n",
      "|    value_loss           | 0.215     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | 14.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 468          |\n",
      "|    time_elapsed         | 3825         |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092865685 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 5.38         |\n",
      "|    explained_variance   | 0.8967218    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0965       |\n",
      "|    n_updates            | 4670         |\n",
      "|    policy_gradient_loss | 0.00381      |\n",
      "|    std                  | 0.0663       |\n",
      "|    value_loss           | 0.104        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 960000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01591151 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.39       |\n",
      "|    explained_variance   | 0.89876944 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0695     |\n",
      "|    n_updates            | 4680       |\n",
      "|    policy_gradient_loss | 0.00557    |\n",
      "|    std                  | 0.0665     |\n",
      "|    value_loss           | 0.147      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 250      |\n",
      "|    iterations      | 469      |\n",
      "|    time_elapsed    | 3833     |\n",
      "|    total_timesteps | 960512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 3839        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013554973 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.4         |\n",
      "|    explained_variance   | 0.91347754  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0573      |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | 0.00287     |\n",
      "|    std                  | 0.0668      |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 3846        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021433163 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.41        |\n",
      "|    explained_variance   | 0.8298271   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.243       |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | 0.00647     |\n",
      "|    std                  | 0.0665      |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 3852        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010865582 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.44        |\n",
      "|    explained_variance   | 0.92495483  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | 0.00466     |\n",
      "|    std                  | 0.066       |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 3858        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016618636 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.47        |\n",
      "|    explained_variance   | 0.57969296  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | 0.00896     |\n",
      "|    std                  | 0.0658      |\n",
      "|    value_loss           | 0.51        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=0.80 +/- 1.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 970000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020840786 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.47        |\n",
      "|    explained_variance   | 0.8795464   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.301       |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | 0.00896     |\n",
      "|    std                  | 0.0657      |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 251      |\n",
      "|    iterations      | 474      |\n",
      "|    time_elapsed    | 3866     |\n",
      "|    total_timesteps | 970752   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 3872        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017497798 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.47        |\n",
      "|    explained_variance   | 0.86739564  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.053       |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | 0.00472     |\n",
      "|    std                  | 0.0658      |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 3879        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012913212 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.48        |\n",
      "|    explained_variance   | 0.91995066  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0417      |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | 0.00463     |\n",
      "|    std                  | 0.0659      |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 3885        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011225145 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.48        |\n",
      "|    explained_variance   | 0.7478484   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | 0.00595     |\n",
      "|    std                  | 0.0656      |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 3891        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018845417 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.48        |\n",
      "|    explained_variance   | 0.7724556   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0278      |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | 0.00324     |\n",
      "|    std                  | 0.0657      |\n",
      "|    value_loss           | 0.0947      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 980000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014098031 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.5         |\n",
      "|    explained_variance   | 0.771374    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | 0.00373     |\n",
      "|    std                  | 0.0652      |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 14       |\n",
      "| time/              |          |\n",
      "|    fps             | 251      |\n",
      "|    iterations      | 479      |\n",
      "|    time_elapsed    | 3899     |\n",
      "|    total_timesteps | 980992   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 14.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 480        |\n",
      "|    time_elapsed         | 3906       |\n",
      "|    total_timesteps      | 983040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01688807 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.49       |\n",
      "|    explained_variance   | 0.5392896  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0892     |\n",
      "|    n_updates            | 4790       |\n",
      "|    policy_gradient_loss | 0.00554    |\n",
      "|    std                  | 0.0656     |\n",
      "|    value_loss           | 0.219      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 3912        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025945399 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.48        |\n",
      "|    explained_variance   | 0.67847943  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | 0.0069      |\n",
      "|    std                  | 0.0653      |\n",
      "|    value_loss           | 0.354       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 3918        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015919184 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.49        |\n",
      "|    explained_variance   | 0.880837    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0874      |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | 0.00649     |\n",
      "|    std                  | 0.0653      |\n",
      "|    value_loss           | 0.0734      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 3925        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012073982 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.5         |\n",
      "|    explained_variance   | 0.346672    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 4820        |\n",
      "|    policy_gradient_loss | 0.00336     |\n",
      "|    std                  | 0.0651      |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 990000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018663738 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.52        |\n",
      "|    explained_variance   | 0.8271878   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0417      |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | 0.00536     |\n",
      "|    std                  | 0.0648      |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 484      |\n",
      "|    time_elapsed    | 3932     |\n",
      "|    total_timesteps | 991232   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 3939        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022716075 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.52        |\n",
      "|    explained_variance   | 0.70701045  |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.097       |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | 0.00446     |\n",
      "|    std                  | 0.0651      |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 13.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 486        |\n",
      "|    time_elapsed         | 3945       |\n",
      "|    total_timesteps      | 995328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01632627 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 5.53       |\n",
      "|    explained_variance   | 0.8412467  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.117      |\n",
      "|    n_updates            | 4850       |\n",
      "|    policy_gradient_loss | 0.00173    |\n",
      "|    std                  | 0.0647     |\n",
      "|    value_loss           | 0.245      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 3951        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013663148 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.55        |\n",
      "|    explained_variance   | 0.8094116   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0743      |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | 0.00733     |\n",
      "|    std                  | 0.0642      |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 13.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 3958        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013732664 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.55        |\n",
      "|    explained_variance   | 0.6966721   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | 0.00626     |\n",
      "|    std                  | 0.0642      |\n",
      "|    value_loss           | 0.306       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014266953 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 5.55        |\n",
      "|    explained_variance   | 0.6788579   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | 0.00519     |\n",
      "|    std                  | 0.064       |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 13.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 489      |\n",
      "|    time_elapsed    | 3965     |\n",
      "|    total_timesteps | 1001472  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x103fe6090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"../tmp/logs/2\"\n",
    "\n",
    "new_logger = configure(log_dir, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "model.set_logger(new_logger)\n",
    "\n",
    "eval_env = AppleGameEnv(m=36, n=36, max_steps=1000)\n",
    "\n",
    "# Use deterministic actions for evaluation\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=log_dir,\n",
    "                             log_path=log_dir, eval_freq=10_000, n_eval_episodes=5,\n",
    "                             deterministic=False, render=False)\n",
    "\n",
    "model.learn(total_timesteps=1_000_000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard로 훈련 과정 확인\n",
    "\n",
    "> 루트 디렉토리에서 실행\n",
    "```bash\n",
    "tensorboard --logdir ./tmp/logs/1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../tmp/logs/1\"\n",
    "model = PPO.load(log_dir + \"/best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0, 'steps': 1, 'reward': 0}\n",
      "{'score': 0, 'steps': 2, 'reward': 0}\n",
      "{'score': 0, 'steps': 3, 'reward': 0}\n",
      "{'score': 0, 'steps': 4, 'reward': 0}\n",
      "{'score': 0, 'steps': 5, 'reward': 0}\n",
      "{'score': 0, 'steps': 6, 'reward': 0}\n",
      "{'score': 0, 'steps': 7, 'reward': 0}\n",
      "{'score': 0, 'steps': 8, 'reward': 0}\n",
      "{'score': 0, 'steps': 9, 'reward': 0}\n",
      "{'score': 0, 'steps': 10, 'reward': 0}\n",
      "{'score': 0, 'steps': 11, 'reward': 0}\n",
      "{'score': 0, 'steps': 12, 'reward': 0}\n",
      "{'score': 0, 'steps': 13, 'reward': 0}\n",
      "{'score': 0, 'steps': 14, 'reward': 0}\n",
      "{'score': 0, 'steps': 15, 'reward': 0}\n",
      "{'score': 0, 'steps': 16, 'reward': 0}\n",
      "{'score': 0, 'steps': 17, 'reward': 0}\n",
      "{'score': 0, 'steps': 18, 'reward': 0}\n",
      "{'score': 0, 'steps': 19, 'reward': 0}\n",
      "{'score': 0, 'steps': 20, 'reward': 0}\n",
      "{'score': 0, 'steps': 21, 'reward': 0}\n",
      "{'score': 0, 'steps': 22, 'reward': 0}\n",
      "{'score': 0, 'steps': 23, 'reward': 0}\n",
      "{'score': 0, 'steps': 24, 'reward': 0}\n",
      "{'score': 0, 'steps': 25, 'reward': 0}\n",
      "{'score': 0, 'steps': 26, 'reward': 0}\n",
      "{'score': 0, 'steps': 27, 'reward': 0}\n",
      "{'score': 0, 'steps': 28, 'reward': 0}\n",
      "{'score': 0, 'steps': 29, 'reward': 0}\n",
      "{'score': 0, 'steps': 30, 'reward': 0}\n",
      "{'score': 0, 'steps': 31, 'reward': 0}\n",
      "{'score': 0, 'steps': 32, 'reward': 0}\n",
      "{'score': 0, 'steps': 33, 'reward': 0}\n",
      "{'score': 0, 'steps': 34, 'reward': 0}\n",
      "{'score': 0, 'steps': 35, 'reward': 0}\n",
      "{'score': 0, 'steps': 36, 'reward': 0}\n",
      "{'score': 0, 'steps': 37, 'reward': 0}\n",
      "{'score': 0, 'steps': 38, 'reward': 0}\n",
      "{'score': 0, 'steps': 39, 'reward': 0}\n",
      "{'score': 0, 'steps': 40, 'reward': 0}\n",
      "{'score': 0, 'steps': 41, 'reward': 0}\n",
      "{'score': 0, 'steps': 42, 'reward': 0}\n",
      "{'score': 0, 'steps': 43, 'reward': 0}\n",
      "{'score': 0, 'steps': 44, 'reward': 0}\n",
      "{'score': 0, 'steps': 45, 'reward': 0}\n",
      "{'score': 0, 'steps': 46, 'reward': 0}\n",
      "{'score': 0, 'steps': 47, 'reward': 0}\n",
      "{'score': 0, 'steps': 48, 'reward': 0}\n",
      "{'score': 0, 'steps': 49, 'reward': 0}\n",
      "{'score': 0, 'steps': 50, 'reward': 0}\n",
      "{'score': 0, 'steps': 51, 'reward': 0}\n",
      "{'score': 0, 'steps': 52, 'reward': 0}\n",
      "{'score': 0, 'steps': 53, 'reward': 0}\n",
      "{'score': 0, 'steps': 54, 'reward': 0}\n",
      "{'score': 0, 'steps': 55, 'reward': 0}\n",
      "{'score': 0, 'steps': 56, 'reward': 0}\n",
      "{'score': 0, 'steps': 57, 'reward': 0}\n",
      "{'score': 0, 'steps': 58, 'reward': 0}\n",
      "{'score': 0, 'steps': 59, 'reward': 0}\n",
      "{'score': 0, 'steps': 60, 'reward': 0}\n",
      "{'score': 0, 'steps': 61, 'reward': 0}\n",
      "{'score': 0, 'steps': 62, 'reward': 0}\n",
      "{'score': 0, 'steps': 63, 'reward': 0}\n",
      "{'score': 0, 'steps': 64, 'reward': 0}\n",
      "{'score': 0, 'steps': 65, 'reward': 0}\n",
      "{'score': 0, 'steps': 66, 'reward': 0}\n",
      "{'score': 0, 'steps': 67, 'reward': 0}\n",
      "{'score': 0, 'steps': 68, 'reward': 0}\n",
      "{'score': 0, 'steps': 69, 'reward': 0}\n",
      "{'score': 0, 'steps': 70, 'reward': 0}\n",
      "{'score': 0, 'steps': 71, 'reward': 0}\n",
      "{'score': 0, 'steps': 72, 'reward': 0}\n",
      "{'score': 0, 'steps': 73, 'reward': 0}\n",
      "{'score': 0, 'steps': 74, 'reward': 0}\n",
      "{'score': 0, 'steps': 75, 'reward': 0}\n",
      "{'score': 0, 'steps': 76, 'reward': 0}\n",
      "{'score': 0, 'steps': 77, 'reward': 0}\n",
      "{'score': 0, 'steps': 78, 'reward': 0}\n",
      "{'score': 0, 'steps': 79, 'reward': 0}\n",
      "{'score': 0, 'steps': 80, 'reward': 0}\n",
      "{'score': 0, 'steps': 81, 'reward': 0}\n",
      "{'score': 0, 'steps': 82, 'reward': 0}\n",
      "{'score': 0, 'steps': 83, 'reward': 0}\n",
      "{'score': 0, 'steps': 84, 'reward': 0}\n",
      "{'score': 0, 'steps': 85, 'reward': 0}\n",
      "{'score': 0, 'steps': 86, 'reward': 0}\n",
      "{'score': 0, 'steps': 87, 'reward': 0}\n",
      "{'score': 0, 'steps': 88, 'reward': 0}\n",
      "{'score': 0, 'steps': 89, 'reward': 0}\n",
      "{'score': 0, 'steps': 90, 'reward': 0}\n",
      "{'score': 0, 'steps': 91, 'reward': 0}\n",
      "{'score': 0, 'steps': 92, 'reward': 0}\n",
      "{'score': 0, 'steps': 93, 'reward': 0}\n",
      "{'score': 0, 'steps': 94, 'reward': 0}\n",
      "{'score': 0, 'steps': 95, 'reward': 0}\n",
      "{'score': 0, 'steps': 96, 'reward': 0}\n",
      "{'score': 0, 'steps': 97, 'reward': 0}\n",
      "{'score': 0, 'steps': 98, 'reward': 0}\n",
      "{'score': 0, 'steps': 99, 'reward': 0}\n",
      "{'score': 0, 'steps': 100, 'reward': 0}\n",
      "{'score': 0, 'steps': 101, 'reward': 0}\n",
      "{'score': 0, 'steps': 102, 'reward': 0}\n",
      "{'score': 0, 'steps': 103, 'reward': 0}\n",
      "{'score': 0, 'steps': 104, 'reward': 0}\n",
      "{'score': 0, 'steps': 105, 'reward': 0}\n",
      "{'score': 0, 'steps': 106, 'reward': 0}\n",
      "{'score': 0, 'steps': 107, 'reward': 0}\n",
      "{'score': 0, 'steps': 108, 'reward': 0}\n",
      "{'score': 0, 'steps': 109, 'reward': 0}\n",
      "{'score': 0, 'steps': 110, 'reward': 0}\n",
      "{'score': 0, 'steps': 111, 'reward': 0}\n",
      "{'score': 0, 'steps': 112, 'reward': 0}\n",
      "{'score': 0, 'steps': 113, 'reward': 0}\n",
      "{'score': 0, 'steps': 114, 'reward': 0}\n",
      "{'score': 0, 'steps': 115, 'reward': 0}\n",
      "{'score': 0, 'steps': 116, 'reward': 0}\n",
      "{'score': 0, 'steps': 117, 'reward': 0}\n",
      "{'score': 0, 'steps': 118, 'reward': 0}\n",
      "{'score': 0, 'steps': 119, 'reward': 0}\n",
      "{'score': 0, 'steps': 120, 'reward': 0}\n",
      "{'score': 0, 'steps': 121, 'reward': 0}\n",
      "{'score': 0, 'steps': 122, 'reward': 0}\n",
      "{'score': 0, 'steps': 123, 'reward': 0}\n",
      "{'score': 0, 'steps': 124, 'reward': 0}\n",
      "{'score': 0, 'steps': 125, 'reward': 0}\n",
      "{'score': 0, 'steps': 126, 'reward': 0}\n",
      "{'score': 0, 'steps': 127, 'reward': 0}\n",
      "{'score': 0, 'steps': 128, 'reward': 0}\n",
      "{'score': 0, 'steps': 129, 'reward': 0}\n",
      "{'score': 0, 'steps': 130, 'reward': 0}\n",
      "{'score': 0, 'steps': 131, 'reward': 0}\n",
      "{'score': 0, 'steps': 132, 'reward': 0}\n",
      "{'score': 0, 'steps': 133, 'reward': 0}\n",
      "{'score': 0, 'steps': 134, 'reward': 0}\n",
      "{'score': 0, 'steps': 135, 'reward': 0}\n",
      "{'score': 0, 'steps': 136, 'reward': 0}\n",
      "{'score': 0, 'steps': 137, 'reward': 0}\n",
      "{'score': 0, 'steps': 138, 'reward': 0}\n",
      "{'score': 0, 'steps': 139, 'reward': 0}\n",
      "{'score': 0, 'steps': 140, 'reward': 0}\n",
      "{'score': 0, 'steps': 141, 'reward': 0}\n",
      "{'score': 0, 'steps': 142, 'reward': 0}\n",
      "{'score': 0, 'steps': 143, 'reward': 0}\n",
      "{'score': 0, 'steps': 144, 'reward': 0}\n",
      "{'score': 0, 'steps': 145, 'reward': 0}\n",
      "{'score': 0, 'steps': 146, 'reward': 0}\n",
      "{'score': 0, 'steps': 147, 'reward': 0}\n",
      "{'score': 0, 'steps': 148, 'reward': 0}\n",
      "{'score': 0, 'steps': 149, 'reward': 0}\n",
      "{'score': 0, 'steps': 150, 'reward': 0}\n",
      "{'score': 0, 'steps': 151, 'reward': 0}\n",
      "{'score': 0, 'steps': 152, 'reward': 0}\n",
      "{'score': 0, 'steps': 153, 'reward': 0}\n",
      "{'score': 0, 'steps': 154, 'reward': 0}\n",
      "{'score': 0, 'steps': 155, 'reward': 0}\n",
      "{'score': 0, 'steps': 156, 'reward': 0}\n",
      "{'score': 0, 'steps': 157, 'reward': 0}\n",
      "{'score': 0, 'steps': 158, 'reward': 0}\n",
      "{'score': 0, 'steps': 159, 'reward': 0}\n",
      "{'score': 0, 'steps': 160, 'reward': 0}\n",
      "{'score': 2, 'steps': 161, 'reward': 2}\n",
      "{'score': 2, 'steps': 162, 'reward': 0}\n",
      "{'score': 2, 'steps': 163, 'reward': 0}\n",
      "{'score': 2, 'steps': 164, 'reward': 0}\n",
      "{'score': 2, 'steps': 165, 'reward': 0}\n",
      "{'score': 2, 'steps': 166, 'reward': 0}\n",
      "{'score': 2, 'steps': 167, 'reward': 0}\n",
      "{'score': 2, 'steps': 168, 'reward': 0}\n",
      "{'score': 2, 'steps': 169, 'reward': 0}\n",
      "{'score': 2, 'steps': 170, 'reward': 0}\n",
      "{'score': 2, 'steps': 171, 'reward': 0}\n",
      "{'score': 2, 'steps': 172, 'reward': 0}\n",
      "{'score': 2, 'steps': 173, 'reward': 0}\n",
      "{'score': 2, 'steps': 174, 'reward': 0}\n",
      "{'score': 2, 'steps': 175, 'reward': 0}\n",
      "{'score': 2, 'steps': 176, 'reward': 0}\n",
      "{'score': 2, 'steps': 177, 'reward': 0}\n",
      "{'score': 2, 'steps': 178, 'reward': 0}\n",
      "{'score': 2, 'steps': 179, 'reward': 0}\n",
      "{'score': 2, 'steps': 180, 'reward': 0}\n",
      "{'score': 2, 'steps': 181, 'reward': 0}\n",
      "{'score': 2, 'steps': 182, 'reward': 0}\n",
      "{'score': 2, 'steps': 183, 'reward': 0}\n",
      "{'score': 2, 'steps': 184, 'reward': 0}\n",
      "{'score': 2, 'steps': 185, 'reward': 0}\n",
      "{'score': 2, 'steps': 186, 'reward': 0}\n",
      "{'score': 2, 'steps': 187, 'reward': 0}\n",
      "{'score': 2, 'steps': 188, 'reward': 0}\n",
      "{'score': 2, 'steps': 189, 'reward': 0}\n",
      "{'score': 2, 'steps': 190, 'reward': 0}\n",
      "{'score': 2, 'steps': 191, 'reward': 0}\n",
      "{'score': 2, 'steps': 192, 'reward': 0}\n",
      "{'score': 2, 'steps': 193, 'reward': 0}\n",
      "{'score': 2, 'steps': 194, 'reward': 0}\n",
      "{'score': 2, 'steps': 195, 'reward': 0}\n",
      "{'score': 2, 'steps': 196, 'reward': 0}\n",
      "{'score': 2, 'steps': 197, 'reward': 0}\n",
      "{'score': 2, 'steps': 198, 'reward': 0}\n",
      "{'score': 2, 'steps': 199, 'reward': 0}\n",
      "{'score': 2, 'steps': 200, 'reward': 0}\n",
      "{'score': 2, 'steps': 201, 'reward': 0}\n",
      "{'score': 2, 'steps': 202, 'reward': 0}\n",
      "{'score': 2, 'steps': 203, 'reward': 0}\n",
      "{'score': 2, 'steps': 204, 'reward': 0}\n",
      "{'score': 2, 'steps': 205, 'reward': 0}\n",
      "{'score': 2, 'steps': 206, 'reward': 0}\n",
      "{'score': 2, 'steps': 207, 'reward': 0}\n",
      "{'score': 2, 'steps': 208, 'reward': 0}\n",
      "{'score': 2, 'steps': 209, 'reward': 0}\n",
      "{'score': 2, 'steps': 210, 'reward': 0}\n",
      "{'score': 2, 'steps': 211, 'reward': 0}\n",
      "{'score': 2, 'steps': 212, 'reward': 0}\n",
      "{'score': 2, 'steps': 213, 'reward': 0}\n",
      "{'score': 2, 'steps': 214, 'reward': 0}\n",
      "{'score': 2, 'steps': 215, 'reward': 0}\n",
      "{'score': 2, 'steps': 216, 'reward': 0}\n",
      "{'score': 2, 'steps': 217, 'reward': 0}\n",
      "{'score': 2, 'steps': 218, 'reward': 0}\n",
      "{'score': 2, 'steps': 219, 'reward': 0}\n",
      "{'score': 2, 'steps': 220, 'reward': 0}\n",
      "{'score': 2, 'steps': 221, 'reward': 0}\n",
      "{'score': 2, 'steps': 222, 'reward': 0}\n",
      "{'score': 2, 'steps': 223, 'reward': 0}\n",
      "{'score': 2, 'steps': 224, 'reward': 0}\n",
      "{'score': 2, 'steps': 225, 'reward': 0}\n",
      "{'score': 2, 'steps': 226, 'reward': 0}\n",
      "{'score': 2, 'steps': 227, 'reward': 0}\n",
      "{'score': 2, 'steps': 228, 'reward': 0}\n",
      "{'score': 2, 'steps': 229, 'reward': 0}\n",
      "{'score': 2, 'steps': 230, 'reward': 0}\n",
      "{'score': 2, 'steps': 231, 'reward': 0}\n",
      "{'score': 2, 'steps': 232, 'reward': 0}\n",
      "{'score': 2, 'steps': 233, 'reward': 0}\n",
      "{'score': 2, 'steps': 234, 'reward': 0}\n",
      "{'score': 2, 'steps': 235, 'reward': 0}\n",
      "{'score': 2, 'steps': 236, 'reward': 0}\n",
      "{'score': 2, 'steps': 237, 'reward': 0}\n",
      "{'score': 2, 'steps': 238, 'reward': 0}\n",
      "{'score': 2, 'steps': 239, 'reward': 0}\n",
      "{'score': 2, 'steps': 240, 'reward': 0}\n",
      "{'score': 2, 'steps': 241, 'reward': 0}\n",
      "{'score': 2, 'steps': 242, 'reward': 0}\n",
      "{'score': 2, 'steps': 243, 'reward': 0}\n",
      "{'score': 2, 'steps': 244, 'reward': 0}\n",
      "{'score': 2, 'steps': 245, 'reward': 0}\n",
      "{'score': 2, 'steps': 246, 'reward': 0}\n",
      "{'score': 2, 'steps': 247, 'reward': 0}\n",
      "{'score': 2, 'steps': 248, 'reward': 0}\n",
      "{'score': 2, 'steps': 249, 'reward': 0}\n",
      "{'score': 2, 'steps': 250, 'reward': 0}\n",
      "{'score': 2, 'steps': 251, 'reward': 0}\n",
      "{'score': 2, 'steps': 252, 'reward': 0}\n",
      "{'score': 2, 'steps': 253, 'reward': 0}\n",
      "{'score': 2, 'steps': 254, 'reward': 0}\n",
      "{'score': 2, 'steps': 255, 'reward': 0}\n",
      "{'score': 2, 'steps': 256, 'reward': 0}\n",
      "{'score': 2, 'steps': 257, 'reward': 0}\n",
      "{'score': 2, 'steps': 258, 'reward': 0}\n",
      "{'score': 2, 'steps': 259, 'reward': 0}\n",
      "{'score': 2, 'steps': 260, 'reward': 0}\n",
      "{'score': 2, 'steps': 261, 'reward': 0}\n",
      "{'score': 2, 'steps': 262, 'reward': 0}\n",
      "{'score': 2, 'steps': 263, 'reward': 0}\n",
      "{'score': 2, 'steps': 264, 'reward': 0}\n",
      "{'score': 2, 'steps': 265, 'reward': 0}\n",
      "{'score': 2, 'steps': 266, 'reward': 0}\n",
      "{'score': 2, 'steps': 267, 'reward': 0}\n",
      "{'score': 2, 'steps': 268, 'reward': 0}\n",
      "{'score': 2, 'steps': 269, 'reward': 0}\n",
      "{'score': 2, 'steps': 270, 'reward': 0}\n",
      "{'score': 2, 'steps': 271, 'reward': 0}\n",
      "{'score': 2, 'steps': 272, 'reward': 0}\n",
      "{'score': 2, 'steps': 273, 'reward': 0}\n",
      "{'score': 2, 'steps': 274, 'reward': 0}\n",
      "{'score': 2, 'steps': 275, 'reward': 0}\n",
      "{'score': 2, 'steps': 276, 'reward': 0}\n",
      "{'score': 2, 'steps': 277, 'reward': 0}\n",
      "{'score': 2, 'steps': 278, 'reward': 0}\n",
      "{'score': 2, 'steps': 279, 'reward': 0}\n",
      "{'score': 2, 'steps': 280, 'reward': 0}\n",
      "{'score': 2, 'steps': 281, 'reward': 0}\n",
      "{'score': 2, 'steps': 282, 'reward': 0}\n",
      "{'score': 2, 'steps': 283, 'reward': 0}\n",
      "{'score': 2, 'steps': 284, 'reward': 0}\n",
      "{'score': 2, 'steps': 285, 'reward': 0}\n",
      "{'score': 2, 'steps': 286, 'reward': 0}\n",
      "{'score': 2, 'steps': 287, 'reward': 0}\n",
      "{'score': 2, 'steps': 288, 'reward': 0}\n",
      "{'score': 2, 'steps': 289, 'reward': 0}\n",
      "{'score': 2, 'steps': 290, 'reward': 0}\n",
      "{'score': 2, 'steps': 291, 'reward': 0}\n",
      "{'score': 2, 'steps': 292, 'reward': 0}\n",
      "{'score': 2, 'steps': 293, 'reward': 0}\n",
      "{'score': 2, 'steps': 294, 'reward': 0}\n",
      "{'score': 2, 'steps': 295, 'reward': 0}\n",
      "{'score': 4, 'steps': 296, 'reward': 2}\n",
      "{'score': 4, 'steps': 297, 'reward': 0}\n",
      "{'score': 4, 'steps': 298, 'reward': 0}\n",
      "{'score': 4, 'steps': 299, 'reward': 0}\n",
      "{'score': 4, 'steps': 300, 'reward': 0}\n",
      "{'score': 4, 'steps': 301, 'reward': 0}\n",
      "{'score': 4, 'steps': 302, 'reward': 0}\n",
      "{'score': 4, 'steps': 303, 'reward': 0}\n",
      "{'score': 4, 'steps': 304, 'reward': 0}\n",
      "{'score': 4, 'steps': 305, 'reward': 0}\n",
      "{'score': 4, 'steps': 306, 'reward': 0}\n",
      "{'score': 4, 'steps': 307, 'reward': 0}\n",
      "{'score': 4, 'steps': 308, 'reward': 0}\n",
      "{'score': 4, 'steps': 309, 'reward': 0}\n",
      "{'score': 4, 'steps': 310, 'reward': 0}\n",
      "{'score': 4, 'steps': 311, 'reward': 0}\n",
      "{'score': 4, 'steps': 312, 'reward': 0}\n",
      "{'score': 4, 'steps': 313, 'reward': 0}\n",
      "{'score': 4, 'steps': 314, 'reward': 0}\n",
      "{'score': 4, 'steps': 315, 'reward': 0}\n",
      "{'score': 4, 'steps': 316, 'reward': 0}\n",
      "{'score': 4, 'steps': 317, 'reward': 0}\n",
      "{'score': 4, 'steps': 318, 'reward': 0}\n",
      "{'score': 4, 'steps': 319, 'reward': 0}\n",
      "{'score': 4, 'steps': 320, 'reward': 0}\n",
      "{'score': 4, 'steps': 321, 'reward': 0}\n",
      "{'score': 4, 'steps': 322, 'reward': 0}\n",
      "{'score': 4, 'steps': 323, 'reward': 0}\n",
      "{'score': 4, 'steps': 324, 'reward': 0}\n",
      "{'score': 4, 'steps': 325, 'reward': 0}\n",
      "{'score': 4, 'steps': 326, 'reward': 0}\n",
      "{'score': 4, 'steps': 327, 'reward': 0}\n",
      "{'score': 4, 'steps': 328, 'reward': 0}\n",
      "{'score': 4, 'steps': 329, 'reward': 0}\n",
      "{'score': 4, 'steps': 330, 'reward': 0}\n",
      "{'score': 4, 'steps': 331, 'reward': 0}\n",
      "{'score': 4, 'steps': 332, 'reward': 0}\n",
      "{'score': 4, 'steps': 333, 'reward': 0}\n",
      "{'score': 4, 'steps': 334, 'reward': 0}\n",
      "{'score': 4, 'steps': 335, 'reward': 0}\n",
      "{'score': 4, 'steps': 336, 'reward': 0}\n",
      "{'score': 4, 'steps': 337, 'reward': 0}\n",
      "{'score': 4, 'steps': 338, 'reward': 0}\n",
      "{'score': 4, 'steps': 339, 'reward': 0}\n",
      "{'score': 4, 'steps': 340, 'reward': 0}\n",
      "{'score': 4, 'steps': 341, 'reward': 0}\n",
      "{'score': 4, 'steps': 342, 'reward': 0}\n",
      "{'score': 4, 'steps': 343, 'reward': 0}\n",
      "{'score': 4, 'steps': 344, 'reward': 0}\n",
      "{'score': 4, 'steps': 345, 'reward': 0}\n",
      "{'score': 4, 'steps': 346, 'reward': 0}\n",
      "{'score': 4, 'steps': 347, 'reward': 0}\n",
      "{'score': 4, 'steps': 348, 'reward': 0}\n",
      "{'score': 4, 'steps': 349, 'reward': 0}\n",
      "{'score': 4, 'steps': 350, 'reward': 0}\n",
      "{'score': 4, 'steps': 351, 'reward': 0}\n",
      "{'score': 4, 'steps': 352, 'reward': 0}\n",
      "{'score': 4, 'steps': 353, 'reward': 0}\n",
      "{'score': 4, 'steps': 354, 'reward': 0}\n",
      "{'score': 4, 'steps': 355, 'reward': 0}\n",
      "{'score': 4, 'steps': 356, 'reward': 0}\n",
      "{'score': 4, 'steps': 357, 'reward': 0}\n",
      "{'score': 4, 'steps': 358, 'reward': 0}\n",
      "{'score': 4, 'steps': 359, 'reward': 0}\n",
      "{'score': 4, 'steps': 360, 'reward': 0}\n",
      "{'score': 4, 'steps': 361, 'reward': 0}\n",
      "{'score': 4, 'steps': 362, 'reward': 0}\n",
      "{'score': 4, 'steps': 363, 'reward': 0}\n",
      "{'score': 4, 'steps': 364, 'reward': 0}\n",
      "{'score': 4, 'steps': 365, 'reward': 0}\n",
      "{'score': 4, 'steps': 366, 'reward': 0}\n",
      "{'score': 4, 'steps': 367, 'reward': 0}\n",
      "{'score': 4, 'steps': 368, 'reward': 0}\n",
      "{'score': 4, 'steps': 369, 'reward': 0}\n",
      "{'score': 4, 'steps': 370, 'reward': 0}\n",
      "{'score': 4, 'steps': 371, 'reward': 0}\n",
      "{'score': 4, 'steps': 372, 'reward': 0}\n",
      "{'score': 4, 'steps': 373, 'reward': 0}\n",
      "{'score': 4, 'steps': 374, 'reward': 0}\n",
      "{'score': 4, 'steps': 375, 'reward': 0}\n",
      "{'score': 4, 'steps': 376, 'reward': 0}\n",
      "{'score': 4, 'steps': 377, 'reward': 0}\n",
      "{'score': 4, 'steps': 378, 'reward': 0}\n",
      "{'score': 4, 'steps': 379, 'reward': 0}\n",
      "{'score': 4, 'steps': 380, 'reward': 0}\n",
      "{'score': 4, 'steps': 381, 'reward': 0}\n",
      "{'score': 4, 'steps': 382, 'reward': 0}\n",
      "{'score': 4, 'steps': 383, 'reward': 0}\n",
      "{'score': 4, 'steps': 384, 'reward': 0}\n",
      "{'score': 4, 'steps': 385, 'reward': 0}\n",
      "{'score': 7, 'steps': 386, 'reward': 3}\n",
      "{'score': 7, 'steps': 387, 'reward': 0}\n",
      "{'score': 7, 'steps': 388, 'reward': 0}\n",
      "{'score': 7, 'steps': 389, 'reward': 0}\n",
      "{'score': 7, 'steps': 390, 'reward': 0}\n",
      "{'score': 7, 'steps': 391, 'reward': 0}\n",
      "{'score': 7, 'steps': 392, 'reward': 0}\n",
      "{'score': 7, 'steps': 393, 'reward': 0}\n",
      "{'score': 7, 'steps': 394, 'reward': 0}\n",
      "{'score': 7, 'steps': 395, 'reward': 0}\n",
      "{'score': 7, 'steps': 396, 'reward': 0}\n",
      "{'score': 7, 'steps': 397, 'reward': 0}\n",
      "{'score': 7, 'steps': 398, 'reward': 0}\n",
      "{'score': 7, 'steps': 399, 'reward': 0}\n",
      "{'score': 7, 'steps': 400, 'reward': 0}\n",
      "{'score': 7, 'steps': 401, 'reward': 0}\n",
      "{'score': 7, 'steps': 402, 'reward': 0}\n",
      "{'score': 7, 'steps': 403, 'reward': 0}\n",
      "{'score': 7, 'steps': 404, 'reward': 0}\n",
      "{'score': 7, 'steps': 405, 'reward': 0}\n",
      "{'score': 7, 'steps': 406, 'reward': 0}\n",
      "{'score': 7, 'steps': 407, 'reward': 0}\n",
      "{'score': 7, 'steps': 408, 'reward': 0}\n",
      "{'score': 7, 'steps': 409, 'reward': 0}\n",
      "{'score': 7, 'steps': 410, 'reward': 0}\n",
      "{'score': 7, 'steps': 411, 'reward': 0}\n",
      "{'score': 7, 'steps': 412, 'reward': 0}\n",
      "{'score': 7, 'steps': 413, 'reward': 0}\n",
      "{'score': 7, 'steps': 414, 'reward': 0}\n",
      "{'score': 7, 'steps': 415, 'reward': 0}\n",
      "{'score': 7, 'steps': 416, 'reward': 0}\n",
      "{'score': 7, 'steps': 417, 'reward': 0}\n",
      "{'score': 7, 'steps': 418, 'reward': 0}\n",
      "{'score': 7, 'steps': 419, 'reward': 0}\n",
      "{'score': 7, 'steps': 420, 'reward': 0}\n",
      "{'score': 7, 'steps': 421, 'reward': 0}\n",
      "{'score': 7, 'steps': 422, 'reward': 0}\n",
      "{'score': 7, 'steps': 423, 'reward': 0}\n",
      "{'score': 7, 'steps': 424, 'reward': 0}\n",
      "{'score': 7, 'steps': 425, 'reward': 0}\n",
      "{'score': 7, 'steps': 426, 'reward': 0}\n",
      "{'score': 7, 'steps': 427, 'reward': 0}\n",
      "{'score': 7, 'steps': 428, 'reward': 0}\n",
      "{'score': 7, 'steps': 429, 'reward': 0}\n",
      "{'score': 7, 'steps': 430, 'reward': 0}\n",
      "{'score': 7, 'steps': 431, 'reward': 0}\n",
      "{'score': 7, 'steps': 432, 'reward': 0}\n",
      "{'score': 7, 'steps': 433, 'reward': 0}\n",
      "{'score': 7, 'steps': 434, 'reward': 0}\n",
      "{'score': 7, 'steps': 435, 'reward': 0}\n",
      "{'score': 7, 'steps': 436, 'reward': 0}\n",
      "{'score': 7, 'steps': 437, 'reward': 0}\n",
      "{'score': 7, 'steps': 438, 'reward': 0}\n",
      "{'score': 7, 'steps': 439, 'reward': 0}\n",
      "{'score': 7, 'steps': 440, 'reward': 0}\n",
      "{'score': 7, 'steps': 441, 'reward': 0}\n",
      "{'score': 7, 'steps': 442, 'reward': 0}\n",
      "{'score': 7, 'steps': 443, 'reward': 0}\n",
      "{'score': 7, 'steps': 444, 'reward': 0}\n",
      "{'score': 7, 'steps': 445, 'reward': 0}\n",
      "{'score': 7, 'steps': 446, 'reward': 0}\n",
      "{'score': 7, 'steps': 447, 'reward': 0}\n",
      "{'score': 7, 'steps': 448, 'reward': 0}\n",
      "{'score': 7, 'steps': 449, 'reward': 0}\n",
      "{'score': 7, 'steps': 450, 'reward': 0}\n",
      "{'score': 7, 'steps': 451, 'reward': 0}\n",
      "{'score': 7, 'steps': 452, 'reward': 0}\n",
      "{'score': 7, 'steps': 453, 'reward': 0}\n",
      "{'score': 7, 'steps': 454, 'reward': 0}\n",
      "{'score': 7, 'steps': 455, 'reward': 0}\n",
      "{'score': 7, 'steps': 456, 'reward': 0}\n",
      "{'score': 7, 'steps': 457, 'reward': 0}\n",
      "{'score': 7, 'steps': 458, 'reward': 0}\n",
      "{'score': 7, 'steps': 459, 'reward': 0}\n",
      "{'score': 7, 'steps': 460, 'reward': 0}\n",
      "{'score': 7, 'steps': 461, 'reward': 0}\n",
      "{'score': 7, 'steps': 462, 'reward': 0}\n",
      "{'score': 7, 'steps': 463, 'reward': 0}\n",
      "{'score': 7, 'steps': 464, 'reward': 0}\n",
      "{'score': 7, 'steps': 465, 'reward': 0}\n",
      "{'score': 7, 'steps': 466, 'reward': 0}\n",
      "{'score': 7, 'steps': 467, 'reward': 0}\n",
      "{'score': 7, 'steps': 468, 'reward': 0}\n",
      "{'score': 7, 'steps': 469, 'reward': 0}\n",
      "{'score': 7, 'steps': 470, 'reward': 0}\n",
      "{'score': 7, 'steps': 471, 'reward': 0}\n",
      "{'score': 7, 'steps': 472, 'reward': 0}\n",
      "{'score': 7, 'steps': 473, 'reward': 0}\n",
      "{'score': 7, 'steps': 474, 'reward': 0}\n",
      "{'score': 7, 'steps': 475, 'reward': 0}\n",
      "{'score': 7, 'steps': 476, 'reward': 0}\n",
      "{'score': 7, 'steps': 477, 'reward': 0}\n",
      "{'score': 7, 'steps': 478, 'reward': 0}\n",
      "{'score': 7, 'steps': 479, 'reward': 0}\n",
      "{'score': 7, 'steps': 480, 'reward': 0}\n",
      "{'score': 7, 'steps': 481, 'reward': 0}\n",
      "{'score': 7, 'steps': 482, 'reward': 0}\n",
      "{'score': 7, 'steps': 483, 'reward': 0}\n",
      "{'score': 7, 'steps': 484, 'reward': 0}\n",
      "{'score': 7, 'steps': 485, 'reward': 0}\n",
      "{'score': 7, 'steps': 486, 'reward': 0}\n",
      "{'score': 7, 'steps': 487, 'reward': 0}\n",
      "{'score': 7, 'steps': 488, 'reward': 0}\n",
      "{'score': 7, 'steps': 489, 'reward': 0}\n",
      "{'score': 7, 'steps': 490, 'reward': 0}\n",
      "{'score': 7, 'steps': 491, 'reward': 0}\n",
      "{'score': 7, 'steps': 492, 'reward': 0}\n",
      "{'score': 7, 'steps': 493, 'reward': 0}\n",
      "{'score': 7, 'steps': 494, 'reward': 0}\n",
      "{'score': 7, 'steps': 495, 'reward': 0}\n",
      "{'score': 7, 'steps': 496, 'reward': 0}\n",
      "{'score': 7, 'steps': 497, 'reward': 0}\n",
      "{'score': 7, 'steps': 498, 'reward': 0}\n",
      "{'score': 7, 'steps': 499, 'reward': 0}\n",
      "{'score': 7, 'steps': 500, 'reward': 0}\n",
      "{'score': 7, 'steps': 501, 'reward': 0}\n",
      "{'score': 7, 'steps': 502, 'reward': 0}\n",
      "{'score': 7, 'steps': 503, 'reward': 0}\n",
      "{'score': 7, 'steps': 504, 'reward': 0}\n",
      "{'score': 7, 'steps': 505, 'reward': 0}\n",
      "{'score': 7, 'steps': 506, 'reward': 0}\n",
      "{'score': 7, 'steps': 507, 'reward': 0}\n",
      "{'score': 7, 'steps': 508, 'reward': 0}\n",
      "{'score': 7, 'steps': 509, 'reward': 0}\n",
      "{'score': 7, 'steps': 510, 'reward': 0}\n",
      "{'score': 7, 'steps': 511, 'reward': 0}\n",
      "{'score': 7, 'steps': 512, 'reward': 0}\n",
      "{'score': 7, 'steps': 513, 'reward': 0}\n",
      "{'score': 7, 'steps': 514, 'reward': 0}\n",
      "{'score': 7, 'steps': 515, 'reward': 0}\n",
      "{'score': 7, 'steps': 516, 'reward': 0}\n",
      "{'score': 7, 'steps': 517, 'reward': 0}\n",
      "{'score': 7, 'steps': 518, 'reward': 0}\n",
      "{'score': 7, 'steps': 519, 'reward': 0}\n",
      "{'score': 7, 'steps': 520, 'reward': 0}\n",
      "{'score': 7, 'steps': 521, 'reward': 0}\n",
      "{'score': 7, 'steps': 522, 'reward': 0}\n",
      "{'score': 7, 'steps': 523, 'reward': 0}\n",
      "{'score': 7, 'steps': 524, 'reward': 0}\n",
      "{'score': 7, 'steps': 525, 'reward': 0}\n",
      "{'score': 7, 'steps': 526, 'reward': 0}\n",
      "{'score': 7, 'steps': 527, 'reward': 0}\n",
      "{'score': 7, 'steps': 528, 'reward': 0}\n",
      "{'score': 7, 'steps': 529, 'reward': 0}\n",
      "{'score': 7, 'steps': 530, 'reward': 0}\n",
      "{'score': 7, 'steps': 531, 'reward': 0}\n",
      "{'score': 9, 'steps': 532, 'reward': 2}\n",
      "{'score': 9, 'steps': 533, 'reward': 0}\n",
      "{'score': 9, 'steps': 534, 'reward': 0}\n",
      "{'score': 9, 'steps': 535, 'reward': 0}\n",
      "{'score': 9, 'steps': 536, 'reward': 0}\n",
      "{'score': 9, 'steps': 537, 'reward': 0}\n",
      "{'score': 9, 'steps': 538, 'reward': 0}\n",
      "{'score': 9, 'steps': 539, 'reward': 0}\n",
      "{'score': 9, 'steps': 540, 'reward': 0}\n",
      "{'score': 9, 'steps': 541, 'reward': 0}\n",
      "{'score': 9, 'steps': 542, 'reward': 0}\n",
      "{'score': 9, 'steps': 543, 'reward': 0}\n",
      "{'score': 9, 'steps': 544, 'reward': 0}\n",
      "{'score': 9, 'steps': 545, 'reward': 0}\n",
      "{'score': 9, 'steps': 546, 'reward': 0}\n",
      "{'score': 9, 'steps': 547, 'reward': 0}\n",
      "{'score': 9, 'steps': 548, 'reward': 0}\n",
      "{'score': 9, 'steps': 549, 'reward': 0}\n",
      "{'score': 9, 'steps': 550, 'reward': 0}\n",
      "{'score': 9, 'steps': 551, 'reward': 0}\n",
      "{'score': 9, 'steps': 552, 'reward': 0}\n",
      "{'score': 9, 'steps': 553, 'reward': 0}\n",
      "{'score': 9, 'steps': 554, 'reward': 0}\n",
      "{'score': 9, 'steps': 555, 'reward': 0}\n",
      "{'score': 9, 'steps': 556, 'reward': 0}\n",
      "{'score': 9, 'steps': 557, 'reward': 0}\n",
      "{'score': 9, 'steps': 558, 'reward': 0}\n",
      "{'score': 9, 'steps': 559, 'reward': 0}\n",
      "{'score': 9, 'steps': 560, 'reward': 0}\n",
      "{'score': 9, 'steps': 561, 'reward': 0}\n",
      "{'score': 9, 'steps': 562, 'reward': 0}\n",
      "{'score': 9, 'steps': 563, 'reward': 0}\n",
      "{'score': 9, 'steps': 564, 'reward': 0}\n",
      "{'score': 9, 'steps': 565, 'reward': 0}\n",
      "{'score': 9, 'steps': 566, 'reward': 0}\n",
      "{'score': 9, 'steps': 567, 'reward': 0}\n",
      "{'score': 9, 'steps': 568, 'reward': 0}\n",
      "{'score': 9, 'steps': 569, 'reward': 0}\n",
      "{'score': 9, 'steps': 570, 'reward': 0}\n",
      "{'score': 9, 'steps': 571, 'reward': 0}\n",
      "{'score': 9, 'steps': 572, 'reward': 0}\n",
      "{'score': 9, 'steps': 573, 'reward': 0}\n",
      "{'score': 9, 'steps': 574, 'reward': 0}\n",
      "{'score': 9, 'steps': 575, 'reward': 0}\n",
      "{'score': 9, 'steps': 576, 'reward': 0}\n",
      "{'score': 9, 'steps': 577, 'reward': 0}\n",
      "{'score': 9, 'steps': 578, 'reward': 0}\n",
      "{'score': 9, 'steps': 579, 'reward': 0}\n",
      "{'score': 9, 'steps': 580, 'reward': 0}\n",
      "{'score': 9, 'steps': 581, 'reward': 0}\n",
      "{'score': 9, 'steps': 582, 'reward': 0}\n",
      "{'score': 9, 'steps': 583, 'reward': 0}\n",
      "{'score': 9, 'steps': 584, 'reward': 0}\n",
      "{'score': 9, 'steps': 585, 'reward': 0}\n",
      "{'score': 9, 'steps': 586, 'reward': 0}\n",
      "{'score': 9, 'steps': 587, 'reward': 0}\n",
      "{'score': 9, 'steps': 588, 'reward': 0}\n",
      "{'score': 9, 'steps': 589, 'reward': 0}\n",
      "{'score': 9, 'steps': 590, 'reward': 0}\n",
      "{'score': 9, 'steps': 591, 'reward': 0}\n",
      "{'score': 9, 'steps': 592, 'reward': 0}\n",
      "{'score': 9, 'steps': 593, 'reward': 0}\n",
      "{'score': 9, 'steps': 594, 'reward': 0}\n",
      "{'score': 9, 'steps': 595, 'reward': 0}\n",
      "{'score': 9, 'steps': 596, 'reward': 0}\n",
      "{'score': 9, 'steps': 597, 'reward': 0}\n",
      "{'score': 9, 'steps': 598, 'reward': 0}\n",
      "{'score': 9, 'steps': 599, 'reward': 0}\n",
      "{'score': 9, 'steps': 600, 'reward': 0}\n",
      "{'score': 9, 'steps': 601, 'reward': 0}\n",
      "{'score': 9, 'steps': 602, 'reward': 0}\n",
      "{'score': 9, 'steps': 603, 'reward': 0}\n",
      "{'score': 9, 'steps': 604, 'reward': 0}\n",
      "{'score': 9, 'steps': 605, 'reward': 0}\n",
      "{'score': 9, 'steps': 606, 'reward': 0}\n",
      "{'score': 9, 'steps': 607, 'reward': 0}\n",
      "{'score': 9, 'steps': 608, 'reward': 0}\n",
      "{'score': 9, 'steps': 609, 'reward': 0}\n",
      "{'score': 9, 'steps': 610, 'reward': 0}\n",
      "{'score': 9, 'steps': 611, 'reward': 0}\n",
      "{'score': 9, 'steps': 612, 'reward': 0}\n",
      "{'score': 9, 'steps': 613, 'reward': 0}\n",
      "{'score': 9, 'steps': 614, 'reward': 0}\n",
      "{'score': 9, 'steps': 615, 'reward': 0}\n",
      "{'score': 9, 'steps': 616, 'reward': 0}\n",
      "{'score': 9, 'steps': 617, 'reward': 0}\n",
      "{'score': 9, 'steps': 618, 'reward': 0}\n",
      "{'score': 9, 'steps': 619, 'reward': 0}\n",
      "{'score': 9, 'steps': 620, 'reward': 0}\n",
      "{'score': 9, 'steps': 621, 'reward': 0}\n",
      "{'score': 9, 'steps': 622, 'reward': 0}\n",
      "{'score': 9, 'steps': 623, 'reward': 0}\n",
      "{'score': 9, 'steps': 624, 'reward': 0}\n",
      "{'score': 9, 'steps': 625, 'reward': 0}\n",
      "{'score': 9, 'steps': 626, 'reward': 0}\n",
      "{'score': 9, 'steps': 627, 'reward': 0}\n",
      "{'score': 9, 'steps': 628, 'reward': 0}\n",
      "{'score': 9, 'steps': 629, 'reward': 0}\n",
      "{'score': 9, 'steps': 630, 'reward': 0}\n",
      "{'score': 9, 'steps': 631, 'reward': 0}\n",
      "{'score': 9, 'steps': 632, 'reward': 0}\n",
      "{'score': 9, 'steps': 633, 'reward': 0}\n",
      "{'score': 9, 'steps': 634, 'reward': 0}\n",
      "{'score': 9, 'steps': 635, 'reward': 0}\n",
      "{'score': 9, 'steps': 636, 'reward': 0}\n",
      "{'score': 9, 'steps': 637, 'reward': 0}\n",
      "{'score': 9, 'steps': 638, 'reward': 0}\n",
      "{'score': 9, 'steps': 639, 'reward': 0}\n",
      "{'score': 9, 'steps': 640, 'reward': 0}\n",
      "{'score': 9, 'steps': 641, 'reward': 0}\n",
      "{'score': 9, 'steps': 642, 'reward': 0}\n",
      "{'score': 9, 'steps': 643, 'reward': 0}\n",
      "{'score': 9, 'steps': 644, 'reward': 0}\n",
      "{'score': 9, 'steps': 645, 'reward': 0}\n",
      "{'score': 9, 'steps': 646, 'reward': 0}\n",
      "{'score': 9, 'steps': 647, 'reward': 0}\n",
      "{'score': 9, 'steps': 648, 'reward': 0}\n",
      "{'score': 9, 'steps': 649, 'reward': 0}\n",
      "{'score': 9, 'steps': 650, 'reward': 0}\n",
      "{'score': 9, 'steps': 651, 'reward': 0}\n",
      "{'score': 9, 'steps': 652, 'reward': 0}\n",
      "{'score': 9, 'steps': 653, 'reward': 0}\n",
      "{'score': 9, 'steps': 654, 'reward': 0}\n",
      "{'score': 9, 'steps': 655, 'reward': 0}\n",
      "{'score': 9, 'steps': 656, 'reward': 0}\n",
      "{'score': 9, 'steps': 657, 'reward': 0}\n",
      "{'score': 9, 'steps': 658, 'reward': 0}\n",
      "{'score': 9, 'steps': 659, 'reward': 0}\n",
      "{'score': 9, 'steps': 660, 'reward': 0}\n",
      "{'score': 9, 'steps': 661, 'reward': 0}\n",
      "{'score': 9, 'steps': 662, 'reward': 0}\n",
      "{'score': 9, 'steps': 663, 'reward': 0}\n",
      "{'score': 9, 'steps': 664, 'reward': 0}\n",
      "{'score': 9, 'steps': 665, 'reward': 0}\n",
      "{'score': 9, 'steps': 666, 'reward': 0}\n",
      "{'score': 9, 'steps': 667, 'reward': 0}\n",
      "{'score': 9, 'steps': 668, 'reward': 0}\n",
      "{'score': 9, 'steps': 669, 'reward': 0}\n",
      "{'score': 9, 'steps': 670, 'reward': 0}\n",
      "{'score': 9, 'steps': 671, 'reward': 0}\n",
      "{'score': 9, 'steps': 672, 'reward': 0}\n",
      "{'score': 9, 'steps': 673, 'reward': 0}\n",
      "{'score': 9, 'steps': 674, 'reward': 0}\n",
      "{'score': 9, 'steps': 675, 'reward': 0}\n",
      "{'score': 9, 'steps': 676, 'reward': 0}\n",
      "{'score': 9, 'steps': 677, 'reward': 0}\n",
      "{'score': 9, 'steps': 678, 'reward': 0}\n",
      "{'score': 9, 'steps': 679, 'reward': 0}\n",
      "{'score': 9, 'steps': 680, 'reward': 0}\n",
      "{'score': 9, 'steps': 681, 'reward': 0}\n",
      "{'score': 9, 'steps': 682, 'reward': 0}\n",
      "{'score': 9, 'steps': 683, 'reward': 0}\n",
      "{'score': 9, 'steps': 684, 'reward': 0}\n",
      "{'score': 9, 'steps': 685, 'reward': 0}\n",
      "{'score': 9, 'steps': 686, 'reward': 0}\n",
      "{'score': 9, 'steps': 687, 'reward': 0}\n",
      "{'score': 9, 'steps': 688, 'reward': 0}\n",
      "{'score': 9, 'steps': 689, 'reward': 0}\n",
      "{'score': 9, 'steps': 690, 'reward': 0}\n",
      "{'score': 9, 'steps': 691, 'reward': 0}\n",
      "{'score': 9, 'steps': 692, 'reward': 0}\n",
      "{'score': 9, 'steps': 693, 'reward': 0}\n",
      "{'score': 9, 'steps': 694, 'reward': 0}\n",
      "{'score': 9, 'steps': 695, 'reward': 0}\n",
      "{'score': 9, 'steps': 696, 'reward': 0}\n",
      "{'score': 9, 'steps': 697, 'reward': 0}\n",
      "{'score': 9, 'steps': 698, 'reward': 0}\n",
      "{'score': 9, 'steps': 699, 'reward': 0}\n",
      "{'score': 9, 'steps': 700, 'reward': 0}\n",
      "{'score': 9, 'steps': 701, 'reward': 0}\n",
      "{'score': 9, 'steps': 702, 'reward': 0}\n",
      "{'score': 9, 'steps': 703, 'reward': 0}\n",
      "{'score': 9, 'steps': 704, 'reward': 0}\n",
      "{'score': 9, 'steps': 705, 'reward': 0}\n",
      "{'score': 9, 'steps': 706, 'reward': 0}\n",
      "{'score': 9, 'steps': 707, 'reward': 0}\n",
      "{'score': 9, 'steps': 708, 'reward': 0}\n",
      "{'score': 9, 'steps': 709, 'reward': 0}\n",
      "{'score': 9, 'steps': 710, 'reward': 0}\n",
      "{'score': 9, 'steps': 711, 'reward': 0}\n",
      "{'score': 9, 'steps': 712, 'reward': 0}\n",
      "{'score': 9, 'steps': 713, 'reward': 0}\n",
      "{'score': 9, 'steps': 714, 'reward': 0}\n",
      "{'score': 9, 'steps': 715, 'reward': 0}\n",
      "{'score': 9, 'steps': 716, 'reward': 0}\n",
      "{'score': 9, 'steps': 717, 'reward': 0}\n",
      "{'score': 9, 'steps': 718, 'reward': 0}\n",
      "{'score': 9, 'steps': 719, 'reward': 0}\n",
      "{'score': 9, 'steps': 720, 'reward': 0}\n",
      "{'score': 9, 'steps': 721, 'reward': 0}\n",
      "{'score': 9, 'steps': 722, 'reward': 0}\n",
      "{'score': 9, 'steps': 723, 'reward': 0}\n",
      "{'score': 9, 'steps': 724, 'reward': 0}\n",
      "{'score': 9, 'steps': 725, 'reward': 0}\n",
      "{'score': 9, 'steps': 726, 'reward': 0}\n",
      "{'score': 9, 'steps': 727, 'reward': 0}\n",
      "{'score': 9, 'steps': 728, 'reward': 0}\n",
      "{'score': 9, 'steps': 729, 'reward': 0}\n",
      "{'score': 9, 'steps': 730, 'reward': 0}\n",
      "{'score': 9, 'steps': 731, 'reward': 0}\n",
      "{'score': 9, 'steps': 732, 'reward': 0}\n",
      "{'score': 9, 'steps': 733, 'reward': 0}\n",
      "{'score': 9, 'steps': 734, 'reward': 0}\n",
      "{'score': 9, 'steps': 735, 'reward': 0}\n",
      "{'score': 9, 'steps': 736, 'reward': 0}\n",
      "{'score': 9, 'steps': 737, 'reward': 0}\n",
      "{'score': 9, 'steps': 738, 'reward': 0}\n",
      "{'score': 9, 'steps': 739, 'reward': 0}\n",
      "{'score': 9, 'steps': 740, 'reward': 0}\n",
      "{'score': 9, 'steps': 741, 'reward': 0}\n",
      "{'score': 9, 'steps': 742, 'reward': 0}\n",
      "{'score': 9, 'steps': 743, 'reward': 0}\n",
      "{'score': 9, 'steps': 744, 'reward': 0}\n",
      "{'score': 9, 'steps': 745, 'reward': 0}\n",
      "{'score': 9, 'steps': 746, 'reward': 0}\n",
      "{'score': 9, 'steps': 747, 'reward': 0}\n",
      "{'score': 9, 'steps': 748, 'reward': 0}\n",
      "{'score': 9, 'steps': 749, 'reward': 0}\n",
      "{'score': 9, 'steps': 750, 'reward': 0}\n",
      "{'score': 9, 'steps': 751, 'reward': 0}\n",
      "{'score': 9, 'steps': 752, 'reward': 0}\n",
      "{'score': 9, 'steps': 753, 'reward': 0}\n",
      "{'score': 9, 'steps': 754, 'reward': 0}\n",
      "{'score': 9, 'steps': 755, 'reward': 0}\n",
      "{'score': 9, 'steps': 756, 'reward': 0}\n",
      "{'score': 9, 'steps': 757, 'reward': 0}\n",
      "{'score': 12, 'steps': 758, 'reward': 3}\n",
      "{'score': 12, 'steps': 759, 'reward': 0}\n",
      "{'score': 12, 'steps': 760, 'reward': 0}\n",
      "{'score': 12, 'steps': 761, 'reward': 0}\n",
      "{'score': 12, 'steps': 762, 'reward': 0}\n",
      "{'score': 12, 'steps': 763, 'reward': 0}\n",
      "{'score': 12, 'steps': 764, 'reward': 0}\n",
      "{'score': 12, 'steps': 765, 'reward': 0}\n",
      "{'score': 12, 'steps': 766, 'reward': 0}\n",
      "{'score': 12, 'steps': 767, 'reward': 0}\n",
      "{'score': 12, 'steps': 768, 'reward': 0}\n",
      "{'score': 12, 'steps': 769, 'reward': 0}\n",
      "{'score': 12, 'steps': 770, 'reward': 0}\n",
      "{'score': 12, 'steps': 771, 'reward': 0}\n",
      "{'score': 12, 'steps': 772, 'reward': 0}\n",
      "{'score': 12, 'steps': 773, 'reward': 0}\n",
      "{'score': 12, 'steps': 774, 'reward': 0}\n",
      "{'score': 12, 'steps': 775, 'reward': 0}\n",
      "{'score': 12, 'steps': 776, 'reward': 0}\n",
      "{'score': 14, 'steps': 777, 'reward': 2}\n",
      "{'score': 14, 'steps': 778, 'reward': 0}\n",
      "{'score': 14, 'steps': 779, 'reward': 0}\n",
      "{'score': 14, 'steps': 780, 'reward': 0}\n",
      "{'score': 14, 'steps': 781, 'reward': 0}\n",
      "{'score': 14, 'steps': 782, 'reward': 0}\n",
      "{'score': 14, 'steps': 783, 'reward': 0}\n",
      "{'score': 14, 'steps': 784, 'reward': 0}\n",
      "{'score': 14, 'steps': 785, 'reward': 0}\n",
      "{'score': 14, 'steps': 786, 'reward': 0}\n",
      "{'score': 14, 'steps': 787, 'reward': 0}\n",
      "{'score': 14, 'steps': 788, 'reward': 0}\n",
      "{'score': 14, 'steps': 789, 'reward': 0}\n",
      "{'score': 14, 'steps': 790, 'reward': 0}\n",
      "{'score': 14, 'steps': 791, 'reward': 0}\n",
      "{'score': 14, 'steps': 792, 'reward': 0}\n",
      "{'score': 14, 'steps': 793, 'reward': 0}\n",
      "{'score': 14, 'steps': 794, 'reward': 0}\n",
      "{'score': 14, 'steps': 795, 'reward': 0}\n",
      "{'score': 14, 'steps': 796, 'reward': 0}\n",
      "{'score': 14, 'steps': 797, 'reward': 0}\n",
      "{'score': 14, 'steps': 798, 'reward': 0}\n",
      "{'score': 14, 'steps': 799, 'reward': 0}\n",
      "{'score': 14, 'steps': 800, 'reward': 0}\n",
      "{'score': 14, 'steps': 801, 'reward': 0}\n",
      "{'score': 14, 'steps': 802, 'reward': 0}\n",
      "{'score': 14, 'steps': 803, 'reward': 0}\n",
      "{'score': 14, 'steps': 804, 'reward': 0}\n",
      "{'score': 14, 'steps': 805, 'reward': 0}\n",
      "{'score': 14, 'steps': 806, 'reward': 0}\n",
      "{'score': 14, 'steps': 807, 'reward': 0}\n",
      "{'score': 14, 'steps': 808, 'reward': 0}\n",
      "{'score': 14, 'steps': 809, 'reward': 0}\n",
      "{'score': 14, 'steps': 810, 'reward': 0}\n",
      "{'score': 14, 'steps': 811, 'reward': 0}\n",
      "{'score': 14, 'steps': 812, 'reward': 0}\n",
      "{'score': 14, 'steps': 813, 'reward': 0}\n",
      "{'score': 14, 'steps': 814, 'reward': 0}\n",
      "{'score': 14, 'steps': 815, 'reward': 0}\n",
      "{'score': 14, 'steps': 816, 'reward': 0}\n",
      "{'score': 14, 'steps': 817, 'reward': 0}\n",
      "{'score': 14, 'steps': 818, 'reward': 0}\n",
      "{'score': 14, 'steps': 819, 'reward': 0}\n",
      "{'score': 14, 'steps': 820, 'reward': 0}\n",
      "{'score': 14, 'steps': 821, 'reward': 0}\n",
      "{'score': 14, 'steps': 822, 'reward': 0}\n",
      "{'score': 14, 'steps': 823, 'reward': 0}\n",
      "{'score': 14, 'steps': 824, 'reward': 0}\n",
      "{'score': 14, 'steps': 825, 'reward': 0}\n",
      "{'score': 14, 'steps': 826, 'reward': 0}\n",
      "{'score': 14, 'steps': 827, 'reward': 0}\n",
      "{'score': 14, 'steps': 828, 'reward': 0}\n",
      "{'score': 14, 'steps': 829, 'reward': 0}\n",
      "{'score': 14, 'steps': 830, 'reward': 0}\n",
      "{'score': 14, 'steps': 831, 'reward': 0}\n",
      "{'score': 14, 'steps': 832, 'reward': 0}\n",
      "{'score': 14, 'steps': 833, 'reward': 0}\n",
      "{'score': 14, 'steps': 834, 'reward': 0}\n",
      "{'score': 14, 'steps': 835, 'reward': 0}\n",
      "{'score': 14, 'steps': 836, 'reward': 0}\n",
      "{'score': 14, 'steps': 837, 'reward': 0}\n",
      "{'score': 14, 'steps': 838, 'reward': 0}\n",
      "{'score': 14, 'steps': 839, 'reward': 0}\n",
      "{'score': 14, 'steps': 840, 'reward': 0}\n",
      "{'score': 14, 'steps': 841, 'reward': 0}\n",
      "{'score': 14, 'steps': 842, 'reward': 0}\n",
      "{'score': 14, 'steps': 843, 'reward': 0}\n",
      "{'score': 14, 'steps': 844, 'reward': 0}\n",
      "{'score': 14, 'steps': 845, 'reward': 0}\n",
      "{'score': 14, 'steps': 846, 'reward': 0}\n",
      "{'score': 14, 'steps': 847, 'reward': 0}\n",
      "{'score': 14, 'steps': 848, 'reward': 0}\n",
      "{'score': 14, 'steps': 849, 'reward': 0}\n",
      "{'score': 14, 'steps': 850, 'reward': 0}\n",
      "{'score': 14, 'steps': 851, 'reward': 0}\n",
      "{'score': 14, 'steps': 852, 'reward': 0}\n",
      "{'score': 14, 'steps': 853, 'reward': 0}\n",
      "{'score': 14, 'steps': 854, 'reward': 0}\n",
      "{'score': 14, 'steps': 855, 'reward': 0}\n",
      "{'score': 14, 'steps': 856, 'reward': 0}\n",
      "{'score': 14, 'steps': 857, 'reward': 0}\n",
      "{'score': 14, 'steps': 858, 'reward': 0}\n",
      "{'score': 14, 'steps': 859, 'reward': 0}\n",
      "{'score': 14, 'steps': 860, 'reward': 0}\n",
      "{'score': 14, 'steps': 861, 'reward': 0}\n",
      "{'score': 14, 'steps': 862, 'reward': 0}\n",
      "{'score': 14, 'steps': 863, 'reward': 0}\n",
      "{'score': 14, 'steps': 864, 'reward': 0}\n",
      "{'score': 14, 'steps': 865, 'reward': 0}\n",
      "{'score': 14, 'steps': 866, 'reward': 0}\n",
      "{'score': 14, 'steps': 867, 'reward': 0}\n",
      "{'score': 14, 'steps': 868, 'reward': 0}\n",
      "{'score': 14, 'steps': 869, 'reward': 0}\n",
      "{'score': 14, 'steps': 870, 'reward': 0}\n",
      "{'score': 14, 'steps': 871, 'reward': 0}\n",
      "{'score': 14, 'steps': 872, 'reward': 0}\n",
      "{'score': 14, 'steps': 873, 'reward': 0}\n",
      "{'score': 14, 'steps': 874, 'reward': 0}\n",
      "{'score': 14, 'steps': 875, 'reward': 0}\n",
      "{'score': 14, 'steps': 876, 'reward': 0}\n",
      "{'score': 14, 'steps': 877, 'reward': 0}\n",
      "{'score': 14, 'steps': 878, 'reward': 0}\n",
      "{'score': 14, 'steps': 879, 'reward': 0}\n",
      "{'score': 14, 'steps': 880, 'reward': 0}\n",
      "{'score': 14, 'steps': 881, 'reward': 0}\n",
      "{'score': 14, 'steps': 882, 'reward': 0}\n",
      "{'score': 14, 'steps': 883, 'reward': 0}\n",
      "{'score': 14, 'steps': 884, 'reward': 0}\n",
      "{'score': 14, 'steps': 885, 'reward': 0}\n",
      "{'score': 14, 'steps': 886, 'reward': 0}\n",
      "{'score': 14, 'steps': 887, 'reward': 0}\n",
      "{'score': 14, 'steps': 888, 'reward': 0}\n",
      "{'score': 14, 'steps': 889, 'reward': 0}\n",
      "{'score': 14, 'steps': 890, 'reward': 0}\n",
      "{'score': 14, 'steps': 891, 'reward': 0}\n",
      "{'score': 14, 'steps': 892, 'reward': 0}\n",
      "{'score': 14, 'steps': 893, 'reward': 0}\n",
      "{'score': 14, 'steps': 894, 'reward': 0}\n",
      "{'score': 14, 'steps': 895, 'reward': 0}\n",
      "{'score': 14, 'steps': 896, 'reward': 0}\n",
      "{'score': 14, 'steps': 897, 'reward': 0}\n",
      "{'score': 14, 'steps': 898, 'reward': 0}\n",
      "{'score': 14, 'steps': 899, 'reward': 0}\n",
      "{'score': 14, 'steps': 900, 'reward': 0}\n",
      "{'score': 14, 'steps': 901, 'reward': 0}\n",
      "{'score': 14, 'steps': 902, 'reward': 0}\n",
      "{'score': 14, 'steps': 903, 'reward': 0}\n",
      "{'score': 14, 'steps': 904, 'reward': 0}\n",
      "{'score': 14, 'steps': 905, 'reward': 0}\n",
      "{'score': 14, 'steps': 906, 'reward': 0}\n",
      "{'score': 14, 'steps': 907, 'reward': 0}\n",
      "{'score': 14, 'steps': 908, 'reward': 0}\n",
      "{'score': 14, 'steps': 909, 'reward': 0}\n",
      "{'score': 14, 'steps': 910, 'reward': 0}\n",
      "{'score': 14, 'steps': 911, 'reward': 0}\n",
      "{'score': 14, 'steps': 912, 'reward': 0}\n",
      "{'score': 14, 'steps': 913, 'reward': 0}\n",
      "{'score': 14, 'steps': 914, 'reward': 0}\n",
      "{'score': 14, 'steps': 915, 'reward': 0}\n",
      "{'score': 14, 'steps': 916, 'reward': 0}\n",
      "{'score': 14, 'steps': 917, 'reward': 0}\n",
      "{'score': 14, 'steps': 918, 'reward': 0}\n",
      "{'score': 14, 'steps': 919, 'reward': 0}\n",
      "{'score': 14, 'steps': 920, 'reward': 0}\n",
      "{'score': 14, 'steps': 921, 'reward': 0}\n",
      "{'score': 14, 'steps': 922, 'reward': 0}\n",
      "{'score': 14, 'steps': 923, 'reward': 0}\n",
      "{'score': 14, 'steps': 924, 'reward': 0}\n",
      "{'score': 14, 'steps': 925, 'reward': 0}\n",
      "{'score': 14, 'steps': 926, 'reward': 0}\n",
      "{'score': 14, 'steps': 927, 'reward': 0}\n",
      "{'score': 14, 'steps': 928, 'reward': 0}\n",
      "{'score': 14, 'steps': 929, 'reward': 0}\n",
      "{'score': 14, 'steps': 930, 'reward': 0}\n",
      "{'score': 14, 'steps': 931, 'reward': 0}\n",
      "{'score': 17, 'steps': 932, 'reward': 3}\n",
      "{'score': 17, 'steps': 933, 'reward': 0}\n",
      "{'score': 17, 'steps': 934, 'reward': 0}\n",
      "{'score': 17, 'steps': 935, 'reward': 0}\n",
      "{'score': 17, 'steps': 936, 'reward': 0}\n",
      "{'score': 17, 'steps': 937, 'reward': 0}\n",
      "{'score': 17, 'steps': 938, 'reward': 0}\n",
      "{'score': 17, 'steps': 939, 'reward': 0}\n",
      "{'score': 17, 'steps': 940, 'reward': 0}\n",
      "{'score': 17, 'steps': 941, 'reward': 0}\n",
      "{'score': 17, 'steps': 942, 'reward': 0}\n",
      "{'score': 17, 'steps': 943, 'reward': 0}\n",
      "{'score': 17, 'steps': 944, 'reward': 0}\n",
      "{'score': 17, 'steps': 945, 'reward': 0}\n",
      "{'score': 17, 'steps': 946, 'reward': 0}\n",
      "{'score': 17, 'steps': 947, 'reward': 0}\n",
      "{'score': 17, 'steps': 948, 'reward': 0}\n",
      "{'score': 17, 'steps': 949, 'reward': 0}\n",
      "{'score': 17, 'steps': 950, 'reward': 0}\n",
      "{'score': 17, 'steps': 951, 'reward': 0}\n",
      "{'score': 17, 'steps': 952, 'reward': 0}\n",
      "{'score': 17, 'steps': 953, 'reward': 0}\n",
      "{'score': 17, 'steps': 954, 'reward': 0}\n",
      "{'score': 17, 'steps': 955, 'reward': 0}\n",
      "{'score': 17, 'steps': 956, 'reward': 0}\n",
      "{'score': 17, 'steps': 957, 'reward': 0}\n",
      "{'score': 17, 'steps': 958, 'reward': 0}\n",
      "{'score': 17, 'steps': 959, 'reward': 0}\n",
      "{'score': 17, 'steps': 960, 'reward': 0}\n",
      "{'score': 17, 'steps': 961, 'reward': 0}\n",
      "{'score': 17, 'steps': 962, 'reward': 0}\n",
      "{'score': 17, 'steps': 963, 'reward': 0}\n",
      "{'score': 17, 'steps': 964, 'reward': 0}\n",
      "{'score': 17, 'steps': 965, 'reward': 0}\n",
      "{'score': 17, 'steps': 966, 'reward': 0}\n",
      "{'score': 17, 'steps': 967, 'reward': 0}\n",
      "{'score': 17, 'steps': 968, 'reward': 0}\n",
      "{'score': 17, 'steps': 969, 'reward': 0}\n",
      "{'score': 17, 'steps': 970, 'reward': 0}\n",
      "{'score': 17, 'steps': 971, 'reward': 0}\n",
      "{'score': 17, 'steps': 972, 'reward': 0}\n",
      "{'score': 17, 'steps': 973, 'reward': 0}\n",
      "{'score': 17, 'steps': 974, 'reward': 0}\n",
      "{'score': 17, 'steps': 975, 'reward': 0}\n",
      "{'score': 17, 'steps': 976, 'reward': 0}\n",
      "{'score': 17, 'steps': 977, 'reward': 0}\n",
      "{'score': 17, 'steps': 978, 'reward': 0}\n",
      "{'score': 17, 'steps': 979, 'reward': 0}\n",
      "{'score': 17, 'steps': 980, 'reward': 0}\n",
      "{'score': 17, 'steps': 981, 'reward': 0}\n",
      "{'score': 17, 'steps': 982, 'reward': 0}\n",
      "{'score': 17, 'steps': 983, 'reward': 0}\n",
      "{'score': 17, 'steps': 984, 'reward': 0}\n",
      "{'score': 17, 'steps': 985, 'reward': 0}\n",
      "{'score': 17, 'steps': 986, 'reward': 0}\n",
      "{'score': 17, 'steps': 987, 'reward': 0}\n",
      "{'score': 17, 'steps': 988, 'reward': 0}\n",
      "{'score': 17, 'steps': 989, 'reward': 0}\n",
      "{'score': 17, 'steps': 990, 'reward': 0}\n",
      "{'score': 17, 'steps': 991, 'reward': 0}\n",
      "{'score': 17, 'steps': 992, 'reward': 0}\n",
      "{'score': 17, 'steps': 993, 'reward': 0}\n",
      "{'score': 17, 'steps': 994, 'reward': 0}\n",
      "{'score': 17, 'steps': 995, 'reward': 0}\n",
      "{'score': 17, 'steps': 996, 'reward': 0}\n",
      "{'score': 17, 'steps': 997, 'reward': 0}\n",
      "{'score': 17, 'steps': 998, 'reward': 0}\n",
      "{'score': 17, 'steps': 999, 'reward': 0}\n",
      "{'score': 17, 'steps': 1000, 'reward': 0}\n",
      "      0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35\n",
      "   ------------------------------------------------------------------------------------------------------------\n",
      " 0 |  2  2  2  2  5  6  6  3  5  8  4  9  7  6  5  9  6  4  3  3  7  1  3  8  3  7  5  1  6  4  4  4  2  1  8  6\n",
      " 1 |  3  8  9  8  5  7  5  7  8  9  4  3  6  6  4  5  8  2  2  4  6  3  1  5  3  8  5  9  5  7  1  5  3  8  4  9\n",
      " 2 |  3  6  1  6  5  7  4  4  7  5  1  8  1  3  1  7  7  1  7  1  1  6  5  4  6  9  1  3  7  5  4  1  7  4  4  1\n",
      " 3 |  2  7  6  2  2  2  3  2  7  7  9  3  5  2  4  5  9  3  9  9  8  3  1  6  2  8  4  5  4  3  5  9  2  3  5  7\n",
      " 4 |  6  7  8  7  9  3  9  4  4  9  8  6  3  7  1  6  2  3  5  3  4  4  9  2  4  5  2  6  3  5  1  1  8  7  8  1\n",
      " 5 |  2  1  4  8  3  5  2  4  4  7  8  2  5  5  2  7  6  4  3  7  5  2  8  3  6  4  1  5  6  3  3  8  6  8  4  9\n",
      " 6 |  3  2  9  2  4  1  2  8  3  8  5  2  6  4  6  3  7  9  3  3  2  4  9  6  4  1  3  2  8  8  6  2  7  6  3  4\n",
      " 7 |  1  6  9  5  8  7  8  5  0  9  5  5  9  2  7  5  9  4  1  4  3  8  2  5  3  7  9  4  3  1  3  8  1  2  9  2\n",
      " 8 |  2  2  5  2  3  2  6  0  0  0  7  0  9  5  4  1  4  9  8  4  1  8  6  6  9  6  9  3  7  5  9  5  6  4  6  7\n",
      " 9 |  3  8  2  5  1  8  0  0  0  0  0  0  6  4  7  1  8  5  7  9  8  1  3  5  6  7  8  8  7  6  5  8  3  3  4  6\n",
      "10 |  8  2  5  7  5  3  8  0  0  0  8  2  8  8  2  1  9  3  1  4  7  5  2  6  9  3  7  2  9  6  3  2  6  3  6  5\n",
      "11 |  5  3  6  6  9  1  2  0  0  0  1  5  6  5  6  4  5  8  7  2  3  9  4  3  4  2  7  2  7  7  8  4  5  3  1  4\n",
      "12 |  3  9  8  1  7  6  2  5  1  3  3  9  4  7  3  5  2  2  1  9  5  2  3  9  6  4  7  9  3  5  2  8  4  7  8  9\n",
      "13 |  7  1  6  1  4  4  8  6  9  9  8  8  4  8  2  8  7  9  3  5  4  4  9  1  7  8  1  1  2  6  6  9  7  2  4  1\n",
      "14 |  7  7  4  3  4  6  7  6  5  1  2  4  1  8  6  8  2  1  3  5  6  3  8  5  6  4  6  9  5  9  1  2  6  1  2  1\n",
      "15 |  4  9  9  9  7  1  1  4  5  6  7  9  4  7  3  1  1  4  6  5  7  8  9  5  6  9  8  5  9  1  1  6  8  1  7  8\n",
      "16 |  8  4  6  3  8  6  1  1  4  5  1  6  7  9  5  4  2  3  8  8  2  1  7  5  4  5  7  5  8  7  1  3  3  5  4  9\n",
      "17 |  6  3  6  1  4  3  5  8  1  7  1  6  6  3  5  8  8  4  4  7  3  6  1  2  2  1  8  3  1  4  1  2  9  6  9  9\n",
      "18 |  5  7  3  3  5  1  5  4  5  8  2  1  1  8  3  6  9  2  9  6  2  9  1  1  8  4  4  8  9  8  1  5  6  6  3  8\n",
      "19 |  4  4  1  1  8  4  6  1  5  9  5  5  5  2  6  3  5  8  8  8  3  8  6  6  7  4  2  5  9  7  3  5  4  6  3  5\n",
      "20 |  7  2  4  9  5  7  3  8  9  8  5  2  8  4  6  9  7  5  6  2  4  5  8  1  4  1  7  1  4  8  9  7  6  9  4  8\n",
      "21 |  7  9  6  3  2  5  5  8  4  3  1  7  9  1  4  8  6  5  8  5  4  4  4  6  7  7  6  8  3  8  6  8  1  9  8  6\n",
      "22 |  7  5  7  6  4  7  8  6  9  9  6  8  6  2  3  2  4  2  4  7  9  5  2  6  3  3  1  2  9  4  8  6  4  1  7  5\n",
      "23 |  5  5  2  4  9  6  9  3  9  1  2  5  9  8  8  2  9  6  4  3  8  8  9  2  8  6  2  8  5  2  7  5  1  4  6  6\n",
      "24 |  1  1  4  8  2  9  9  2  1  4  6  1  9  1  7  2  6  5  8  4  7  4  5  7  7  7  7  6  6  8  2  9  2  3  8  1\n",
      "25 |  6  7  7  3  3  9  5  7  1  7  9  7  1  3  2  9  4  9  8  2  6  2  4  1  8  2  2  4  8  1  5  5  1  6  9  5\n",
      "26 |  6  7  2  7  4  3  9  2  5  1  3  5  5  4  2  4  4  3  9  5  4  9  7  4  1  3  1  4  8  2  6  8  9  1  9  6\n",
      "27 |  6  7  4  5  4  7  1  1  4  3  5  4  6  2  1  8  2  7  4  7  1  3  9  6  9  8  7  6  8  4  5  4  2  5  4  1\n",
      "28 |  5  4  9  7  8  7  9  2  9  5  2  4  2  2  3  8  6  3  5  8  5  4  3  2  3  8  8  3  7  2  7  7  9  1  7  7\n",
      "29 |  8  1  9  6  9  6  8  2  5  7  3  9  3  5  6  7  2  7  6  8  5  5  1  3  4  9  6  6  9  4  1  1  5  5  3  4\n",
      "30 |  6  8  2  1  1  5  3  2  2  7  7  6  4  2  5  7  2  2  2  8  1  5  1  3  5  4  9  6  1  6  8  6  3  3  7  6\n",
      "31 |  7  8  6  9  3  9  4  3  6  8  9  2  3  9  5  8  3  8  9  2  1  6  6  9  8  1  6  6  8  1  4  6  6  3  6  8\n",
      "32 |  1  5  5  1  7  5  7  6  4  2  1  1  2  3  1  7  9  9  4  7  6  1  5  1  8  2  3  2  5  1  2  2  4  1  5  9\n",
      "33 |  4  9  6  8  4  7  9  4  1  6  2  4  6  9  4  3  2  5  9  3  6  3  1  3  2  3  4  4  3  8  4  8  9  7  5  5\n",
      "34 |  5  4  8  4  5  2  1  5  9  1  4  6  2  5  7  7  5  5  6  7  4  8  3  8  2  2  5  1  8  4  4  2  8  5  2  8\n",
      "35 |  2  9  5  3  9  2  3  6  5  1  5  9  4  5  4  8  6  8  9  4  3  2  4  4  2  5  2  9  6  2  7  1  5  4  5  8\n",
      "남은 스텝:  0\n",
      "점수:  17\n"
     ]
    }
   ],
   "source": [
    "test_env = AppleGameEnv(m=36, n=36, max_steps=1000)\n",
    "obs, _ = test_env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = model.predict(obs, deterministic=False)[0]\n",
    "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "    print(info)\n",
    "    done = terminated or truncated\n",
    "\n",
    "test_env.render()\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
